{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2wtwmnUGYqPm",
        "outputId": "7e8a5013-0958-4b9f-c41a-54707e6ced41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7d7fa9856b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7d7fa9856b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500, Generator Loss: 0.4895, Discriminator Loss: 0.4879\n",
            "Epoch 1/500, Generator Loss: 0.4819, Discriminator Loss: 0.4672\n",
            "Epoch 1/500, Generator Loss: 0.4689, Discriminator Loss: 0.4476\n",
            "Epoch 1/500, Generator Loss: 0.4592, Discriminator Loss: 0.4343\n",
            "Epoch 1/500, Generator Loss: 0.4524, Discriminator Loss: 0.4193\n",
            "Epoch 1/500, Generator Loss: 0.4445, Discriminator Loss: 0.4083\n",
            "Epoch 1/500, Generator Loss: 0.4359, Discriminator Loss: 0.3985\n",
            "Epoch 1/500, Generator Loss: 0.4280, Discriminator Loss: 0.3913\n",
            "Epoch 1/500, Generator Loss: 0.4221, Discriminator Loss: 0.3865\n",
            "Epoch 1/500, Generator Loss: 0.4148, Discriminator Loss: 0.3803\n",
            "Epoch 1/500, Generator Loss: 0.4075, Discriminator Loss: 0.3773\n",
            "Epoch 1/500, Generator Loss: 0.4015, Discriminator Loss: 0.3763\n",
            "Epoch 1/500, Generator Loss: 0.3961, Discriminator Loss: 0.3722\n",
            "Epoch 1/500, Generator Loss: 0.3911, Discriminator Loss: 0.3675\n",
            "Epoch 1/500, Generator Loss: 0.3873, Discriminator Loss: 0.3631\n",
            "Epoch 1/500, Generator Loss: 0.3824, Discriminator Loss: 0.3581\n",
            "Epoch 1/500, Generator Loss: 0.3773, Discriminator Loss: 0.3527\n",
            "Epoch 1/500, Generator Loss: 0.3722, Discriminator Loss: 0.3493\n",
            "Epoch 1/500, Generator Loss: 0.3673, Discriminator Loss: 0.3451\n",
            "Epoch 1/500, Generator Loss: 0.3630, Discriminator Loss: 0.3417\n",
            "Epoch 1/500, Generator Loss: 0.3591, Discriminator Loss: 0.3380\n",
            "Epoch 1/500, Generator Loss: 0.3556, Discriminator Loss: 0.3352\n",
            "Epoch 1/500, Generator Loss: 0.3523, Discriminator Loss: 0.3313\n",
            "Epoch 1/500, Generator Loss: 0.3486, Discriminator Loss: 0.3275\n",
            "Epoch 1/500, Generator Loss: 0.3448, Discriminator Loss: 0.3242\n",
            "Epoch 1/500, Generator Loss: 0.3410, Discriminator Loss: 0.3199\n",
            "Epoch 1/500, Generator Loss: 0.3374, Discriminator Loss: 0.3164\n",
            "Epoch 1/500, Generator Loss: 0.3333, Discriminator Loss: 0.3136\n",
            "Epoch 1/500, Generator Loss: 0.3306, Discriminator Loss: 0.3111\n",
            "Epoch 1/500, Generator Loss: 0.3279, Discriminator Loss: 0.3076\n",
            "Epoch 1/500, Generator Loss: 0.3247, Discriminator Loss: 0.3056\n",
            "Epoch 1/500, Generator Loss: 0.3220, Discriminator Loss: 0.3023\n",
            "Epoch 1/500, Generator Loss: 0.3199, Discriminator Loss: 0.2992\n",
            "Epoch 1/500, Generator Loss: 0.3175, Discriminator Loss: 0.2960\n",
            "Epoch 1/500, Generator Loss: 0.3154, Discriminator Loss: 0.2927\n",
            "Epoch 1/500, Generator Loss: 0.3135, Discriminator Loss: 0.2901\n",
            "Epoch 1/500, Generator Loss: 0.3112, Discriminator Loss: 0.2873\n",
            "Epoch 1/500, Generator Loss: 0.3090, Discriminator Loss: 0.2850\n",
            "Epoch 1/500, Generator Loss: 0.3067, Discriminator Loss: 0.2819\n",
            "Epoch 1/500, Generator Loss: 0.3046, Discriminator Loss: 0.2793\n",
            "Epoch 1/500, Generator Loss: 0.3025, Discriminator Loss: 0.2764\n",
            "Epoch 1/500, Generator Loss: 0.3006, Discriminator Loss: 0.2733\n",
            "Epoch 1/500, Generator Loss: 0.2987, Discriminator Loss: 0.2706\n",
            "Epoch 1/500, Generator Loss: 0.2972, Discriminator Loss: 0.2678\n",
            "Epoch 1/500, Generator Loss: 0.2956, Discriminator Loss: 0.2649\n",
            "Epoch 1/500, Generator Loss: 0.2940, Discriminator Loss: 0.2627\n",
            "Epoch 1/500, Generator Loss: 0.2924, Discriminator Loss: 0.2605\n",
            "Epoch 1/500, Generator Loss: 0.2909, Discriminator Loss: 0.2587\n",
            "Epoch 1/500, Generator Loss: 0.2894, Discriminator Loss: 0.2569\n",
            "Epoch 1/500, Generator Loss: 0.2879, Discriminator Loss: 0.2549\n",
            "Epoch 1/500, Generator Loss: 0.2865, Discriminator Loss: 0.2527\n",
            "Epoch 1/500, Generator Loss: 0.2849, Discriminator Loss: 0.2506\n",
            "Epoch 1/500, Generator Loss: 0.2837, Discriminator Loss: 0.2485\n",
            "Epoch 1/500, Generator Loss: 0.2823, Discriminator Loss: 0.2465\n",
            "Epoch 1/500, Generator Loss: 0.2810, Discriminator Loss: 0.2445\n",
            "Epoch 1/500, Generator Loss: 0.2799, Discriminator Loss: 0.2424\n",
            "Epoch 1/500, Generator Loss: 0.2784, Discriminator Loss: 0.2410\n",
            "Epoch 1/500, Generator Loss: 0.2773, Discriminator Loss: 0.2392\n",
            "Epoch 1/500, Generator Loss: 0.2762, Discriminator Loss: 0.2379\n",
            "Epoch 1/500, Generator Loss: 0.2752, Discriminator Loss: 0.2365\n",
            "Epoch 1/500, Generator Loss: 0.2743, Discriminator Loss: 0.2351\n",
            "Epoch 1/500, Generator Loss: 0.2735, Discriminator Loss: 0.2331\n",
            "Epoch 1/500, Generator Loss: 0.2726, Discriminator Loss: 0.2312\n",
            "Epoch 1/500, Generator Loss: 0.2716, Discriminator Loss: 0.2294\n",
            "Epoch 1/500, Generator Loss: 0.2705, Discriminator Loss: 0.2276\n",
            "Epoch 1/500, Generator Loss: 0.2693, Discriminator Loss: 0.2258\n",
            "Epoch 1/500, Generator Loss: 0.2683, Discriminator Loss: 0.2241\n",
            "Epoch 1/500, Generator Loss: 0.2672, Discriminator Loss: 0.2229\n",
            "Epoch 1/500, Generator Loss: 0.2662, Discriminator Loss: 0.2216\n",
            "Epoch 1/500, Generator Loss: 0.2653, Discriminator Loss: 0.2200\n",
            "Epoch 1/500, Generator Loss: 0.2643, Discriminator Loss: 0.2188\n",
            "Epoch 1/500, Generator Loss: 0.2635, Discriminator Loss: 0.2176\n",
            "Epoch 1/500, Generator Loss: 0.2627, Discriminator Loss: 0.2161\n",
            "Epoch 1/500, Generator Loss: 0.2619, Discriminator Loss: 0.2149\n",
            "Epoch 1/500, Generator Loss: 0.2610, Discriminator Loss: 0.2139\n",
            "Epoch 1/500, Generator Loss: 0.2603, Discriminator Loss: 0.2126\n",
            "Epoch 1/500, Generator Loss: 0.2594, Discriminator Loss: 0.2114\n",
            "Epoch 1/500, Generator Loss: 0.2586, Discriminator Loss: 0.2100\n",
            "Epoch 1/500, Generator Loss: 0.2577, Discriminator Loss: 0.2087\n",
            "Epoch 1/500, Generator Loss: 0.2568, Discriminator Loss: 0.2074\n",
            "Epoch 1/500, Generator Loss: 0.2558, Discriminator Loss: 0.2060\n",
            "Epoch 1/500, Generator Loss: 0.2549, Discriminator Loss: 0.2049\n",
            "Epoch 1/500, Generator Loss: 0.2541, Discriminator Loss: 0.2037\n",
            "Epoch 1/500, Generator Loss: 0.2533, Discriminator Loss: 0.2026\n",
            "Epoch 1/500, Generator Loss: 0.2525, Discriminator Loss: 0.2015\n",
            "Epoch 1/500, Generator Loss: 0.2517, Discriminator Loss: 0.2005\n",
            "Epoch 1/500, Generator Loss: 0.2511, Discriminator Loss: 0.1997\n",
            "Epoch 1/500, Generator Loss: 0.2506, Discriminator Loss: 0.1989\n",
            "Epoch 1/500, Generator Loss: 0.2500, Discriminator Loss: 0.1978\n",
            "Epoch 1/500, Generator Loss: 0.2494, Discriminator Loss: 0.1970\n",
            "Epoch 1/500, Generator Loss: 0.2487, Discriminator Loss: 0.1960\n",
            "Epoch 1/500, Generator Loss: 0.2480, Discriminator Loss: 0.1949\n",
            "Epoch 1/500, Generator Loss: 0.2472, Discriminator Loss: 0.1940\n",
            "Epoch 1/500, Generator Loss: 0.2466, Discriminator Loss: 0.1929\n",
            "Epoch 1/500, Generator Loss: 0.2459, Discriminator Loss: 0.1920\n",
            "Epoch 1/500, Generator Loss: 0.2453, Discriminator Loss: 0.1912\n",
            "Epoch 1/500, Generator Loss: 0.2447, Discriminator Loss: 0.1903\n",
            "Epoch 1/500, Generator Loss: 0.2443, Discriminator Loss: 0.1892\n",
            "Epoch 1/500, Generator Loss: 0.2437, Discriminator Loss: 0.1882\n",
            "Epoch 1/500, Generator Loss: 0.2430, Discriminator Loss: 0.1873\n",
            "Epoch 1/500, Generator Loss: 0.2424, Discriminator Loss: 0.1864\n",
            "Epoch 1/500, Generator Loss: 0.2418, Discriminator Loss: 0.1855\n",
            "Epoch 1/500, Generator Loss: 0.2412, Discriminator Loss: 0.1846\n",
            "Epoch 1/500, Generator Loss: 0.2406, Discriminator Loss: 0.1839\n",
            "Epoch 1/500, Generator Loss: 0.2401, Discriminator Loss: 0.1830\n",
            "Epoch 1/500, Generator Loss: 0.2395, Discriminator Loss: 0.1821\n",
            "Epoch 1/500, Generator Loss: 0.2389, Discriminator Loss: 0.1816\n",
            "Epoch 1/500, Generator Loss: 0.2384, Discriminator Loss: 0.1807\n",
            "Epoch 1/500, Generator Loss: 0.2379, Discriminator Loss: 0.1799\n",
            "Epoch 1/500, Generator Loss: 0.2374, Discriminator Loss: 0.1792\n",
            "Epoch 1/500, Generator Loss: 0.2368, Discriminator Loss: 0.1786\n",
            "Epoch 1/500, Generator Loss: 0.2363, Discriminator Loss: 0.1778\n",
            "Epoch 1/500, Generator Loss: 0.2358, Discriminator Loss: 0.1770\n",
            "Epoch 1/500, Generator Loss: 0.2354, Discriminator Loss: 0.1761\n",
            "Epoch 1/500, Generator Loss: 0.2348, Discriminator Loss: 0.1753\n",
            "Epoch 1/500, Generator Loss: 0.2344, Discriminator Loss: 0.1744\n",
            "Epoch 1/500, Generator Loss: 0.2338, Discriminator Loss: 0.1737\n",
            "Epoch 1/500, Generator Loss: 0.2334, Discriminator Loss: 0.1729\n",
            "Epoch 1/500, Generator Loss: 0.2329, Discriminator Loss: 0.1720\n",
            "Epoch 1/500, Generator Loss: 0.2323, Discriminator Loss: 0.1712\n",
            "Epoch 1/500, Generator Loss: 0.2318, Discriminator Loss: 0.1704\n",
            "Epoch 1/500, Generator Loss: 0.2313, Discriminator Loss: 0.1697\n",
            "Epoch 1/500, Generator Loss: 0.2309, Discriminator Loss: 0.1690\n",
            "Epoch 1/500, Generator Loss: 0.2304, Discriminator Loss: 0.1682\n",
            "Epoch 1/500, Generator Loss: 0.2300, Discriminator Loss: 0.1674\n",
            "Epoch 1/500, Generator Loss: 0.2295, Discriminator Loss: 0.1667\n",
            "Epoch 1/500, Generator Loss: 0.2292, Discriminator Loss: 0.1662\n",
            "Epoch 1/500, Generator Loss: 0.2288, Discriminator Loss: 0.1655\n",
            "Epoch 1/500, Generator Loss: 0.2284, Discriminator Loss: 0.1650\n",
            "Epoch 1/500, Generator Loss: 0.2280, Discriminator Loss: 0.1645\n",
            "Epoch 1/500, Generator Loss: 0.2277, Discriminator Loss: 0.1639\n",
            "Epoch 1/500, Generator Loss: 0.2273, Discriminator Loss: 0.1632\n",
            "Epoch 1/500, Generator Loss: 0.2270, Discriminator Loss: 0.1625\n",
            "Epoch 1/500, Generator Loss: 0.2267, Discriminator Loss: 0.1619\n",
            "Epoch 1/500, Generator Loss: 0.2264, Discriminator Loss: 0.1614\n",
            "Epoch 1/500, Generator Loss: 0.2260, Discriminator Loss: 0.1607\n",
            "Epoch 1/500, Generator Loss: 0.2257, Discriminator Loss: 0.1602\n",
            "Epoch 1/500, Generator Loss: 0.2253, Discriminator Loss: 0.1596\n",
            "Epoch 1/500, Generator Loss: 0.2249, Discriminator Loss: 0.1590\n",
            "Epoch 1/500, Generator Loss: 0.2245, Discriminator Loss: 0.1584\n",
            "Epoch 1/500, Generator Loss: 0.2242, Discriminator Loss: 0.1578\n",
            "Epoch 1/500, Generator Loss: 0.2239, Discriminator Loss: 0.1574\n",
            "Epoch 1/500, Generator Loss: 0.2236, Discriminator Loss: 0.1567\n",
            "Epoch 1/500, Generator Loss: 0.2233, Discriminator Loss: 0.1561\n",
            "Epoch 1/500, Generator Loss: 0.2229, Discriminator Loss: 0.1556\n",
            "Epoch 1/500, Generator Loss: 0.2226, Discriminator Loss: 0.1551\n",
            "Epoch 1/500, Generator Loss: 0.2223, Discriminator Loss: 0.1546\n",
            "Epoch 1/500, Generator Loss: 0.2220, Discriminator Loss: 0.1541\n",
            "Epoch 1/500, Generator Loss: 0.2217, Discriminator Loss: 0.1536\n",
            "Epoch 1/500, Generator Loss: 0.2214, Discriminator Loss: 0.1529\n",
            "Epoch 1/500, Generator Loss: 0.2212, Discriminator Loss: 0.1523\n",
            "Epoch 1/500, Generator Loss: 0.2208, Discriminator Loss: 0.1517\n",
            "Epoch 1/500, Generator Loss: 0.2205, Discriminator Loss: 0.1512\n",
            "Epoch 1/500, Generator Loss: 0.2201, Discriminator Loss: 0.1507\n",
            "Epoch 1/500, Generator Loss: 0.2198, Discriminator Loss: 0.1502\n",
            "Epoch 1/500, Generator Loss: 0.2194, Discriminator Loss: 0.1497\n",
            "Epoch 1/500, Generator Loss: 0.2191, Discriminator Loss: 0.1493\n",
            "Epoch 1/500, Generator Loss: 0.2188, Discriminator Loss: 0.1490\n",
            "Epoch 1/500, Generator Loss: 0.2186, Discriminator Loss: 0.1485\n",
            "Epoch 1/500, Generator Loss: 0.2183, Discriminator Loss: 0.1480\n",
            "Epoch 1/500, Generator Loss: 0.2180, Discriminator Loss: 0.1475\n",
            "Epoch 1/500, Generator Loss: 0.2177, Discriminator Loss: 0.1470\n",
            "Epoch 1/500, Generator Loss: 0.2174, Discriminator Loss: 0.1464\n",
            "Epoch 1/500, Generator Loss: 0.2171, Discriminator Loss: 0.1459\n",
            "Epoch 1/500, Generator Loss: 0.2168, Discriminator Loss: 0.1454\n",
            "Epoch 1/500, Generator Loss: 0.2166, Discriminator Loss: 0.1449\n",
            "Epoch 1/500, Generator Loss: 0.2163, Discriminator Loss: 0.1443\n",
            "Epoch 1/500, Generator Loss: 0.2160, Discriminator Loss: 0.1437\n",
            "Epoch 1/500, Generator Loss: 0.2156, Discriminator Loss: 0.1433\n",
            "Epoch 1/500, Generator Loss: 0.2154, Discriminator Loss: 0.1428\n",
            "Epoch 1/500, Generator Loss: 0.2151, Discriminator Loss: 0.1423\n",
            "Epoch 1/500, Generator Loss: 0.2148, Discriminator Loss: 0.1418\n",
            "Epoch 1/500, Generator Loss: 0.2146, Discriminator Loss: 0.1413\n",
            "Epoch 1/500, Generator Loss: 0.2143, Discriminator Loss: 0.1408\n",
            "Epoch 1/500, Generator Loss: 0.2140, Discriminator Loss: 0.1402\n",
            "Epoch 1/500, Generator Loss: 0.2138, Discriminator Loss: 0.1398\n",
            "Epoch 1/500, Generator Loss: 0.2135, Discriminator Loss: 0.1392\n",
            "Epoch 1/500, Generator Loss: 0.2132, Discriminator Loss: 0.1387\n",
            "Epoch 1/500, Generator Loss: 0.2129, Discriminator Loss: 0.1384\n",
            "Epoch 1/500, Generator Loss: 0.2127, Discriminator Loss: 0.1380\n",
            "Epoch 1/500, Generator Loss: 0.2125, Discriminator Loss: 0.1375\n",
            "Epoch 1/500, Generator Loss: 0.2122, Discriminator Loss: 0.1371\n",
            "Epoch 1/500, Generator Loss: 0.2120, Discriminator Loss: 0.1367\n",
            "Epoch 1/500, Generator Loss: 0.2117, Discriminator Loss: 0.1363\n",
            "Epoch 1/500, Generator Loss: 0.2115, Discriminator Loss: 0.1360\n",
            "Epoch 1/500, Generator Loss: 0.2112, Discriminator Loss: 0.1356\n",
            "Epoch 1/500, Generator Loss: 0.2111, Discriminator Loss: 0.1353\n",
            "Epoch 1/500, Generator Loss: 0.2108, Discriminator Loss: 0.1351\n",
            "Epoch 1/500, Generator Loss: 0.2107, Discriminator Loss: 0.1349\n",
            "Epoch 1/500, Generator Loss: 0.2105, Discriminator Loss: 0.1345\n",
            "Epoch 1/500, Generator Loss: 0.2103, Discriminator Loss: 0.1341\n",
            "Epoch 1/500, Generator Loss: 0.2101, Discriminator Loss: 0.1337\n",
            "Epoch 1/500, Generator Loss: 0.2099, Discriminator Loss: 0.1333\n",
            "Epoch 1/500, Generator Loss: 0.2097, Discriminator Loss: 0.1329\n",
            "Epoch 1/500, Generator Loss: 0.2095, Discriminator Loss: 0.1325\n",
            "Epoch 1/500, Generator Loss: 0.2093, Discriminator Loss: 0.1321\n",
            "Epoch 1/500, Generator Loss: 0.2091, Discriminator Loss: 0.1317\n",
            "Epoch 1/500, Generator Loss: 0.2089, Discriminator Loss: 0.1313\n",
            "Epoch 1/500, Generator Loss: 0.2087, Discriminator Loss: 0.1309\n",
            "Epoch 1/500, Generator Loss: 0.2085, Discriminator Loss: 0.1306\n",
            "Epoch 1/500, Generator Loss: 0.2083, Discriminator Loss: 0.1302\n",
            "Epoch 1/500, Generator Loss: 0.2081, Discriminator Loss: 0.1298\n",
            "Epoch 1/500, Generator Loss: 0.2079, Discriminator Loss: 0.1294\n",
            "Epoch 1/500, Generator Loss: 0.2076, Discriminator Loss: 0.1290\n",
            "Epoch 1/500, Generator Loss: 0.2075, Discriminator Loss: 0.1287\n",
            "Epoch 1/500, Generator Loss: 0.2073, Discriminator Loss: 0.1284\n",
            "Epoch 1/500, Generator Loss: 0.2071, Discriminator Loss: 0.1280\n",
            "Epoch 1/500, Generator Loss: 0.2069, Discriminator Loss: 0.1276\n",
            "Epoch 1/500, Generator Loss: 0.2067, Discriminator Loss: 0.1273\n",
            "Epoch 1/500, Generator Loss: 0.2065, Discriminator Loss: 0.1269\n",
            "Epoch 1/500, Generator Loss: 0.2064, Discriminator Loss: 0.1265\n",
            "Epoch 1/500, Generator Loss: 0.2062, Discriminator Loss: 0.1260\n",
            "Epoch 1/500, Generator Loss: 0.2059, Discriminator Loss: 0.1257\n",
            "Epoch 1/500, Generator Loss: 0.2057, Discriminator Loss: 0.1254\n",
            "Epoch 1/500, Generator Loss: 0.2056, Discriminator Loss: 0.1252\n",
            "Epoch 1/500, Generator Loss: 0.2055, Discriminator Loss: 0.1249\n",
            "Epoch 1/500, Generator Loss: 0.2053, Discriminator Loss: 0.1246\n",
            "Epoch 1/500, Generator Loss: 0.2051, Discriminator Loss: 0.1243\n",
            "Epoch 1/500, Generator Loss: 0.2049, Discriminator Loss: 0.1239\n",
            "Epoch 1/500, Generator Loss: 0.2046, Discriminator Loss: 0.1235\n",
            "Epoch 1/500, Generator Loss: 0.2045, Discriminator Loss: 0.1232\n",
            "Epoch 1/500, Generator Loss: 0.2043, Discriminator Loss: 0.1228\n",
            "Epoch 1/500, Generator Loss: 0.2041, Discriminator Loss: 0.1225\n",
            "Epoch 1/500, Generator Loss: 0.2039, Discriminator Loss: 0.1222\n",
            "Epoch 1/500, Generator Loss: 0.2037, Discriminator Loss: 0.1218\n",
            "Epoch 1/500, Generator Loss: 0.2035, Discriminator Loss: 0.1215\n",
            "Epoch 1/500, Generator Loss: 0.2033, Discriminator Loss: 0.1212\n",
            "Epoch 1/500, Generator Loss: 0.2031, Discriminator Loss: 0.1209\n",
            "Epoch 1/500, Generator Loss: 0.2029, Discriminator Loss: 0.1206\n",
            "Epoch 1/500, Generator Loss: 0.2027, Discriminator Loss: 0.1203\n",
            "Epoch 1/500, Generator Loss: 0.2026, Discriminator Loss: 0.1199\n",
            "Epoch 1/500, Generator Loss: 0.2024, Discriminator Loss: 0.1196\n",
            "Epoch 1/500, Generator Loss: 0.2022, Discriminator Loss: 0.1193\n",
            "Epoch 1/500, Generator Loss: 0.2020, Discriminator Loss: 0.1189\n",
            "Epoch 1/500, Generator Loss: 0.2018, Discriminator Loss: 0.1187\n",
            "Epoch 1/500, Generator Loss: 0.2016, Discriminator Loss: 0.1184\n",
            "Epoch 1/500, Generator Loss: 0.2014, Discriminator Loss: 0.1182\n",
            "Epoch 1/500, Generator Loss: 0.2012, Discriminator Loss: 0.1180\n",
            "Epoch 1/500, Generator Loss: 0.2011, Discriminator Loss: 0.1176\n",
            "Epoch 1/500, Generator Loss: 0.2009, Discriminator Loss: 0.1174\n",
            "Epoch 1/500, Generator Loss: 0.2007, Discriminator Loss: 0.1170\n",
            "Epoch 1/500, Generator Loss: 0.2006, Discriminator Loss: 0.1167\n",
            "Epoch 1/500, Generator Loss: 0.2004, Discriminator Loss: 0.1164\n",
            "Epoch 1/500, Generator Loss: 0.2002, Discriminator Loss: 0.1161\n",
            "Epoch 1/500, Generator Loss: 0.2001, Discriminator Loss: 0.1159\n",
            "Epoch 1/500, Generator Loss: 0.1999, Discriminator Loss: 0.1157\n",
            "Epoch 1/500, Generator Loss: 0.1998, Discriminator Loss: 0.1154\n",
            "Epoch 1/500, Generator Loss: 0.1996, Discriminator Loss: 0.1151\n",
            "Epoch 1/500, Generator Loss: 0.1995, Discriminator Loss: 0.1149\n",
            "Epoch 1/500, Generator Loss: 0.1994, Discriminator Loss: 0.1148\n",
            "Epoch 1/500, Generator Loss: 0.1993, Discriminator Loss: 0.1146\n",
            "Epoch 1/500, Generator Loss: 0.1991, Discriminator Loss: 0.1143\n",
            "Epoch 1/500, Generator Loss: 0.1990, Discriminator Loss: 0.1141\n",
            "Epoch 1/500, Generator Loss: 0.1989, Discriminator Loss: 0.1138\n",
            "Epoch 1/500, Generator Loss: 0.1988, Discriminator Loss: 0.1136\n",
            "Epoch 1/500, Generator Loss: 0.1987, Discriminator Loss: 0.1133\n",
            "Epoch 1/500, Generator Loss: 0.1985, Discriminator Loss: 0.1130\n",
            "Epoch 1/500, Generator Loss: 0.1984, Discriminator Loss: 0.1128\n",
            "Epoch 1/500, Generator Loss: 0.1982, Discriminator Loss: 0.1125\n",
            "Epoch 1/500, Generator Loss: 0.1981, Discriminator Loss: 0.1123\n",
            "Epoch 1/500, Generator Loss: 0.1979, Discriminator Loss: 0.1120\n",
            "Epoch 1/500, Generator Loss: 0.1978, Discriminator Loss: 0.1118\n",
            "Epoch 1/500, Generator Loss: 0.1976, Discriminator Loss: 0.1116\n",
            "Epoch 1/500, Generator Loss: 0.1975, Discriminator Loss: 0.1114\n",
            "Epoch 1/500, Generator Loss: 0.1974, Discriminator Loss: 0.1111\n",
            "Epoch 1/500, Generator Loss: 0.1973, Discriminator Loss: 0.1109\n",
            "Epoch 1/500, Generator Loss: 0.1971, Discriminator Loss: 0.1107\n",
            "Epoch 1/500, Generator Loss: 0.1970, Discriminator Loss: 0.1105\n",
            "Epoch 1/500, Generator Loss: 0.1969, Discriminator Loss: 0.1102\n",
            "Epoch 1/500, Generator Loss: 0.1968, Discriminator Loss: 0.1099\n",
            "Epoch 1/500, Generator Loss: 0.1967, Discriminator Loss: 0.1096\n",
            "Epoch 1/500, Generator Loss: 0.1965, Discriminator Loss: 0.1094\n",
            "Epoch 1/500, Generator Loss: 0.1964, Discriminator Loss: 0.1091\n",
            "Epoch 1/500, Generator Loss: 0.1962, Discriminator Loss: 0.1090\n",
            "Epoch 1/500, Generator Loss: 0.1961, Discriminator Loss: 0.1088\n",
            "Epoch 1/500, Generator Loss: 0.1959, Discriminator Loss: 0.1085\n",
            "Epoch 1/500, Generator Loss: 0.1958, Discriminator Loss: 0.1083\n",
            "Epoch 1/500, Generator Loss: 0.1957, Discriminator Loss: 0.1080\n",
            "Epoch 1/500, Generator Loss: 0.1956, Discriminator Loss: 0.1078\n",
            "Epoch 1/500, Generator Loss: 0.1954, Discriminator Loss: 0.1076\n",
            "Epoch 1/500, Generator Loss: 0.1953, Discriminator Loss: 0.1074\n",
            "Epoch 1/500, Generator Loss: 0.1952, Discriminator Loss: 0.1072\n",
            "Epoch 1/500, Generator Loss: 0.1951, Discriminator Loss: 0.1069\n",
            "Epoch 1/500, Generator Loss: 0.1950, Discriminator Loss: 0.1067\n",
            "Epoch 1/500, Generator Loss: 0.1949, Discriminator Loss: 0.1065\n",
            "Epoch 1/500, Generator Loss: 0.1947, Discriminator Loss: 0.1063\n",
            "Epoch 1/500, Generator Loss: 0.1946, Discriminator Loss: 0.1061\n",
            "Epoch 1/500, Generator Loss: 0.1945, Discriminator Loss: 0.1059\n",
            "Epoch 1/500, Generator Loss: 0.1944, Discriminator Loss: 0.1058\n",
            "Epoch 1/500, Generator Loss: 0.1943, Discriminator Loss: 0.1056\n",
            "Epoch 1/500, Generator Loss: 0.1942, Discriminator Loss: 0.1054\n",
            "Epoch 1/500, Generator Loss: 0.1941, Discriminator Loss: 0.1052\n",
            "Epoch 1/500, Generator Loss: 0.1939, Discriminator Loss: 0.1050\n",
            "Epoch 1/500, Generator Loss: 0.1938, Discriminator Loss: 0.1048\n",
            "Epoch 1/500, Generator Loss: 0.1937, Discriminator Loss: 0.1046\n",
            "Epoch 1/500, Generator Loss: 0.1936, Discriminator Loss: 0.1044\n",
            "Epoch 1/500, Generator Loss: 0.1935, Discriminator Loss: 0.1042\n",
            "Epoch 1/500, Generator Loss: 0.1934, Discriminator Loss: 0.1040\n",
            "Epoch 1/500, Generator Loss: 0.1933, Discriminator Loss: 0.1038\n",
            "Epoch 1/500, Generator Loss: 0.1932, Discriminator Loss: 0.1036\n",
            "Epoch 1/500, Generator Loss: 0.1931, Discriminator Loss: 0.1033\n",
            "Epoch 1/500, Generator Loss: 0.1930, Discriminator Loss: 0.1031\n",
            "Epoch 1/500, Generator Loss: 0.1929, Discriminator Loss: 0.1029\n",
            "Epoch 1/500, Generator Loss: 0.1927, Discriminator Loss: 0.1027\n",
            "Epoch 1/500, Generator Loss: 0.1926, Discriminator Loss: 0.1025\n",
            "Epoch 1/500, Generator Loss: 0.1925, Discriminator Loss: 0.1023\n",
            "Epoch 1/500, Generator Loss: 0.1924, Discriminator Loss: 0.1021\n",
            "Epoch 1/500, Generator Loss: 0.1923, Discriminator Loss: 0.1019\n",
            "Epoch 1/500, Generator Loss: 0.1922, Discriminator Loss: 0.1017\n",
            "Epoch 1/500, Generator Loss: 0.1920, Discriminator Loss: 0.1015\n",
            "Epoch 1/500, Generator Loss: 0.1919, Discriminator Loss: 0.1013\n",
            "Epoch 1/500, Generator Loss: 0.1918, Discriminator Loss: 0.1011\n",
            "Epoch 1/500, Generator Loss: 0.1917, Discriminator Loss: 0.1009\n",
            "Epoch 1/500, Generator Loss: 0.1916, Discriminator Loss: 0.1008\n",
            "Epoch 1/500, Generator Loss: 0.1915, Discriminator Loss: 0.1006\n",
            "Epoch 1/500, Generator Loss: 0.1914, Discriminator Loss: 0.1004\n",
            "Epoch 1/500, Generator Loss: 0.1913, Discriminator Loss: 0.1002\n",
            "Epoch 1/500, Generator Loss: 0.1912, Discriminator Loss: 0.1001\n",
            "Epoch 1/500, Generator Loss: 0.1911, Discriminator Loss: 0.0999\n",
            "Epoch 1/500, Generator Loss: 0.1910, Discriminator Loss: 0.0999\n",
            "Epoch 1/500, Generator Loss: 0.1908, Discriminator Loss: 0.0997\n",
            "Epoch 1/500, Generator Loss: 0.1907, Discriminator Loss: 0.0995\n",
            "Epoch 1/500, Generator Loss: 0.1906, Discriminator Loss: 0.0994\n",
            "Epoch 1/500, Generator Loss: 0.1905, Discriminator Loss: 0.0992\n",
            "Epoch 1/500, Generator Loss: 0.1904, Discriminator Loss: 0.0990\n",
            "Epoch 1/500, Generator Loss: 0.1903, Discriminator Loss: 0.0988\n",
            "Epoch 1/500, Generator Loss: 0.1902, Discriminator Loss: 0.0985\n",
            "Epoch 1/500, Generator Loss: 0.1901, Discriminator Loss: 0.0983\n",
            "Epoch 1/500, Generator Loss: 0.1900, Discriminator Loss: 0.0981\n",
            "Epoch 1/500, Generator Loss: 0.1899, Discriminator Loss: 0.0979\n",
            "Epoch 1/500, Generator Loss: 0.1898, Discriminator Loss: 0.0977\n",
            "Epoch 1/500, Generator Loss: 0.1897, Discriminator Loss: 0.0976\n",
            "Epoch 1/500, Generator Loss: 0.1896, Discriminator Loss: 0.0974\n",
            "Epoch 1/500, Generator Loss: 0.1895, Discriminator Loss: 0.0972\n",
            "Epoch 1/500, Generator Loss: 0.1894, Discriminator Loss: 0.0971\n",
            "Epoch 1/500, Generator Loss: 0.1893, Discriminator Loss: 0.0970\n",
            "Epoch 1/500, Generator Loss: 0.1892, Discriminator Loss: 0.0969\n",
            "Epoch 1/500, Generator Loss: 0.1891, Discriminator Loss: 0.0967\n",
            "Epoch 1/500, Generator Loss: 0.1890, Discriminator Loss: 0.0966\n",
            "Epoch 1/500, Generator Loss: 0.1889, Discriminator Loss: 0.0964\n",
            "Epoch 1/500, Generator Loss: 0.1888, Discriminator Loss: 0.0962\n",
            "Epoch 1/500, Generator Loss: 0.1887, Discriminator Loss: 0.0960\n",
            "Epoch 1/500, Generator Loss: 0.1886, Discriminator Loss: 0.0958\n",
            "Epoch 1/500, Generator Loss: 0.1886, Discriminator Loss: 0.0956\n",
            "Epoch 1/500, Generator Loss: 0.1885, Discriminator Loss: 0.0954\n",
            "Epoch 1/500, Generator Loss: 0.1884, Discriminator Loss: 0.0953\n",
            "Epoch 1/500, Generator Loss: 0.1883, Discriminator Loss: 0.0951\n",
            "Epoch 1/500, Generator Loss: 0.1882, Discriminator Loss: 0.0949\n",
            "Epoch 1/500, Generator Loss: 0.1881, Discriminator Loss: 0.0947\n",
            "Epoch 1/500, Generator Loss: 0.1880, Discriminator Loss: 0.0946\n",
            "Epoch 1/500, Generator Loss: 0.1879, Discriminator Loss: 0.0944\n",
            "Epoch 1/500, Generator Loss: 0.1878, Discriminator Loss: 0.0942\n",
            "Epoch 1/500, Generator Loss: 0.1877, Discriminator Loss: 0.0941\n",
            "Epoch 1/500, Generator Loss: 0.1876, Discriminator Loss: 0.0939\n",
            "Epoch 1/500, Generator Loss: 0.1875, Discriminator Loss: 0.0938\n",
            "Epoch 1/500, Generator Loss: 0.1874, Discriminator Loss: 0.0936\n",
            "Epoch 1/500, Generator Loss: 0.1873, Discriminator Loss: 0.0937\n",
            "Epoch 1/500, Generator Loss: 0.1872, Discriminator Loss: 0.0935\n",
            "Epoch 1/500, Generator Loss: 0.1872, Discriminator Loss: 0.0935\n",
            "Epoch 1/500, Generator Loss: 0.1871, Discriminator Loss: 0.0935\n",
            "Epoch 1/500, Generator Loss: 0.1871, Discriminator Loss: 0.0934\n",
            "Epoch 1/500, Generator Loss: 0.1870, Discriminator Loss: 0.0933\n",
            "Epoch 1/500, Generator Loss: 0.1869, Discriminator Loss: 0.0931\n",
            "Epoch 1/500, Generator Loss: 0.1869, Discriminator Loss: 0.0929\n",
            "Epoch 1/500, Generator Loss: 0.1868, Discriminator Loss: 0.0928\n",
            "Epoch 1/500, Generator Loss: 0.1867, Discriminator Loss: 0.0926\n",
            "Epoch 1/500, Generator Loss: 0.1866, Discriminator Loss: 0.0924\n",
            "Epoch 1/500, Generator Loss: 0.1865, Discriminator Loss: 0.0922\n",
            "Epoch 1/500, Generator Loss: 0.1864, Discriminator Loss: 0.0920\n",
            "Epoch 1/500, Generator Loss: 0.1863, Discriminator Loss: 0.0919\n",
            "Epoch 1/500, Generator Loss: 0.1862, Discriminator Loss: 0.0917\n",
            "Epoch 1/500, Generator Loss: 0.1862, Discriminator Loss: 0.0916\n",
            "Epoch 1/500, Generator Loss: 0.1861, Discriminator Loss: 0.0914\n",
            "Epoch 1/500, Generator Loss: 0.1860, Discriminator Loss: 0.0913\n",
            "Epoch 1/500, Generator Loss: 0.1859, Discriminator Loss: 0.0911\n",
            "Epoch 1/500, Generator Loss: 0.1858, Discriminator Loss: 0.0910\n",
            "Epoch 1/500, Generator Loss: 0.1858, Discriminator Loss: 0.0908\n",
            "Epoch 1/500, Generator Loss: 0.1857, Discriminator Loss: 0.0906\n",
            "Epoch 1/500, Generator Loss: 0.1856, Discriminator Loss: 0.0905\n",
            "Epoch 1/500, Generator Loss: 0.1855, Discriminator Loss: 0.0904\n",
            "Epoch 1/500, Generator Loss: 0.1854, Discriminator Loss: 0.0902\n",
            "Epoch 1/500, Generator Loss: 0.1853, Discriminator Loss: 0.0901\n",
            "Epoch 1/500, Generator Loss: 0.1852, Discriminator Loss: 0.0899\n",
            "Epoch 1/500, Generator Loss: 0.1851, Discriminator Loss: 0.0898\n",
            "Epoch 1/500, Generator Loss: 0.1851, Discriminator Loss: 0.0896\n",
            "Epoch 1/500, Generator Loss: 0.1850, Discriminator Loss: 0.0895\n",
            "Epoch 1/500, Generator Loss: 0.1849, Discriminator Loss: 0.0893\n",
            "Epoch 1/500, Generator Loss: 0.1849, Discriminator Loss: 0.0892\n",
            "Epoch 1/500, Generator Loss: 0.1848, Discriminator Loss: 0.0890\n",
            "Epoch 1/500, Generator Loss: 0.1847, Discriminator Loss: 0.0889\n",
            "Epoch 1/500, Generator Loss: 0.1846, Discriminator Loss: 0.0887\n",
            "Epoch 1/500, Generator Loss: 0.1845, Discriminator Loss: 0.0885\n",
            "Epoch 1/500, Generator Loss: 0.1845, Discriminator Loss: 0.0884\n",
            "Epoch 1/500, Generator Loss: 0.1844, Discriminator Loss: 0.0882\n",
            "Epoch 1/500, Generator Loss: 0.1843, Discriminator Loss: 0.0881\n",
            "Epoch 1/500, Generator Loss: 0.1842, Discriminator Loss: 0.0879\n",
            "Epoch 1/500, Generator Loss: 0.1842, Discriminator Loss: 0.0878\n",
            "Epoch 1/500, Generator Loss: 0.1841, Discriminator Loss: 0.0876\n",
            "Epoch 1/500, Generator Loss: 0.1840, Discriminator Loss: 0.0875\n",
            "Epoch 1/500, Generator Loss: 0.1840, Discriminator Loss: 0.0874\n",
            "Epoch 1/500, Generator Loss: 0.1840, Discriminator Loss: 0.0873\n",
            "Epoch 1/500, Generator Loss: 0.1839, Discriminator Loss: 0.0872\n",
            "Epoch 1/500, Generator Loss: 0.1839, Discriminator Loss: 0.0872\n",
            "Epoch 1/500, Generator Loss: 0.1838, Discriminator Loss: 0.0871\n",
            "Epoch 1/500, Generator Loss: 0.1838, Discriminator Loss: 0.0869\n",
            "Epoch 1/500, Generator Loss: 0.1837, Discriminator Loss: 0.0868\n",
            "Epoch 1/500, Generator Loss: 0.1836, Discriminator Loss: 0.0867\n",
            "Epoch 1/500, Generator Loss: 0.1836, Discriminator Loss: 0.0865\n",
            "Epoch 1/500, Generator Loss: 0.1835, Discriminator Loss: 0.0864\n",
            "Epoch 1/500, Generator Loss: 0.1834, Discriminator Loss: 0.0863\n",
            "Epoch 1/500, Generator Loss: 0.1833, Discriminator Loss: 0.0861\n",
            "Epoch 1/500, Generator Loss: 0.1833, Discriminator Loss: 0.0860\n",
            "Epoch 1/500, Generator Loss: 0.1832, Discriminator Loss: 0.0859\n",
            "Epoch 1/500, Generator Loss: 0.1831, Discriminator Loss: 0.0857\n",
            "Epoch 1/500, Generator Loss: 0.1830, Discriminator Loss: 0.0856\n",
            "Epoch 1/500, Generator Loss: 0.1830, Discriminator Loss: 0.0854\n",
            "Epoch 1/500, Generator Loss: 0.1829, Discriminator Loss: 0.0853\n",
            "Epoch 1/500, Generator Loss: 0.1828, Discriminator Loss: 0.0851\n",
            "Epoch 1/500, Generator Loss: 0.1827, Discriminator Loss: 0.0850\n",
            "Epoch 1/500, Generator Loss: 0.1826, Discriminator Loss: 0.0849\n",
            "Epoch 1/500, Generator Loss: 0.1826, Discriminator Loss: 0.0847\n",
            "Epoch 1/500, Generator Loss: 0.1825, Discriminator Loss: 0.0846\n",
            "Epoch 1/500, Generator Loss: 0.1824, Discriminator Loss: 0.0844\n",
            "Epoch 1/500, Generator Loss: 0.1824, Discriminator Loss: 0.0843\n",
            "Epoch 1/500, Generator Loss: 0.1823, Discriminator Loss: 0.0842\n",
            "Epoch 1/500, Generator Loss: 0.1822, Discriminator Loss: 0.0842\n",
            "Epoch 1/500, Generator Loss: 0.1822, Discriminator Loss: 0.0840\n",
            "Epoch 1/500, Generator Loss: 0.1821, Discriminator Loss: 0.0840\n",
            "Epoch 1/500, Generator Loss: 0.1821, Discriminator Loss: 0.0839\n",
            "Epoch 1/500, Generator Loss: 0.1820, Discriminator Loss: 0.0838\n",
            "Epoch 1/500, Generator Loss: 0.1820, Discriminator Loss: 0.0837\n",
            "Epoch 1/500, Generator Loss: 0.1819, Discriminator Loss: 0.0836\n",
            "Epoch 1/500, Generator Loss: 0.1819, Discriminator Loss: 0.0835\n",
            "Epoch 1/500, Generator Loss: 0.1818, Discriminator Loss: 0.0834\n",
            "Epoch 1/500, Generator Loss: 0.1817, Discriminator Loss: 0.0832\n",
            "Epoch 1/500, Generator Loss: 0.1817, Discriminator Loss: 0.0831\n",
            "Epoch 1/500, Generator Loss: 0.1816, Discriminator Loss: 0.0830\n",
            "Epoch 1/500, Generator Loss: 0.1816, Discriminator Loss: 0.0828\n",
            "Epoch 1/500, Generator Loss: 0.1815, Discriminator Loss: 0.0827\n",
            "Epoch 1/500, Generator Loss: 0.1814, Discriminator Loss: 0.0825\n",
            "Epoch 1/500, Generator Loss: 0.1814, Discriminator Loss: 0.0824\n",
            "Epoch 1/500, Generator Loss: 0.1813, Discriminator Loss: 0.0823\n",
            "Epoch 1/500, Generator Loss: 0.1813, Discriminator Loss: 0.0822\n",
            "Epoch 1/500, Generator Loss: 0.1812, Discriminator Loss: 0.0821\n",
            "Epoch 1/500, Generator Loss: 0.1812, Discriminator Loss: 0.0820\n",
            "Epoch 1/500, Generator Loss: 0.1811, Discriminator Loss: 0.0819\n",
            "Epoch 1/500, Generator Loss: 0.1810, Discriminator Loss: 0.0818\n",
            "Epoch 1/500, Generator Loss: 0.1810, Discriminator Loss: 0.0817\n",
            "Epoch 1/500, Generator Loss: 0.1809, Discriminator Loss: 0.0816\n",
            "Epoch 1/500, Generator Loss: 0.1808, Discriminator Loss: 0.0815\n",
            "Epoch 1/500, Generator Loss: 0.1808, Discriminator Loss: 0.0814\n",
            "Epoch 1/500, Generator Loss: 0.1807, Discriminator Loss: 0.0813\n",
            "Epoch 1/500, Generator Loss: 0.1806, Discriminator Loss: 0.0811\n",
            "Epoch 1/500, Generator Loss: 0.1806, Discriminator Loss: 0.0810\n",
            "Epoch 1/500, Generator Loss: 0.1805, Discriminator Loss: 0.0809\n",
            "Epoch 1/500, Generator Loss: 0.1804, Discriminator Loss: 0.0808\n",
            "Epoch 1/500, Generator Loss: 0.1804, Discriminator Loss: 0.0806\n",
            "Epoch 1/500, Generator Loss: 0.1803, Discriminator Loss: 0.0805\n",
            "Epoch 1/500, Generator Loss: 0.1803, Discriminator Loss: 0.0804\n",
            "Epoch 1/500, Generator Loss: 0.1802, Discriminator Loss: 0.0803\n",
            "Epoch 1/500, Generator Loss: 0.1801, Discriminator Loss: 0.0802\n",
            "Epoch 1/500, Generator Loss: 0.1801, Discriminator Loss: 0.0801\n",
            "Epoch 1/500, Generator Loss: 0.1800, Discriminator Loss: 0.0799\n",
            "Epoch 1/500, Generator Loss: 0.1800, Discriminator Loss: 0.0798\n",
            "Epoch 1/500, Generator Loss: 0.1799, Discriminator Loss: 0.0797\n",
            "Epoch 1/500, Generator Loss: 0.1798, Discriminator Loss: 0.0796\n",
            "Epoch 1/500, Generator Loss: 0.1798, Discriminator Loss: 0.0795\n",
            "Epoch 1/500, Generator Loss: 0.1797, Discriminator Loss: 0.0793\n",
            "Epoch 1/500, Generator Loss: 0.1797, Discriminator Loss: 0.0792\n",
            "Epoch 1/500, Generator Loss: 0.1796, Discriminator Loss: 0.0791\n",
            "Epoch 1/500, Generator Loss: 0.1795, Discriminator Loss: 0.0790\n",
            "Epoch 1/500, Generator Loss: 0.1795, Discriminator Loss: 0.0789\n",
            "Epoch 1/500, Generator Loss: 0.1794, Discriminator Loss: 0.0788\n",
            "Epoch 1/500, Generator Loss: 0.1793, Discriminator Loss: 0.0787\n",
            "Epoch 1/500, Generator Loss: 0.1793, Discriminator Loss: 0.0786\n",
            "Epoch 1/500, Generator Loss: 0.1792, Discriminator Loss: 0.0785\n",
            "Epoch 1/500, Generator Loss: 0.1792, Discriminator Loss: 0.0784\n",
            "Epoch 1/500, Generator Loss: 0.1791, Discriminator Loss: 0.0783\n",
            "Epoch 1/500, Generator Loss: 0.1791, Discriminator Loss: 0.0782\n",
            "Epoch 1/500, Generator Loss: 0.1790, Discriminator Loss: 0.0781\n",
            "Epoch 1/500, Generator Loss: 0.1789, Discriminator Loss: 0.0779\n",
            "Epoch 1/500, Generator Loss: 0.1789, Discriminator Loss: 0.0778\n",
            "Epoch 1/500, Generator Loss: 0.1788, Discriminator Loss: 0.0777\n",
            "Epoch 1/500, Generator Loss: 0.1787, Discriminator Loss: 0.0776\n",
            "Epoch 1/500, Generator Loss: 0.1787, Discriminator Loss: 0.0776\n",
            "Epoch 1/500, Generator Loss: 0.1786, Discriminator Loss: 0.0776\n",
            "Epoch 1/500, Generator Loss: 0.1786, Discriminator Loss: 0.0775\n",
            "Epoch 1/500, Generator Loss: 0.1785, Discriminator Loss: 0.0774\n",
            "Epoch 1/500, Generator Loss: 0.1785, Discriminator Loss: 0.0772\n",
            "Epoch 1/500, Generator Loss: 0.1784, Discriminator Loss: 0.0771\n",
            "Epoch 1/500, Generator Loss: 0.1784, Discriminator Loss: 0.0770\n",
            "Epoch 1/500, Generator Loss: 0.1783, Discriminator Loss: 0.0769\n",
            "Epoch 1/500, Generator Loss: 0.1783, Discriminator Loss: 0.0768\n",
            "Epoch 1/500, Generator Loss: 0.1782, Discriminator Loss: 0.0767\n",
            "Epoch 1/500, Generator Loss: 0.1781, Discriminator Loss: 0.0766\n",
            "Epoch 1/500, Generator Loss: 0.1781, Discriminator Loss: 0.0765\n",
            "Epoch 1/500, Generator Loss: 0.1780, Discriminator Loss: 0.0764\n",
            "Epoch 1/500, Generator Loss: 0.1779, Discriminator Loss: 0.0763\n",
            "Epoch 1/500, Generator Loss: 0.1779, Discriminator Loss: 0.0762\n",
            "Epoch 1/500, Generator Loss: 0.1778, Discriminator Loss: 0.0761\n",
            "Epoch 1/500, Generator Loss: 0.1777, Discriminator Loss: 0.0760\n",
            "Epoch 1/500, Generator Loss: 0.1777, Discriminator Loss: 0.0759\n",
            "Epoch 1/500, Generator Loss: 0.1776, Discriminator Loss: 0.0758\n",
            "Epoch 1/500, Generator Loss: 0.1776, Discriminator Loss: 0.0757\n",
            "Epoch 1/500, Generator Loss: 0.1775, Discriminator Loss: 0.0756\n",
            "Epoch 1/500, Generator Loss: 0.1775, Discriminator Loss: 0.0755\n",
            "Epoch 1/500, Generator Loss: 0.1774, Discriminator Loss: 0.0755\n",
            "Epoch 1/500, Generator Loss: 0.1774, Discriminator Loss: 0.0754\n",
            "Epoch 1/500, Generator Loss: 0.1773, Discriminator Loss: 0.0753\n",
            "Epoch 1/500, Generator Loss: 0.1773, Discriminator Loss: 0.0752\n",
            "Epoch 1/500, Generator Loss: 0.1772, Discriminator Loss: 0.0751\n",
            "Epoch 1/500, Generator Loss: 0.1772, Discriminator Loss: 0.0750\n",
            "Epoch 1/500, Generator Loss: 0.1771, Discriminator Loss: 0.0749\n",
            "Epoch 1/500, Generator Loss: 0.1771, Discriminator Loss: 0.0748\n",
            "Epoch 1/500, Generator Loss: 0.1770, Discriminator Loss: 0.0747\n",
            "Epoch 1/500, Generator Loss: 0.1769, Discriminator Loss: 0.0746\n",
            "Epoch 1/500, Generator Loss: 0.1769, Discriminator Loss: 0.0745\n",
            "Epoch 1/500, Generator Loss: 0.1768, Discriminator Loss: 0.0744\n",
            "Epoch 1/500, Generator Loss: 0.1768, Discriminator Loss: 0.0743\n",
            "Epoch 1/500, Generator Loss: 0.1767, Discriminator Loss: 0.0742\n",
            "Epoch 1/500, Generator Loss: 0.1767, Discriminator Loss: 0.0741\n",
            "Epoch 1/500, Generator Loss: 0.1766, Discriminator Loss: 0.0740\n",
            "Epoch 1/500, Generator Loss: 0.1765, Discriminator Loss: 0.0740\n",
            "Epoch 1/500, Generator Loss: 0.1765, Discriminator Loss: 0.0739\n",
            "Epoch 1/500, Generator Loss: 0.1764, Discriminator Loss: 0.0738\n",
            "Epoch 1/500, Generator Loss: 0.1764, Discriminator Loss: 0.0737\n",
            "Epoch 1/500, Generator Loss: 0.1763, Discriminator Loss: 0.0736\n",
            "Epoch 1/500, Generator Loss: 0.1763, Discriminator Loss: 0.0735\n",
            "Epoch 1/500, Generator Loss: 0.1762, Discriminator Loss: 0.0734\n",
            "Epoch 1/500, Generator Loss: 0.1761, Discriminator Loss: 0.0733\n",
            "Epoch 1/500, Generator Loss: 0.1761, Discriminator Loss: 0.0733\n",
            "Epoch 1/500, Generator Loss: 0.1760, Discriminator Loss: 0.0732\n",
            "Epoch 1/500, Generator Loss: 0.1760, Discriminator Loss: 0.0731\n",
            "Epoch 1/500, Generator Loss: 0.1759, Discriminator Loss: 0.0730\n",
            "Epoch 1/500, Generator Loss: 0.1759, Discriminator Loss: 0.0730\n",
            "Epoch 1/500, Generator Loss: 0.1758, Discriminator Loss: 0.0729\n",
            "Epoch 1/500, Generator Loss: 0.1758, Discriminator Loss: 0.0728\n",
            "Epoch 1/500, Generator Loss: 0.1757, Discriminator Loss: 0.0727\n",
            "Epoch 1/500, Generator Loss: 0.1756, Discriminator Loss: 0.0726\n",
            "Epoch 1/500, Generator Loss: 0.1756, Discriminator Loss: 0.0725\n",
            "Epoch 1/500, Generator Loss: 0.1755, Discriminator Loss: 0.0724\n",
            "Epoch 1/500, Generator Loss: 0.1755, Discriminator Loss: 0.0724\n",
            "Epoch 1/500, Generator Loss: 0.1755, Discriminator Loss: 0.0723\n",
            "Epoch 1/500, Generator Loss: 0.1754, Discriminator Loss: 0.0722\n",
            "Epoch 1/500, Generator Loss: 0.1754, Discriminator Loss: 0.0722\n",
            "Epoch 1/500, Generator Loss: 0.1754, Discriminator Loss: 0.0721\n",
            "Epoch 1/500, Generator Loss: 0.1753, Discriminator Loss: 0.0720\n",
            "Epoch 1/500, Generator Loss: 0.1753, Discriminator Loss: 0.0719\n",
            "Epoch 1/500, Generator Loss: 0.1752, Discriminator Loss: 0.0718\n",
            "Epoch 1/500, Generator Loss: 0.1752, Discriminator Loss: 0.0718\n",
            "Epoch 1/500, Generator Loss: 0.1752, Discriminator Loss: 0.0717\n",
            "Epoch 1/500, Generator Loss: 0.1751, Discriminator Loss: 0.0716\n",
            "Epoch 1/500, Generator Loss: 0.1751, Discriminator Loss: 0.0715\n",
            "Epoch 1/500, Generator Loss: 0.1750, Discriminator Loss: 0.0714\n",
            "Epoch 1/500, Generator Loss: 0.1750, Discriminator Loss: 0.0714\n",
            "Epoch 1/500, Generator Loss: 0.1749, Discriminator Loss: 0.0713\n",
            "Epoch 1/500, Generator Loss: 0.1748, Discriminator Loss: 0.0712\n",
            "Epoch 1/500, Generator Loss: 0.1748, Discriminator Loss: 0.0712\n",
            "Epoch 1/500, Generator Loss: 0.1748, Discriminator Loss: 0.0711\n",
            "Epoch 1/500, Generator Loss: 0.1747, Discriminator Loss: 0.0711\n",
            "Epoch 1/500, Generator Loss: 0.1747, Discriminator Loss: 0.0710\n",
            "Epoch 1/500, Generator Loss: 0.1746, Discriminator Loss: 0.0709\n",
            "Epoch 1/500, Generator Loss: 0.1746, Discriminator Loss: 0.0708\n",
            "Epoch 1/500, Generator Loss: 0.1745, Discriminator Loss: 0.0707\n",
            "Epoch 1/500, Generator Loss: 0.1745, Discriminator Loss: 0.0706\n",
            "Epoch 1/500, Generator Loss: 0.1745, Discriminator Loss: 0.0706\n",
            "Epoch 1/500, Generator Loss: 0.1744, Discriminator Loss: 0.0705\n",
            "Epoch 1/500, Generator Loss: 0.1744, Discriminator Loss: 0.0704\n",
            "Epoch 1/500, Generator Loss: 0.1743, Discriminator Loss: 0.0703\n",
            "Epoch 1/500, Generator Loss: 0.1743, Discriminator Loss: 0.0702\n",
            "Epoch 1/500, Generator Loss: 0.1742, Discriminator Loss: 0.0701\n",
            "Epoch 1/500, Generator Loss: 0.1742, Discriminator Loss: 0.0700\n",
            "Epoch 1/500, Generator Loss: 0.1741, Discriminator Loss: 0.0700\n",
            "Epoch 1/500, Generator Loss: 0.1741, Discriminator Loss: 0.0699\n",
            "Epoch 1/500, Generator Loss: 0.1740, Discriminator Loss: 0.0698\n",
            "Epoch 1/500, Generator Loss: 0.1740, Discriminator Loss: 0.0697\n",
            "Epoch 1/500, Generator Loss: 0.1739, Discriminator Loss: 0.0697\n",
            "Epoch 1/500, Generator Loss: 0.1739, Discriminator Loss: 0.0696\n",
            "Epoch 1/500, Generator Loss: 0.1739, Discriminator Loss: 0.0695\n",
            "Epoch 1/500, Generator Loss: 0.1738, Discriminator Loss: 0.0694\n",
            "Epoch 1/500, Generator Loss: 0.1738, Discriminator Loss: 0.0693\n",
            "Epoch 1/500, Generator Loss: 0.1737, Discriminator Loss: 0.0693\n",
            "Epoch 1/500, Generator Loss: 0.1737, Discriminator Loss: 0.0692\n",
            "Epoch 1/500, Generator Loss: 0.1736, Discriminator Loss: 0.0692\n",
            "Epoch 1/500, Generator Loss: 0.1736, Discriminator Loss: 0.0691\n",
            "Epoch 1/500, Generator Loss: 0.1736, Discriminator Loss: 0.0690\n",
            "Epoch 1/500, Generator Loss: 0.1735, Discriminator Loss: 0.0689\n",
            "Epoch 1/500, Generator Loss: 0.1735, Discriminator Loss: 0.0688\n",
            "Epoch 1/500, Generator Loss: 0.1734, Discriminator Loss: 0.0688\n",
            "Epoch 1/500, Generator Loss: 0.1734, Discriminator Loss: 0.0687\n",
            "Epoch 1/500, Generator Loss: 0.1733, Discriminator Loss: 0.0686\n",
            "Epoch 1/500, Generator Loss: 0.1733, Discriminator Loss: 0.0685\n",
            "Epoch 1/500, Generator Loss: 0.1732, Discriminator Loss: 0.0684\n",
            "Epoch 1/500, Generator Loss: 0.1732, Discriminator Loss: 0.0684\n",
            "Epoch 1/500, Generator Loss: 0.1731, Discriminator Loss: 0.0683\n",
            "Epoch 1/500, Generator Loss: 0.1731, Discriminator Loss: 0.0682\n",
            "Epoch 1/500, Generator Loss: 0.1730, Discriminator Loss: 0.0681\n",
            "Epoch 1/500, Generator Loss: 0.1730, Discriminator Loss: 0.0681\n",
            "Epoch 1/500, Generator Loss: 0.1729, Discriminator Loss: 0.0680\n",
            "Epoch 1/500, Generator Loss: 0.1729, Discriminator Loss: 0.0679\n",
            "Epoch 1/500, Generator Loss: 0.1728, Discriminator Loss: 0.0679\n",
            "Epoch 1/500, Generator Loss: 0.1728, Discriminator Loss: 0.0678\n",
            "Epoch 1/500, Generator Loss: 0.1727, Discriminator Loss: 0.0677\n",
            "Epoch 1/500, Generator Loss: 0.1727, Discriminator Loss: 0.0677\n",
            "Epoch 1/500, Generator Loss: 0.1726, Discriminator Loss: 0.0676\n",
            "Epoch 1/500, Generator Loss: 0.1726, Discriminator Loss: 0.0676\n",
            "Epoch 1/500, Generator Loss: 0.1725, Discriminator Loss: 0.0675\n",
            "Epoch 1/500, Generator Loss: 0.1725, Discriminator Loss: 0.0675\n",
            "Epoch 1/500, Generator Loss: 0.1725, Discriminator Loss: 0.0674\n",
            "Epoch 1/500, Generator Loss: 0.1724, Discriminator Loss: 0.0674\n",
            "Epoch 1/500, Generator Loss: 0.1724, Discriminator Loss: 0.0673\n",
            "Epoch 1/500, Generator Loss: 0.1724, Discriminator Loss: 0.0672\n",
            "Epoch 1/500, Generator Loss: 0.1723, Discriminator Loss: 0.0672\n",
            "Epoch 1/500, Generator Loss: 0.1723, Discriminator Loss: 0.0672\n",
            "Epoch 1/500, Generator Loss: 0.1723, Discriminator Loss: 0.0672\n",
            "Epoch 1/500, Generator Loss: 0.1722, Discriminator Loss: 0.0671\n",
            "Epoch 1/500, Generator Loss: 0.1722, Discriminator Loss: 0.0670\n",
            "Epoch 1/500, Generator Loss: 0.1721, Discriminator Loss: 0.0670\n",
            "Epoch 1/500, Generator Loss: 0.1721, Discriminator Loss: 0.0669\n",
            "Epoch 1/500, Generator Loss: 0.1721, Discriminator Loss: 0.0668\n",
            "Epoch 1/500, Generator Loss: 0.1720, Discriminator Loss: 0.0668\n",
            "Epoch 1/500, Generator Loss: 0.1720, Discriminator Loss: 0.0667\n",
            "Epoch 1/500, Generator Loss: 0.1719, Discriminator Loss: 0.0666\n",
            "Epoch 1/500, Generator Loss: 0.1719, Discriminator Loss: 0.0666\n",
            "Epoch 1/500, Generator Loss: 0.1719, Discriminator Loss: 0.0665\n",
            "Epoch 1/500, Generator Loss: 0.1718, Discriminator Loss: 0.0664\n",
            "Epoch 1/500, Generator Loss: 0.1718, Discriminator Loss: 0.0664\n",
            "Epoch 1/500, Generator Loss: 0.1717, Discriminator Loss: 0.0663\n",
            "Epoch 1/500, Generator Loss: 0.1717, Discriminator Loss: 0.0662\n",
            "Epoch 1/500, Generator Loss: 0.1716, Discriminator Loss: 0.0662\n",
            "Epoch 1/500, Generator Loss: 0.1716, Discriminator Loss: 0.0661\n",
            "Epoch 1/500, Generator Loss: 0.1715, Discriminator Loss: 0.0661\n",
            "Epoch 1/500, Generator Loss: 0.1715, Discriminator Loss: 0.0660\n",
            "Epoch 1/500, Generator Loss: 0.1715, Discriminator Loss: 0.0659\n",
            "Epoch 1/500, Generator Loss: 0.1714, Discriminator Loss: 0.0659\n",
            "Epoch 1/500, Generator Loss: 0.1714, Discriminator Loss: 0.0658\n",
            "Epoch 1/500, Generator Loss: 0.1713, Discriminator Loss: 0.0658\n",
            "Epoch 1/500, Generator Loss: 0.1713, Discriminator Loss: 0.0657\n",
            "Epoch 1/500, Generator Loss: 0.1713, Discriminator Loss: 0.0657\n",
            "Epoch 1/500, Generator Loss: 0.1712, Discriminator Loss: 0.0656\n",
            "Epoch 1/500, Generator Loss: 0.1712, Discriminator Loss: 0.0655\n",
            "Epoch 1/500, Generator Loss: 0.1711, Discriminator Loss: 0.0655\n",
            "Epoch 1/500, Generator Loss: 0.1711, Discriminator Loss: 0.0654\n",
            "Epoch 1/500, Generator Loss: 0.1711, Discriminator Loss: 0.0653\n",
            "Epoch 1/500, Generator Loss: 0.1710, Discriminator Loss: 0.0653\n",
            "Epoch 1/500, Generator Loss: 0.1710, Discriminator Loss: 0.0652\n",
            "Epoch 1/500, Generator Loss: 0.1709, Discriminator Loss: 0.0652\n",
            "Epoch 1/500, Generator Loss: 0.1709, Discriminator Loss: 0.0651\n",
            "Epoch 1/500, Generator Loss: 0.1709, Discriminator Loss: 0.0650\n",
            "Epoch 1/500, Generator Loss: 0.1708, Discriminator Loss: 0.0650\n",
            "Epoch 1/500, Generator Loss: 0.1708, Discriminator Loss: 0.0649\n",
            "Epoch 1/500, Generator Loss: 0.1708, Discriminator Loss: 0.0648\n",
            "Epoch 1/500, Generator Loss: 0.1707, Discriminator Loss: 0.0648\n",
            "Epoch 1/500, Generator Loss: 0.1707, Discriminator Loss: 0.0647\n",
            "Epoch 1/500, Generator Loss: 0.1706, Discriminator Loss: 0.0647\n",
            "Epoch 1/500, Generator Loss: 0.1706, Discriminator Loss: 0.0646\n",
            "Epoch 1/500, Generator Loss: 0.1706, Discriminator Loss: 0.0646\n",
            "Epoch 1/500, Generator Loss: 0.1705, Discriminator Loss: 0.0645\n",
            "Epoch 1/500, Generator Loss: 0.1705, Discriminator Loss: 0.0644\n",
            "Epoch 1/500, Generator Loss: 0.1705, Discriminator Loss: 0.0644\n",
            "Epoch 1/500, Generator Loss: 0.1704, Discriminator Loss: 0.0643\n",
            "Epoch 1/500, Generator Loss: 0.1704, Discriminator Loss: 0.0642\n",
            "Epoch 1/500, Generator Loss: 0.1704, Discriminator Loss: 0.0642\n",
            "Epoch 1/500, Generator Loss: 0.1703, Discriminator Loss: 0.0641\n",
            "Epoch 1/500, Generator Loss: 0.1703, Discriminator Loss: 0.0641\n",
            "Epoch 1/500, Generator Loss: 0.1703, Discriminator Loss: 0.0640\n",
            "Epoch 1/500, Generator Loss: 0.1702, Discriminator Loss: 0.0639\n",
            "Epoch 1/500, Generator Loss: 0.1702, Discriminator Loss: 0.0639\n",
            "Epoch 1/500, Generator Loss: 0.1701, Discriminator Loss: 0.0638\n",
            "Epoch 1/500, Generator Loss: 0.1701, Discriminator Loss: 0.0638\n",
            "Epoch 1/500, Generator Loss: 0.1701, Discriminator Loss: 0.0637\n",
            "Epoch 1/500, Generator Loss: 0.1700, Discriminator Loss: 0.0637\n",
            "Epoch 1/500, Generator Loss: 0.1700, Discriminator Loss: 0.0637\n",
            "Epoch 1/500, Generator Loss: 0.1700, Discriminator Loss: 0.0636\n",
            "Epoch 1/500, Generator Loss: 0.1699, Discriminator Loss: 0.0636\n",
            "Epoch 1/500, Generator Loss: 0.1699, Discriminator Loss: 0.0635\n",
            "Epoch 1/500, Generator Loss: 0.1698, Discriminator Loss: 0.0635\n",
            "Epoch 1/500, Generator Loss: 0.1698, Discriminator Loss: 0.0634\n",
            "Epoch 1/500, Generator Loss: 0.1698, Discriminator Loss: 0.0633\n",
            "Epoch 1/500, Generator Loss: 0.1697, Discriminator Loss: 0.0633\n",
            "Epoch 1/500, Generator Loss: 0.1697, Discriminator Loss: 0.0632\n",
            "Epoch 1/500, Generator Loss: 0.1696, Discriminator Loss: 0.0632\n",
            "Epoch 1/500, Generator Loss: 0.1696, Discriminator Loss: 0.0631\n",
            "Epoch 1/500, Generator Loss: 0.1696, Discriminator Loss: 0.0631\n",
            "Epoch 1/500, Generator Loss: 0.1695, Discriminator Loss: 0.0630\n",
            "Epoch 1/500, Generator Loss: 0.1695, Discriminator Loss: 0.0629\n",
            "Epoch 1/500, Generator Loss: 0.1695, Discriminator Loss: 0.0629\n",
            "Epoch 1/500, Generator Loss: 0.1694, Discriminator Loss: 0.0628\n",
            "Epoch 1/500, Generator Loss: 0.1694, Discriminator Loss: 0.0628\n",
            "Epoch 1/500, Generator Loss: 0.1694, Discriminator Loss: 0.0627\n",
            "Epoch 1/500, Generator Loss: 0.1693, Discriminator Loss: 0.0626\n",
            "Epoch 1/500, Generator Loss: 0.1693, Discriminator Loss: 0.0626\n",
            "Epoch 1/500, Generator Loss: 0.1693, Discriminator Loss: 0.0625\n",
            "Epoch 1/500, Generator Loss: 0.1692, Discriminator Loss: 0.0625\n",
            "Epoch 1/500, Generator Loss: 0.1692, Discriminator Loss: 0.0624\n",
            "Epoch 1/500, Generator Loss: 0.1691, Discriminator Loss: 0.0623\n",
            "Epoch 1/500, Generator Loss: 0.1691, Discriminator Loss: 0.0623\n",
            "Epoch 1/500, Generator Loss: 0.1691, Discriminator Loss: 0.0622\n",
            "Epoch 1/500, Generator Loss: 0.1690, Discriminator Loss: 0.0622\n",
            "Epoch 1/500, Generator Loss: 0.1690, Discriminator Loss: 0.0622\n",
            "Epoch 1/500, Generator Loss: 0.1690, Discriminator Loss: 0.0621\n",
            "Epoch 1/500, Generator Loss: 0.1689, Discriminator Loss: 0.0621\n",
            "Epoch 1/500, Generator Loss: 0.1689, Discriminator Loss: 0.0620\n",
            "Epoch 1/500, Generator Loss: 0.1688, Discriminator Loss: 0.0620\n",
            "Epoch 1/500, Generator Loss: 0.1688, Discriminator Loss: 0.0619\n",
            "Epoch 1/500, Generator Loss: 0.1688, Discriminator Loss: 0.0618\n",
            "Epoch 1/500, Generator Loss: 0.1687, Discriminator Loss: 0.0618\n",
            "Epoch 1/500, Generator Loss: 0.1687, Discriminator Loss: 0.0617\n",
            "Epoch 1/500, Generator Loss: 0.1687, Discriminator Loss: 0.0617\n",
            "Epoch 1/500, Generator Loss: 0.1686, Discriminator Loss: 0.0616\n",
            "Epoch 1/500, Generator Loss: 0.1686, Discriminator Loss: 0.0616\n",
            "Epoch 1/500, Generator Loss: 0.1686, Discriminator Loss: 0.0615\n",
            "Epoch 1/500, Generator Loss: 0.1685, Discriminator Loss: 0.0614\n",
            "Epoch 1/500, Generator Loss: 0.1685, Discriminator Loss: 0.0614\n",
            "Epoch 1/500, Generator Loss: 0.1684, Discriminator Loss: 0.0613\n",
            "Epoch 1/500, Generator Loss: 0.1684, Discriminator Loss: 0.0613\n",
            "Epoch 1/500, Generator Loss: 0.1684, Discriminator Loss: 0.0612\n",
            "Epoch 1/500, Generator Loss: 0.1683, Discriminator Loss: 0.0612\n",
            "Epoch 1/500, Generator Loss: 0.1683, Discriminator Loss: 0.0611\n",
            "Epoch 1/500, Generator Loss: 0.1683, Discriminator Loss: 0.0611\n",
            "Epoch 1/500, Generator Loss: 0.1682, Discriminator Loss: 0.0611\n",
            "Epoch 1/500, Generator Loss: 0.1682, Discriminator Loss: 0.0610\n",
            "Epoch 1/500, Generator Loss: 0.1682, Discriminator Loss: 0.0610\n",
            "Epoch 1/500, Generator Loss: 0.1681, Discriminator Loss: 0.0609\n",
            "Epoch 1/500, Generator Loss: 0.1681, Discriminator Loss: 0.0609\n",
            "Epoch 1/500, Generator Loss: 0.1681, Discriminator Loss: 0.0608\n",
            "Epoch 1/500, Generator Loss: 0.1681, Discriminator Loss: 0.0608\n",
            "Epoch 1/500, Generator Loss: 0.1680, Discriminator Loss: 0.0607\n",
            "Epoch 1/500, Generator Loss: 0.1680, Discriminator Loss: 0.0607\n",
            "Epoch 1/500, Generator Loss: 0.1680, Discriminator Loss: 0.0606\n",
            "Epoch 1/500, Generator Loss: 0.1679, Discriminator Loss: 0.0606\n",
            "Epoch 1/500, Generator Loss: 0.1679, Discriminator Loss: 0.0606\n",
            "Epoch 1/500, Generator Loss: 0.1679, Discriminator Loss: 0.0605\n",
            "Epoch 1/500, Generator Loss: 0.1679, Discriminator Loss: 0.0605\n",
            "Epoch 1/500, Generator Loss: 0.1679, Discriminator Loss: 0.0604\n",
            "Epoch 1/500, Generator Loss: 0.1678, Discriminator Loss: 0.0603\n",
            "Epoch 1/500, Generator Loss: 0.1678, Discriminator Loss: 0.0603\n",
            "Epoch 1/500, Generator Loss: 0.1678, Discriminator Loss: 0.0602\n",
            "Epoch 1/500, Generator Loss: 0.1677, Discriminator Loss: 0.0602\n",
            "Epoch 1/500, Generator Loss: 0.1677, Discriminator Loss: 0.0601\n",
            "Epoch 1/500, Generator Loss: 0.1677, Discriminator Loss: 0.0601\n",
            "Epoch 1/500, Generator Loss: 0.1676, Discriminator Loss: 0.0600\n",
            "Epoch 1/500, Generator Loss: 0.1676, Discriminator Loss: 0.0600\n",
            "Epoch 1/500, Generator Loss: 0.1676, Discriminator Loss: 0.0599\n",
            "Epoch 1/500, Generator Loss: 0.1675, Discriminator Loss: 0.0598\n",
            "Epoch 1/500, Generator Loss: 0.1675, Discriminator Loss: 0.0598\n",
            "Epoch 1/500, Generator Loss: 0.1674, Discriminator Loss: 0.0597\n",
            "Epoch 1/500, Generator Loss: 0.1674, Discriminator Loss: 0.0597\n",
            "Epoch 1/500, Generator Loss: 0.1674, Discriminator Loss: 0.0596\n",
            "Epoch 1/500, Generator Loss: 0.1673, Discriminator Loss: 0.0596\n",
            "Epoch 1/500, Generator Loss: 0.1673, Discriminator Loss: 0.0595\n",
            "Epoch 1/500, Generator Loss: 0.1673, Discriminator Loss: 0.0595\n",
            "Epoch 1/500, Generator Loss: 0.1672, Discriminator Loss: 0.0594\n",
            "Epoch 1/500, Generator Loss: 0.1672, Discriminator Loss: 0.0594\n",
            "Epoch 1/500, Generator Loss: 0.1672, Discriminator Loss: 0.0594\n",
            "Epoch 1/500, Generator Loss: 0.1672, Discriminator Loss: 0.0594\n",
            "Epoch 1/500, Generator Loss: 0.1671, Discriminator Loss: 0.0593\n",
            "Epoch 1/500, Generator Loss: 0.1671, Discriminator Loss: 0.0593\n",
            "Epoch 1/500, Generator Loss: 0.1671, Discriminator Loss: 0.0592\n",
            "Epoch 1/500, Generator Loss: 0.1670, Discriminator Loss: 0.0592\n",
            "Epoch 1/500, Generator Loss: 0.1670, Discriminator Loss: 0.0591\n",
            "Epoch 1/500, Generator Loss: 0.1670, Discriminator Loss: 0.0591\n",
            "Epoch 1/500, Generator Loss: 0.1669, Discriminator Loss: 0.0590\n",
            "Epoch 1/500, Generator Loss: 0.1669, Discriminator Loss: 0.0590\n",
            "Epoch 1/500, Generator Loss: 0.1669, Discriminator Loss: 0.0589\n",
            "Epoch 1/500, Generator Loss: 0.1668, Discriminator Loss: 0.0589\n",
            "Epoch 1/500, Generator Loss: 0.1668, Discriminator Loss: 0.0588\n",
            "Epoch 1/500, Generator Loss: 0.1668, Discriminator Loss: 0.0588\n",
            "Epoch 1/500, Generator Loss: 0.1667, Discriminator Loss: 0.0587\n",
            "Epoch 1/500, Generator Loss: 0.1667, Discriminator Loss: 0.0587\n",
            "Epoch 1/500, Generator Loss: 0.1667, Discriminator Loss: 0.0586\n",
            "Epoch 1/500, Generator Loss: 0.1666, Discriminator Loss: 0.0586\n",
            "Epoch 1/500, Generator Loss: 0.1666, Discriminator Loss: 0.0586\n",
            "Epoch 1/500, Generator Loss: 0.1666, Discriminator Loss: 0.0585\n",
            "Epoch 1/500, Generator Loss: 0.1665, Discriminator Loss: 0.0585\n",
            "Epoch 1/500, Generator Loss: 0.1665, Discriminator Loss: 0.0584\n",
            "Epoch 1/500, Generator Loss: 0.1665, Discriminator Loss: 0.0584\n",
            "Epoch 1/500, Generator Loss: 0.1665, Discriminator Loss: 0.0583\n",
            "Epoch 1/500, Generator Loss: 0.1664, Discriminator Loss: 0.0583\n",
            "Epoch 1/500, Generator Loss: 0.1664, Discriminator Loss: 0.0582\n",
            "Epoch 1/500, Generator Loss: 0.1663, Discriminator Loss: 0.0582\n",
            "Epoch 1/500, Generator Loss: 0.1663, Discriminator Loss: 0.0582\n",
            "Epoch 1/500, Generator Loss: 0.1663, Discriminator Loss: 0.0581\n",
            "Epoch 1/500, Generator Loss: 0.1663, Discriminator Loss: 0.0580\n",
            "Epoch 1/500, Generator Loss: 0.1662, Discriminator Loss: 0.0580\n",
            "Epoch 1/500, Generator Loss: 0.1662, Discriminator Loss: 0.0579\n",
            "Epoch 1/500, Generator Loss: 0.1662, Discriminator Loss: 0.0579\n",
            "Epoch 1/500, Generator Loss: 0.1661, Discriminator Loss: 0.0579\n",
            "Epoch 1/500, Generator Loss: 0.1661, Discriminator Loss: 0.0578\n",
            "Epoch 1/500, Generator Loss: 0.1660, Discriminator Loss: 0.0578\n",
            "Epoch 1/500, Generator Loss: 0.1660, Discriminator Loss: 0.0578\n",
            "Epoch 1/500, Generator Loss: 0.1660, Discriminator Loss: 0.0577\n",
            "Epoch 1/500, Generator Loss: 0.1659, Discriminator Loss: 0.0577\n",
            "Epoch 1/500, Generator Loss: 0.1659, Discriminator Loss: 0.0576\n",
            "Epoch 1/500, Generator Loss: 0.1659, Discriminator Loss: 0.0576\n",
            "Epoch 1/500, Generator Loss: 0.1658, Discriminator Loss: 0.0575\n",
            "Epoch 1/500, Generator Loss: 0.1658, Discriminator Loss: 0.0575\n",
            "Epoch 1/500, Generator Loss: 0.1658, Discriminator Loss: 0.0574\n",
            "Epoch 1/500, Generator Loss: 0.1658, Discriminator Loss: 0.0574\n",
            "Epoch 1/500, Generator Loss: 0.1657, Discriminator Loss: 0.0574\n",
            "Epoch 1/500, Generator Loss: 0.1657, Discriminator Loss: 0.0573\n",
            "Epoch 1/500, Generator Loss: 0.1657, Discriminator Loss: 0.0573\n",
            "Epoch 1/500, Generator Loss: 0.1656, Discriminator Loss: 0.0572\n",
            "Epoch 1/500, Generator Loss: 0.1656, Discriminator Loss: 0.0572\n",
            "Epoch 1/500, Generator Loss: 0.1656, Discriminator Loss: 0.0572\n",
            "Epoch 1/500, Generator Loss: 0.1655, Discriminator Loss: 0.0571\n",
            "Epoch 1/500, Generator Loss: 0.1655, Discriminator Loss: 0.0571\n",
            "Epoch 1/500, Generator Loss: 0.1655, Discriminator Loss: 0.0570\n",
            "Epoch 1/500, Generator Loss: 0.1654, Discriminator Loss: 0.0570\n",
            "Epoch 1/500, Generator Loss: 0.1654, Discriminator Loss: 0.0570\n",
            "Epoch 1/500, Generator Loss: 0.1654, Discriminator Loss: 0.0569\n",
            "Epoch 1/500, Generator Loss: 0.1654, Discriminator Loss: 0.0569\n",
            "Epoch 1/500, Generator Loss: 0.1653, Discriminator Loss: 0.0569\n",
            "Epoch 1/500, Generator Loss: 0.1653, Discriminator Loss: 0.0568\n",
            "Epoch 1/500, Generator Loss: 0.1653, Discriminator Loss: 0.0568\n",
            "Epoch 1/500, Generator Loss: 0.1653, Discriminator Loss: 0.0567\n",
            "Epoch 1/500, Generator Loss: 0.1652, Discriminator Loss: 0.0567\n",
            "Epoch 1/500, Generator Loss: 0.1652, Discriminator Loss: 0.0567\n",
            "Epoch 1/500, Generator Loss: 0.1652, Discriminator Loss: 0.0566\n",
            "Epoch 1/500, Generator Loss: 0.1651, Discriminator Loss: 0.0566\n",
            "Epoch 1/500, Generator Loss: 0.1651, Discriminator Loss: 0.0566\n",
            "Epoch 1/500, Generator Loss: 0.1651, Discriminator Loss: 0.0565\n",
            "Epoch 1/500, Generator Loss: 0.1650, Discriminator Loss: 0.0565\n",
            "Epoch 1/500, Generator Loss: 0.1650, Discriminator Loss: 0.0564\n",
            "Epoch 1/500, Generator Loss: 0.1650, Discriminator Loss: 0.0564\n",
            "Epoch 1/500, Generator Loss: 0.1650, Discriminator Loss: 0.0564\n",
            "Epoch 1/500, Generator Loss: 0.1649, Discriminator Loss: 0.0563\n",
            "Epoch 1/500, Generator Loss: 0.1649, Discriminator Loss: 0.0563\n",
            "Epoch 1/500, Generator Loss: 0.1649, Discriminator Loss: 0.0563\n",
            "Epoch 1/500, Generator Loss: 0.1648, Discriminator Loss: 0.0562\n",
            "Epoch 1/500, Generator Loss: 0.1648, Discriminator Loss: 0.0562\n",
            "Epoch 1/500, Generator Loss: 0.1648, Discriminator Loss: 0.0562\n",
            "Epoch 1/500, Generator Loss: 0.1648, Discriminator Loss: 0.0561\n",
            "Epoch 1/500, Generator Loss: 0.1647, Discriminator Loss: 0.0561\n",
            "Epoch 1/500, Generator Loss: 0.1647, Discriminator Loss: 0.0560\n",
            "Epoch 1/500, Generator Loss: 0.1646, Discriminator Loss: 0.0560\n",
            "Epoch 1/500, Generator Loss: 0.1646, Discriminator Loss: 0.0559\n",
            "Epoch 1/500, Generator Loss: 0.1646, Discriminator Loss: 0.0559\n",
            "Epoch 1/500, Generator Loss: 0.1646, Discriminator Loss: 0.0559\n",
            "Epoch 1/500, Generator Loss: 0.1645, Discriminator Loss: 0.0558\n",
            "Epoch 1/500, Generator Loss: 0.1645, Discriminator Loss: 0.0558\n",
            "Epoch 1/500, Generator Loss: 0.1645, Discriminator Loss: 0.0557\n",
            "Epoch 1/500, Generator Loss: 0.1644, Discriminator Loss: 0.0557\n",
            "Epoch 1/500, Generator Loss: 0.1644, Discriminator Loss: 0.0556\n",
            "Epoch 1/500, Generator Loss: 0.1644, Discriminator Loss: 0.0556\n",
            "Epoch 1/500, Generator Loss: 0.1643, Discriminator Loss: 0.0556\n",
            "Epoch 1/500, Generator Loss: 0.1643, Discriminator Loss: 0.0555\n",
            "Epoch 1/500, Generator Loss: 0.1643, Discriminator Loss: 0.0555\n",
            "Epoch 1/500, Generator Loss: 0.1643, Discriminator Loss: 0.0555\n",
            "Epoch 1/500, Generator Loss: 0.1642, Discriminator Loss: 0.0554\n",
            "Epoch 1/500, Generator Loss: 0.1642, Discriminator Loss: 0.0554\n",
            "Epoch 1/500, Generator Loss: 0.1642, Discriminator Loss: 0.0554\n",
            "Epoch 1/500, Generator Loss: 0.1642, Discriminator Loss: 0.0554\n",
            "Epoch 1/500, Generator Loss: 0.1642, Discriminator Loss: 0.0553\n",
            "Epoch 1/500, Generator Loss: 0.1641, Discriminator Loss: 0.0553\n",
            "Epoch 1/500, Generator Loss: 0.1641, Discriminator Loss: 0.0552\n",
            "Epoch 1/500, Generator Loss: 0.1641, Discriminator Loss: 0.0552\n",
            "Epoch 1/500, Generator Loss: 0.1641, Discriminator Loss: 0.0551\n",
            "Epoch 1/500, Generator Loss: 0.1640, Discriminator Loss: 0.0551\n",
            "Epoch 1/500, Generator Loss: 0.1640, Discriminator Loss: 0.0551\n",
            "Epoch 1/500, Generator Loss: 0.1640, Discriminator Loss: 0.0550\n",
            "Epoch 1/500, Generator Loss: 0.1639, Discriminator Loss: 0.0550\n",
            "Epoch 1/500, Generator Loss: 0.1639, Discriminator Loss: 0.0550\n",
            "Epoch 1/500, Generator Loss: 0.1639, Discriminator Loss: 0.0549\n",
            "Epoch 1/500, Generator Loss: 0.1638, Discriminator Loss: 0.0549\n",
            "Epoch 1/500, Generator Loss: 0.1638, Discriminator Loss: 0.0548\n",
            "Epoch 1/500, Generator Loss: 0.1638, Discriminator Loss: 0.0548\n",
            "Epoch 1/500, Generator Loss: 0.1637, Discriminator Loss: 0.0548\n",
            "Epoch 1/500, Generator Loss: 0.1637, Discriminator Loss: 0.0547\n",
            "Epoch 1/500, Generator Loss: 0.1637, Discriminator Loss: 0.0547\n",
            "Epoch 1/500, Generator Loss: 0.1637, Discriminator Loss: 0.0546\n",
            "Epoch 1/500, Generator Loss: 0.1636, Discriminator Loss: 0.0546\n",
            "Epoch 1/500, Generator Loss: 0.1636, Discriminator Loss: 0.0546\n",
            "Epoch 1/500, Generator Loss: 0.1636, Discriminator Loss: 0.0545\n",
            "Epoch 1/500, Generator Loss: 0.1635, Discriminator Loss: 0.0545\n",
            "Epoch 1/500, Generator Loss: 0.1635, Discriminator Loss: 0.0544\n",
            "Epoch 1/500, Generator Loss: 0.1635, Discriminator Loss: 0.0544\n",
            "Epoch 1/500, Generator Loss: 0.1634, Discriminator Loss: 0.0544\n",
            "Epoch 1/500, Generator Loss: 0.1634, Discriminator Loss: 0.0543\n",
            "Epoch 1/500, Generator Loss: 0.1634, Discriminator Loss: 0.0543\n",
            "Epoch 1/500, Generator Loss: 0.1633, Discriminator Loss: 0.0543\n",
            "Epoch 1/500, Generator Loss: 0.1633, Discriminator Loss: 0.0542\n",
            "Epoch 1/500, Generator Loss: 0.1633, Discriminator Loss: 0.0542\n",
            "Epoch 1/500, Generator Loss: 0.1633, Discriminator Loss: 0.0542\n",
            "Epoch 1/500, Generator Loss: 0.1632, Discriminator Loss: 0.0541\n",
            "Epoch 1/500, Generator Loss: 0.1632, Discriminator Loss: 0.0541\n",
            "Epoch 1/500, Generator Loss: 0.1632, Discriminator Loss: 0.0541\n",
            "Epoch 1/500, Generator Loss: 0.1631, Discriminator Loss: 0.0540\n",
            "Epoch 1/500, Generator Loss: 0.1631, Discriminator Loss: 0.0540\n",
            "Epoch 1/500, Generator Loss: 0.1631, Discriminator Loss: 0.0540\n",
            "Epoch 1/500, Generator Loss: 0.1631, Discriminator Loss: 0.0539\n",
            "Epoch 1/500, Generator Loss: 0.1630, Discriminator Loss: 0.0539\n",
            "Epoch 1/500, Generator Loss: 0.1630, Discriminator Loss: 0.0539\n",
            "Epoch 1/500, Generator Loss: 0.1630, Discriminator Loss: 0.0538\n",
            "Epoch 1/500, Generator Loss: 0.1630, Discriminator Loss: 0.0538\n",
            "Epoch 1/500, Generator Loss: 0.1629, Discriminator Loss: 0.0538\n",
            "Epoch 1/500, Generator Loss: 0.1629, Discriminator Loss: 0.0538\n",
            "Epoch 1/500, Generator Loss: 0.1629, Discriminator Loss: 0.0538\n",
            "Epoch 1/500, Generator Loss: 0.1629, Discriminator Loss: 0.0538\n",
            "Epoch 1/500, Generator Loss: 0.1629, Discriminator Loss: 0.0538\n",
            "Epoch 1/500, Generator Loss: 0.1628, Discriminator Loss: 0.0538\n",
            "Epoch 1/500, Generator Loss: 0.1628, Discriminator Loss: 0.0537\n",
            "Epoch 1/500, Generator Loss: 0.1628, Discriminator Loss: 0.0537\n",
            "Epoch 1/500, Generator Loss: 0.1628, Discriminator Loss: 0.0537\n",
            "Epoch 1/500, Generator Loss: 0.1628, Discriminator Loss: 0.0536\n",
            "Epoch 1/500, Generator Loss: 0.1627, Discriminator Loss: 0.0536\n",
            "Epoch 1/500, Generator Loss: 0.1627, Discriminator Loss: 0.0536\n",
            "Epoch 1/500, Generator Loss: 0.1627, Discriminator Loss: 0.0535\n",
            "Epoch 1/500, Generator Loss: 0.1627, Discriminator Loss: 0.0535\n",
            "Epoch 1/500, Generator Loss: 0.1626, Discriminator Loss: 0.0535\n",
            "Epoch 1/500, Generator Loss: 0.1626, Discriminator Loss: 0.0534\n",
            "Epoch 1/500, Generator Loss: 0.1626, Discriminator Loss: 0.0534\n",
            "Epoch 1/500, Generator Loss: 0.1626, Discriminator Loss: 0.0534\n",
            "Epoch 1/500, Generator Loss: 0.1625, Discriminator Loss: 0.0533\n",
            "Epoch 1/500, Generator Loss: 0.1625, Discriminator Loss: 0.0533\n",
            "Epoch 1/500, Generator Loss: 0.1625, Discriminator Loss: 0.0533\n",
            "Epoch 1/500, Generator Loss: 0.1625, Discriminator Loss: 0.0532\n",
            "Epoch 1/500, Generator Loss: 0.1624, Discriminator Loss: 0.0532\n",
            "Epoch 1/500, Generator Loss: 0.1624, Discriminator Loss: 0.0532\n",
            "Epoch 1/500, Generator Loss: 0.1624, Discriminator Loss: 0.0531\n",
            "Epoch 1/500, Generator Loss: 0.1624, Discriminator Loss: 0.0531\n",
            "Epoch 1/500, Generator Loss: 0.1623, Discriminator Loss: 0.0531\n",
            "Epoch 1/500, Generator Loss: 0.1623, Discriminator Loss: 0.0531\n",
            "Epoch 1/500, Generator Loss: 0.1623, Discriminator Loss: 0.0530\n",
            "Epoch 1/500, Generator Loss: 0.1622, Discriminator Loss: 0.0530\n",
            "Epoch 1/500, Generator Loss: 0.1622, Discriminator Loss: 0.0530\n",
            "Epoch 1/500, Generator Loss: 0.1622, Discriminator Loss: 0.0529\n",
            "Epoch 1/500, Generator Loss: 0.1622, Discriminator Loss: 0.0529\n",
            "Epoch 1/500, Generator Loss: 0.1621, Discriminator Loss: 0.0529\n",
            "Epoch 1/500, Generator Loss: 0.1621, Discriminator Loss: 0.0528\n",
            "Epoch 1/500, Generator Loss: 0.1621, Discriminator Loss: 0.0528\n",
            "Epoch 1/500, Generator Loss: 0.1621, Discriminator Loss: 0.0528\n",
            "Epoch 1/500, Generator Loss: 0.1621, Discriminator Loss: 0.0527\n",
            "Epoch 1/500, Generator Loss: 0.1620, Discriminator Loss: 0.0527\n",
            "Epoch 1/500, Generator Loss: 0.1620, Discriminator Loss: 0.0527\n",
            "Epoch 1/500, Generator Loss: 0.1620, Discriminator Loss: 0.0526\n",
            "Epoch 1/500, Generator Loss: 0.1620, Discriminator Loss: 0.0526\n",
            "Epoch 1/500, Generator Loss: 0.1620, Discriminator Loss: 0.0526\n",
            "Epoch 1/500, Generator Loss: 0.1619, Discriminator Loss: 0.0526\n",
            "Epoch 1/500, Generator Loss: 0.1619, Discriminator Loss: 0.0525\n",
            "Epoch 1/500, Generator Loss: 0.1619, Discriminator Loss: 0.0525\n",
            "Epoch 1/500, Generator Loss: 0.1619, Discriminator Loss: 0.0525\n",
            "Epoch 1/500, Generator Loss: 0.1618, Discriminator Loss: 0.0524\n",
            "Epoch 1/500, Generator Loss: 0.1618, Discriminator Loss: 0.0524\n",
            "Epoch 1/500, Generator Loss: 0.1618, Discriminator Loss: 0.0523\n",
            "Epoch 1/500, Generator Loss: 0.1617, Discriminator Loss: 0.0523\n",
            "Epoch 1/500, Generator Loss: 0.1617, Discriminator Loss: 0.0523\n",
            "Epoch 1/500, Generator Loss: 0.1617, Discriminator Loss: 0.0523\n",
            "Epoch 1/500, Generator Loss: 0.1617, Discriminator Loss: 0.0523\n",
            "Epoch 1/500, Generator Loss: 0.1616, Discriminator Loss: 0.0522\n",
            "Epoch 1/500, Generator Loss: 0.1616, Discriminator Loss: 0.0522\n",
            "Epoch 1/500, Generator Loss: 0.1616, Discriminator Loss: 0.0522\n",
            "Epoch 1/500, Generator Loss: 0.1616, Discriminator Loss: 0.0521\n",
            "Epoch 1/500, Generator Loss: 0.1616, Discriminator Loss: 0.0521\n",
            "Epoch 1/500, Generator Loss: 0.1616, Discriminator Loss: 0.0521\n",
            "Epoch 1/500, Generator Loss: 0.1615, Discriminator Loss: 0.0520\n",
            "Epoch 1/500, Generator Loss: 0.1615, Discriminator Loss: 0.0520\n",
            "Epoch 1/500, Generator Loss: 0.1615, Discriminator Loss: 0.0520\n",
            "Epoch 1/500, Generator Loss: 0.1615, Discriminator Loss: 0.0520\n",
            "Epoch 1/500, Generator Loss: 0.1614, Discriminator Loss: 0.0519\n",
            "Epoch 1/500, Generator Loss: 0.1614, Discriminator Loss: 0.0519\n",
            "Epoch 1/500, Generator Loss: 0.1614, Discriminator Loss: 0.0519\n",
            "Epoch 1/500, Generator Loss: 0.1614, Discriminator Loss: 0.0518\n",
            "Epoch 1/500, Generator Loss: 0.1613, Discriminator Loss: 0.0518\n",
            "Epoch 1/500, Generator Loss: 0.1613, Discriminator Loss: 0.0518\n",
            "Epoch 1/500, Generator Loss: 0.1613, Discriminator Loss: 0.0517\n",
            "Epoch 1/500, Generator Loss: 0.1613, Discriminator Loss: 0.0517\n",
            "Epoch 1/500, Generator Loss: 0.1612, Discriminator Loss: 0.0517\n",
            "Epoch 1/500, Generator Loss: 0.1612, Discriminator Loss: 0.0516\n",
            "Epoch 1/500, Generator Loss: 0.1612, Discriminator Loss: 0.0516\n",
            "Epoch 1/500, Generator Loss: 0.1612, Discriminator Loss: 0.0516\n",
            "Epoch 1/500, Generator Loss: 0.1611, Discriminator Loss: 0.0516\n",
            "Epoch 1/500, Generator Loss: 0.1611, Discriminator Loss: 0.0515\n",
            "Epoch 1/500, Generator Loss: 0.1611, Discriminator Loss: 0.0515\n",
            "Epoch 1/500, Generator Loss: 0.1611, Discriminator Loss: 0.0515\n",
            "Epoch 1/500, Generator Loss: 0.1611, Discriminator Loss: 0.0514\n",
            "Epoch 1/500, Generator Loss: 0.1610, Discriminator Loss: 0.0514\n",
            "Epoch 1/500, Generator Loss: 0.1610, Discriminator Loss: 0.0513\n",
            "Epoch 1/500, Generator Loss: 0.1610, Discriminator Loss: 0.0513\n",
            "Epoch 1/500, Generator Loss: 0.1609, Discriminator Loss: 0.0513\n",
            "Epoch 1/500, Generator Loss: 0.1609, Discriminator Loss: 0.0513\n",
            "Epoch 1/500, Generator Loss: 0.1609, Discriminator Loss: 0.0512\n",
            "Epoch 1/500, Generator Loss: 0.1609, Discriminator Loss: 0.0512\n",
            "Epoch 1/500, Generator Loss: 0.1608, Discriminator Loss: 0.0512\n",
            "Epoch 1/500, Generator Loss: 0.1608, Discriminator Loss: 0.0512\n",
            "Epoch 1/500, Generator Loss: 0.1608, Discriminator Loss: 0.0511\n",
            "Epoch 1/500, Generator Loss: 0.1608, Discriminator Loss: 0.0511\n",
            "Epoch 1/500, Generator Loss: 0.1608, Discriminator Loss: 0.0511\n",
            "Epoch 1/500, Generator Loss: 0.1607, Discriminator Loss: 0.0510\n",
            "Epoch 1/500, Generator Loss: 0.1607, Discriminator Loss: 0.0510\n",
            "Epoch 1/500, Generator Loss: 0.1607, Discriminator Loss: 0.0510\n",
            "Epoch 1/500, Generator Loss: 0.1607, Discriminator Loss: 0.0510\n",
            "Epoch 1/500, Generator Loss: 0.1606, Discriminator Loss: 0.0510\n",
            "Epoch 1/500, Generator Loss: 0.1606, Discriminator Loss: 0.0509\n",
            "Epoch 1/500, Generator Loss: 0.1606, Discriminator Loss: 0.0509\n",
            "Epoch 1/500, Generator Loss: 0.1606, Discriminator Loss: 0.0509\n",
            "Epoch 1/500, Generator Loss: 0.1606, Discriminator Loss: 0.0508\n",
            "Epoch 1/500, Generator Loss: 0.1605, Discriminator Loss: 0.0508\n",
            "Epoch 1/500, Generator Loss: 0.1605, Discriminator Loss: 0.0508\n",
            "Epoch 1/500, Generator Loss: 0.1605, Discriminator Loss: 0.0508\n",
            "Epoch 1/500, Generator Loss: 0.1605, Discriminator Loss: 0.0507\n",
            "Epoch 1/500, Generator Loss: 0.1604, Discriminator Loss: 0.0507\n",
            "Epoch 1/500, Generator Loss: 0.1604, Discriminator Loss: 0.0507\n",
            "Epoch 1/500, Generator Loss: 0.1604, Discriminator Loss: 0.0507\n",
            "Epoch 1/500, Generator Loss: 0.1604, Discriminator Loss: 0.0506\n",
            "Epoch 1/500, Generator Loss: 0.1603, Discriminator Loss: 0.0506\n",
            "Epoch 1/500, Generator Loss: 0.1603, Discriminator Loss: 0.0506\n",
            "Epoch 1/500, Generator Loss: 0.1603, Discriminator Loss: 0.0506\n",
            "Epoch 1/500, Generator Loss: 0.1603, Discriminator Loss: 0.0505\n",
            "Epoch 1/500, Generator Loss: 0.1602, Discriminator Loss: 0.0505\n",
            "Epoch 1/500, Generator Loss: 0.1602, Discriminator Loss: 0.0505\n",
            "Epoch 1/500, Generator Loss: 0.1602, Discriminator Loss: 0.0505\n",
            "Epoch 1/500, Generator Loss: 0.1602, Discriminator Loss: 0.0504\n",
            "Epoch 1/500, Generator Loss: 0.1602, Discriminator Loss: 0.0504\n",
            "Epoch 1/500, Generator Loss: 0.1601, Discriminator Loss: 0.0504\n",
            "Epoch 1/500, Generator Loss: 0.1601, Discriminator Loss: 0.0504\n",
            "Epoch 1/500, Generator Loss: 0.1601, Discriminator Loss: 0.0503\n",
            "Epoch 1/500, Generator Loss: 0.1601, Discriminator Loss: 0.0503\n",
            "Epoch 1/500, Generator Loss: 0.1600, Discriminator Loss: 0.0503\n",
            "Epoch 1/500, Generator Loss: 0.1600, Discriminator Loss: 0.0502\n",
            "Epoch 1/500, Generator Loss: 0.1600, Discriminator Loss: 0.0502\n",
            "Epoch 1/500, Generator Loss: 0.1600, Discriminator Loss: 0.0502\n",
            "Epoch 1/500, Generator Loss: 0.1599, Discriminator Loss: 0.0502\n",
            "Epoch 1/500, Generator Loss: 0.1599, Discriminator Loss: 0.0501\n",
            "Epoch 1/500, Generator Loss: 0.1599, Discriminator Loss: 0.0501\n",
            "Epoch 1/500, Generator Loss: 0.1599, Discriminator Loss: 0.0501\n",
            "Epoch 1/500, Generator Loss: 0.1598, Discriminator Loss: 0.0500\n",
            "Epoch 1/500, Generator Loss: 0.1598, Discriminator Loss: 0.0500\n",
            "Epoch 1/500, Generator Loss: 0.1598, Discriminator Loss: 0.0500\n",
            "Epoch 1/500, Generator Loss: 0.1598, Discriminator Loss: 0.0499\n",
            "Epoch 1/500, Generator Loss: 0.1598, Discriminator Loss: 0.0499\n",
            "Epoch 1/500, Generator Loss: 0.1597, Discriminator Loss: 0.0499\n",
            "Epoch 1/500, Generator Loss: 0.1597, Discriminator Loss: 0.0499\n",
            "Epoch 1/500, Generator Loss: 0.1597, Discriminator Loss: 0.0498\n",
            "Epoch 1/500, Generator Loss: 0.1597, Discriminator Loss: 0.0498\n",
            "Epoch 1/500, Generator Loss: 0.1596, Discriminator Loss: 0.0498\n",
            "Epoch 1/500, Generator Loss: 0.1596, Discriminator Loss: 0.0498\n",
            "Epoch 1/500, Generator Loss: 0.1596, Discriminator Loss: 0.0497\n",
            "Epoch 1/500, Generator Loss: 0.1596, Discriminator Loss: 0.0497\n",
            "Epoch 1/500, Generator Loss: 0.1595, Discriminator Loss: 0.0497\n",
            "Epoch 1/500, Generator Loss: 0.1595, Discriminator Loss: 0.0497\n",
            "Epoch 1/500, Generator Loss: 0.1595, Discriminator Loss: 0.0496\n",
            "Epoch 1/500, Generator Loss: 0.1595, Discriminator Loss: 0.0496\n",
            "Epoch 1/500, Generator Loss: 0.1594, Discriminator Loss: 0.0496\n",
            "Epoch 1/500, Generator Loss: 0.1594, Discriminator Loss: 0.0496\n",
            "Epoch 1/500, Generator Loss: 0.1594, Discriminator Loss: 0.0495\n",
            "Epoch 1/500, Generator Loss: 0.1594, Discriminator Loss: 0.0495\n",
            "Epoch 1/500, Generator Loss: 0.1593, Discriminator Loss: 0.0495\n",
            "Epoch 1/500, Generator Loss: 0.1593, Discriminator Loss: 0.0495\n",
            "Epoch 1/500, Generator Loss: 0.1593, Discriminator Loss: 0.0494\n",
            "Epoch 1/500, Generator Loss: 0.1593, Discriminator Loss: 0.0494\n",
            "Epoch 1/500, Generator Loss: 0.1592, Discriminator Loss: 0.0494\n",
            "Epoch 1/500, Generator Loss: 0.1592, Discriminator Loss: 0.0494\n",
            "Epoch 1/500, Generator Loss: 0.1592, Discriminator Loss: 0.0494\n",
            "Epoch 1/500, Generator Loss: 0.1592, Discriminator Loss: 0.0493\n",
            "Epoch 1/500, Generator Loss: 0.1591, Discriminator Loss: 0.0493\n",
            "Epoch 1/500, Generator Loss: 0.1591, Discriminator Loss: 0.0493\n",
            "Epoch 1/500, Generator Loss: 0.1591, Discriminator Loss: 0.0493\n",
            "Epoch 1/500, Generator Loss: 0.1591, Discriminator Loss: 0.0492\n",
            "Epoch 1/500, Generator Loss: 0.1591, Discriminator Loss: 0.0492\n",
            "Epoch 1/500, Generator Loss: 0.1590, Discriminator Loss: 0.0492\n",
            "Epoch 1/500, Generator Loss: 0.1590, Discriminator Loss: 0.0492\n",
            "Epoch 1/500, Generator Loss: 0.1590, Discriminator Loss: 0.0491\n",
            "Epoch 1/500, Generator Loss: 0.1590, Discriminator Loss: 0.0491\n",
            "Epoch 1/500, Generator Loss: 0.1589, Discriminator Loss: 0.0491\n",
            "Epoch 1/500, Generator Loss: 0.1589, Discriminator Loss: 0.0491\n",
            "Epoch 1/500, Generator Loss: 0.1589, Discriminator Loss: 0.0490\n",
            "Epoch 1/500, Generator Loss: 0.1589, Discriminator Loss: 0.0490\n",
            "Epoch 1/500, Generator Loss: 0.1589, Discriminator Loss: 0.0490\n",
            "Epoch 1/500, Generator Loss: 0.1588, Discriminator Loss: 0.0490\n",
            "Epoch 1/500, Generator Loss: 0.1588, Discriminator Loss: 0.0489\n",
            "Epoch 1/500, Generator Loss: 0.1588, Discriminator Loss: 0.0489\n",
            "Epoch 1/500, Generator Loss: 0.1588, Discriminator Loss: 0.0489\n",
            "Epoch 1/500, Generator Loss: 0.1587, Discriminator Loss: 0.0489\n",
            "Epoch 1/500, Generator Loss: 0.1587, Discriminator Loss: 0.0488\n",
            "Epoch 1/500, Generator Loss: 0.1587, Discriminator Loss: 0.0488\n",
            "Epoch 1/500, Generator Loss: 0.1587, Discriminator Loss: 0.0488\n",
            "Epoch 1/500, Generator Loss: 0.1586, Discriminator Loss: 0.0488\n",
            "Epoch 1/500, Generator Loss: 0.1586, Discriminator Loss: 0.0488\n",
            "Epoch 1/500, Generator Loss: 0.1586, Discriminator Loss: 0.0487\n",
            "Epoch 1/500, Generator Loss: 0.1586, Discriminator Loss: 0.0487\n",
            "Epoch 1/500, Generator Loss: 0.1586, Discriminator Loss: 0.0487\n",
            "Epoch 1/500, Generator Loss: 0.1585, Discriminator Loss: 0.0487\n",
            "Epoch 1/500, Generator Loss: 0.1585, Discriminator Loss: 0.0487\n",
            "Epoch 1/500, Generator Loss: 0.1585, Discriminator Loss: 0.0486\n",
            "Epoch 1/500, Generator Loss: 0.1585, Discriminator Loss: 0.0486\n",
            "Epoch 1/500, Generator Loss: 0.1584, Discriminator Loss: 0.0486\n",
            "Epoch 1/500, Generator Loss: 0.1584, Discriminator Loss: 0.0486\n",
            "Epoch 1/500, Generator Loss: 0.1584, Discriminator Loss: 0.0485\n",
            "Epoch 1/500, Generator Loss: 0.1584, Discriminator Loss: 0.0485\n",
            "Epoch 1/500, Generator Loss: 0.1584, Discriminator Loss: 0.0485\n",
            "Epoch 1/500, Generator Loss: 0.1583, Discriminator Loss: 0.0485\n",
            "Epoch 1/500, Generator Loss: 0.1583, Discriminator Loss: 0.0484\n",
            "Epoch 1/500, Generator Loss: 0.1583, Discriminator Loss: 0.0484\n",
            "Epoch 1/500, Generator Loss: 0.1583, Discriminator Loss: 0.0484\n",
            "Epoch 1/500, Generator Loss: 0.1582, Discriminator Loss: 0.0484\n",
            "Epoch 1/500, Generator Loss: 0.1582, Discriminator Loss: 0.0483\n",
            "Epoch 1/500, Generator Loss: 0.1582, Discriminator Loss: 0.0483\n",
            "Epoch 1/500, Generator Loss: 0.1582, Discriminator Loss: 0.0483\n",
            "Epoch 1/500, Generator Loss: 0.1581, Discriminator Loss: 0.0483\n",
            "Epoch 1/500, Generator Loss: 0.1581, Discriminator Loss: 0.0482\n",
            "Epoch 1/500, Generator Loss: 0.1581, Discriminator Loss: 0.0482\n",
            "Epoch 1/500, Generator Loss: 0.1581, Discriminator Loss: 0.0482\n",
            "Epoch 1/500, Generator Loss: 0.1581, Discriminator Loss: 0.0482\n",
            "Epoch 1/500, Generator Loss: 0.1580, Discriminator Loss: 0.0481\n",
            "Epoch 1/500, Generator Loss: 0.1580, Discriminator Loss: 0.0481\n",
            "Epoch 1/500, Generator Loss: 0.1580, Discriminator Loss: 0.0481\n",
            "Epoch 1/500, Generator Loss: 0.1580, Discriminator Loss: 0.0481\n",
            "Epoch 1/500, Generator Loss: 0.1579, Discriminator Loss: 0.0480\n",
            "Epoch 1/500, Generator Loss: 0.1579, Discriminator Loss: 0.0480\n",
            "Epoch 1/500, Generator Loss: 0.1579, Discriminator Loss: 0.0480\n",
            "Epoch 1/500, Generator Loss: 0.1579, Discriminator Loss: 0.0480\n",
            "Epoch 1/500, Generator Loss: 0.1579, Discriminator Loss: 0.0479\n",
            "Epoch 1/500, Generator Loss: 0.1578, Discriminator Loss: 0.0479\n",
            "Epoch 1/500, Generator Loss: 0.1578, Discriminator Loss: 0.0479\n",
            "Epoch 1/500, Generator Loss: 0.1578, Discriminator Loss: 0.0479\n",
            "Epoch 1/500, Generator Loss: 0.1578, Discriminator Loss: 0.0478\n",
            "Epoch 1/500, Generator Loss: 0.1578, Discriminator Loss: 0.0478\n",
            "Epoch 1/500, Generator Loss: 0.1577, Discriminator Loss: 0.0478\n",
            "Epoch 1/500, Generator Loss: 0.1577, Discriminator Loss: 0.0478\n",
            "Epoch 1/500, Generator Loss: 0.1577, Discriminator Loss: 0.0478\n",
            "Epoch 1/500, Generator Loss: 0.1577, Discriminator Loss: 0.0477\n",
            "Epoch 1/500, Generator Loss: 0.1576, Discriminator Loss: 0.0477\n",
            "Epoch 1/500, Generator Loss: 0.1576, Discriminator Loss: 0.0477\n",
            "Epoch 1/500, Generator Loss: 0.1576, Discriminator Loss: 0.0477\n",
            "Epoch 1/500, Generator Loss: 0.1576, Discriminator Loss: 0.0476\n",
            "Epoch 1/500, Generator Loss: 0.1575, Discriminator Loss: 0.0476\n",
            "Epoch 1/500, Generator Loss: 0.1575, Discriminator Loss: 0.0476\n",
            "Epoch 1/500, Generator Loss: 0.1575, Discriminator Loss: 0.0476\n",
            "Epoch 1/500, Generator Loss: 0.1575, Discriminator Loss: 0.0476\n",
            "Epoch 1/500, Generator Loss: 0.1575, Discriminator Loss: 0.0476\n",
            "Epoch 1/500, Generator Loss: 0.1574, Discriminator Loss: 0.0475\n",
            "Epoch 1/500, Generator Loss: 0.1574, Discriminator Loss: 0.0475\n",
            "Epoch 1/500, Generator Loss: 0.1574, Discriminator Loss: 0.0475\n",
            "Epoch 1/500, Generator Loss: 0.1574, Discriminator Loss: 0.0475\n",
            "Epoch 1/500, Generator Loss: 0.1574, Discriminator Loss: 0.0474\n",
            "Epoch 1/500, Generator Loss: 0.1573, Discriminator Loss: 0.0474\n",
            "Epoch 1/500, Generator Loss: 0.1573, Discriminator Loss: 0.0474\n",
            "Epoch 1/500, Generator Loss: 0.1573, Discriminator Loss: 0.0474\n",
            "Epoch 1/500, Generator Loss: 0.1573, Discriminator Loss: 0.0474\n",
            "Epoch 1/500, Generator Loss: 0.1573, Discriminator Loss: 0.0474\n",
            "Epoch 1/500, Generator Loss: 0.1572, Discriminator Loss: 0.0473\n",
            "Epoch 1/500, Generator Loss: 0.1572, Discriminator Loss: 0.0473\n",
            "Epoch 1/500, Generator Loss: 0.1572, Discriminator Loss: 0.0473\n",
            "Epoch 1/500, Generator Loss: 0.1572, Discriminator Loss: 0.0473\n",
            "Epoch 1/500, Generator Loss: 0.1572, Discriminator Loss: 0.0473\n",
            "Epoch 1/500, Generator Loss: 0.1571, Discriminator Loss: 0.0472\n",
            "Epoch 1/500, Generator Loss: 0.1571, Discriminator Loss: 0.0472\n",
            "Epoch 1/500, Generator Loss: 0.1571, Discriminator Loss: 0.0472\n",
            "Epoch 1/500, Generator Loss: 0.1571, Discriminator Loss: 0.0472\n",
            "Epoch 1/500, Generator Loss: 0.1570, Discriminator Loss: 0.0471\n",
            "Epoch 1/500, Generator Loss: 0.1570, Discriminator Loss: 0.0471\n",
            "Epoch 1/500, Generator Loss: 0.1570, Discriminator Loss: 0.0471\n",
            "Epoch 1/500, Generator Loss: 0.1570, Discriminator Loss: 0.0471\n",
            "Epoch 1/500, Generator Loss: 0.1570, Discriminator Loss: 0.0470\n",
            "Epoch 1/500, Generator Loss: 0.1569, Discriminator Loss: 0.0470\n",
            "Epoch 1/500, Generator Loss: 0.1569, Discriminator Loss: 0.0470\n",
            "Epoch 1/500, Generator Loss: 0.1569, Discriminator Loss: 0.0470\n",
            "Epoch 1/500, Generator Loss: 0.1569, Discriminator Loss: 0.0470\n",
            "Epoch 1/500, Generator Loss: 0.1569, Discriminator Loss: 0.0470\n",
            "Epoch 1/500, Generator Loss: 0.1568, Discriminator Loss: 0.0470\n",
            "Epoch 1/500, Generator Loss: 0.1568, Discriminator Loss: 0.0470\n",
            "Epoch 1/500, Generator Loss: 0.1568, Discriminator Loss: 0.0470\n",
            "Epoch 1/500, Generator Loss: 0.1568, Discriminator Loss: 0.0469\n",
            "Epoch 1/500, Generator Loss: 0.1568, Discriminator Loss: 0.0469\n",
            "Epoch 1/500, Generator Loss: 0.1568, Discriminator Loss: 0.0469\n",
            "Epoch 1/500, Generator Loss: 0.1567, Discriminator Loss: 0.0469\n",
            "Epoch 1/500, Generator Loss: 0.1567, Discriminator Loss: 0.0469\n",
            "Epoch 1/500, Generator Loss: 0.1567, Discriminator Loss: 0.0468\n",
            "Epoch 1/500, Generator Loss: 0.1567, Discriminator Loss: 0.0468\n",
            "Epoch 1/500, Generator Loss: 0.1567, Discriminator Loss: 0.0468\n",
            "Epoch 1/500, Generator Loss: 0.1566, Discriminator Loss: 0.0468\n",
            "Epoch 1/500, Generator Loss: 0.1566, Discriminator Loss: 0.0468\n",
            "Epoch 1/500, Generator Loss: 0.1566, Discriminator Loss: 0.0467\n",
            "Epoch 1/500, Generator Loss: 0.1566, Discriminator Loss: 0.0467\n",
            "Epoch 1/500, Generator Loss: 0.1565, Discriminator Loss: 0.0467\n",
            "Epoch 1/500, Generator Loss: 0.1565, Discriminator Loss: 0.0467\n",
            "Epoch 1/500, Generator Loss: 0.1565, Discriminator Loss: 0.0467\n",
            "Epoch 1/500, Generator Loss: 0.1565, Discriminator Loss: 0.0467\n",
            "Epoch 1/500, Generator Loss: 0.1565, Discriminator Loss: 0.0466\n",
            "Epoch 1/500, Generator Loss: 0.1564, Discriminator Loss: 0.0466\n",
            "Epoch 1/500, Generator Loss: 0.1564, Discriminator Loss: 0.0466\n",
            "Epoch 1/500, Generator Loss: 0.1564, Discriminator Loss: 0.0466\n",
            "Epoch 1/500, Generator Loss: 0.1564, Discriminator Loss: 0.0466\n",
            "Epoch 1/500, Generator Loss: 0.1564, Discriminator Loss: 0.0465\n",
            "Epoch 1/500, Generator Loss: 0.1563, Discriminator Loss: 0.0465\n",
            "Epoch 1/500, Generator Loss: 0.1563, Discriminator Loss: 0.0465\n",
            "Epoch 1/500, Generator Loss: 0.1563, Discriminator Loss: 0.0465\n",
            "Epoch 1/500, Generator Loss: 0.1563, Discriminator Loss: 0.0464\n",
            "Epoch 1/500, Generator Loss: 0.1563, Discriminator Loss: 0.0464\n",
            "Epoch 1/500, Generator Loss: 0.1563, Discriminator Loss: 0.0464\n",
            "Epoch 1/500, Generator Loss: 0.1563, Discriminator Loss: 0.0464\n",
            "Epoch 1/500, Generator Loss: 0.1563, Discriminator Loss: 0.0464\n",
            "Epoch 1/500, Generator Loss: 0.1562, Discriminator Loss: 0.0463\n",
            "Epoch 1/500, Generator Loss: 0.1562, Discriminator Loss: 0.0463\n",
            "Epoch 1/500, Generator Loss: 0.1562, Discriminator Loss: 0.0463\n",
            "Epoch 1/500, Generator Loss: 0.1562, Discriminator Loss: 0.0463\n",
            "Epoch 1/500, Generator Loss: 0.1561, Discriminator Loss: 0.0463\n",
            "Epoch 1/500, Generator Loss: 0.1561, Discriminator Loss: 0.0462\n",
            "Epoch 1/500, Generator Loss: 0.1561, Discriminator Loss: 0.0462\n",
            "Epoch 2/500, Generator Loss: 0.1250, Discriminator Loss: 0.0220\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 3/500, Generator Loss: 0.1257, Discriminator Loss: 0.0164\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 4/500, Generator Loss: 0.1248, Discriminator Loss: 0.0123\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 5/500, Generator Loss: 0.1232, Discriminator Loss: 0.0113\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 6/500, Generator Loss: 0.1224, Discriminator Loss: 0.0124\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 7/500, Generator Loss: 0.1216, Discriminator Loss: 0.0176\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 8/500, Generator Loss: 0.1260, Discriminator Loss: 0.0367\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 9/500, Generator Loss: 0.1209, Discriminator Loss: 0.0152\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 10/500, Generator Loss: 0.1217, Discriminator Loss: 0.0127\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 11/500, Generator Loss: 0.1203, Discriminator Loss: 0.0124\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 12/500, Generator Loss: 0.1177, Discriminator Loss: 0.0101\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 13/500, Generator Loss: 0.1173, Discriminator Loss: 0.0067\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 14/500, Generator Loss: 0.1149, Discriminator Loss: 0.0076\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 15/500, Generator Loss: 0.1154, Discriminator Loss: 0.0076\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 16/500, Generator Loss: 0.1137, Discriminator Loss: 0.0119\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 17/500, Generator Loss: 0.1172, Discriminator Loss: 0.0260\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 18/500, Generator Loss: 0.1149, Discriminator Loss: 0.0153\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 19/500, Generator Loss: 0.1150, Discriminator Loss: 0.0161\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 20/500, Generator Loss: 0.1128, Discriminator Loss: 0.0070\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 21/500, Generator Loss: 0.1106, Discriminator Loss: 0.0078\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 22/500, Generator Loss: 0.1110, Discriminator Loss: 0.0094\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 23/500, Generator Loss: 0.1082, Discriminator Loss: 0.0102\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 24/500, Generator Loss: 0.1114, Discriminator Loss: 0.0126\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 25/500, Generator Loss: 0.1071, Discriminator Loss: 0.0130\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 26/500, Generator Loss: 0.1105, Discriminator Loss: 0.0114\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 27/500, Generator Loss: 0.1064, Discriminator Loss: 0.0089\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 28/500, Generator Loss: 0.1073, Discriminator Loss: 0.0111\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 29/500, Generator Loss: 0.1079, Discriminator Loss: 0.0138\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 30/500, Generator Loss: 0.1090, Discriminator Loss: 0.0239\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 31/500, Generator Loss: 0.1118, Discriminator Loss: 0.0222\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 32/500, Generator Loss: 0.1060, Discriminator Loss: 0.0083\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 33/500, Generator Loss: 0.1026, Discriminator Loss: 0.0099\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 34/500, Generator Loss: 0.1045, Discriminator Loss: 0.0074\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 35/500, Generator Loss: 0.1012, Discriminator Loss: 0.0059\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 36/500, Generator Loss: 0.1010, Discriminator Loss: 0.0066\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 37/500, Generator Loss: 0.1000, Discriminator Loss: 0.0079\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 38/500, Generator Loss: 0.1003, Discriminator Loss: 0.0108\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 39/500, Generator Loss: 0.0988, Discriminator Loss: 0.0166\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 40/500, Generator Loss: 0.1027, Discriminator Loss: 0.0144\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 41/500, Generator Loss: 0.0992, Discriminator Loss: 0.0119\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 42/500, Generator Loss: 0.1004, Discriminator Loss: 0.0142\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 43/500, Generator Loss: 0.0986, Discriminator Loss: 0.0125\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 44/500, Generator Loss: 0.1010, Discriminator Loss: 0.0208\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 45/500, Generator Loss: 0.0977, Discriminator Loss: 0.0225\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 46/500, Generator Loss: 0.1055, Discriminator Loss: 0.0372\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 47/500, Generator Loss: 0.1022, Discriminator Loss: 0.0105\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 48/500, Generator Loss: 0.0992, Discriminator Loss: 0.0125\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 49/500, Generator Loss: 0.0970, Discriminator Loss: 0.0101\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 50/500, Generator Loss: 0.0941, Discriminator Loss: 0.0078\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 51/500, Generator Loss: 0.0954, Discriminator Loss: 0.0056\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 52/500, Generator Loss: 0.0928, Discriminator Loss: 0.0063\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 53/500, Generator Loss: 0.0939, Discriminator Loss: 0.0076\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 54/500, Generator Loss: 0.0912, Discriminator Loss: 0.0095\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 55/500, Generator Loss: 0.0949, Discriminator Loss: 0.0121\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 56/500, Generator Loss: 0.0931, Discriminator Loss: 0.0089\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 57/500, Generator Loss: 0.0921, Discriminator Loss: 0.0093\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 58/500, Generator Loss: 0.0926, Discriminator Loss: 0.0069\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 59/500, Generator Loss: 0.0887, Discriminator Loss: 0.0083\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 60/500, Generator Loss: 0.0921, Discriminator Loss: 0.0096\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 61/500, Generator Loss: 0.0881, Discriminator Loss: 0.0100\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 62/500, Generator Loss: 0.0919, Discriminator Loss: 0.0105\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 63/500, Generator Loss: 0.0869, Discriminator Loss: 0.0070\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 64/500, Generator Loss: 0.0881, Discriminator Loss: 0.0059\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 65/500, Generator Loss: 0.0866, Discriminator Loss: 0.0068\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 66/500, Generator Loss: 0.0876, Discriminator Loss: 0.0098\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 67/500, Generator Loss: 0.0866, Discriminator Loss: 0.0091\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 68/500, Generator Loss: 0.0889, Discriminator Loss: 0.0121\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 69/500, Generator Loss: 0.0855, Discriminator Loss: 0.0074\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 70/500, Generator Loss: 0.0846, Discriminator Loss: 0.0080\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 71/500, Generator Loss: 0.0853, Discriminator Loss: 0.0093\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 72/500, Generator Loss: 0.0840, Discriminator Loss: 0.0095\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 73/500, Generator Loss: 0.0860, Discriminator Loss: 0.0097\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 74/500, Generator Loss: 0.0835, Discriminator Loss: 0.0087\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 75/500, Generator Loss: 0.0874, Discriminator Loss: 0.0110\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 76/500, Generator Loss: 0.0841, Discriminator Loss: 0.0172\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 77/500, Generator Loss: 0.0910, Discriminator Loss: 0.0262\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 78/500, Generator Loss: 0.0870, Discriminator Loss: 0.0103\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 79/500, Generator Loss: 0.0821, Discriminator Loss: 0.0100\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 80/500, Generator Loss: 0.0856, Discriminator Loss: 0.0094\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 81/500, Generator Loss: 0.0817, Discriminator Loss: 0.0064\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 82/500, Generator Loss: 0.0814, Discriminator Loss: 0.0059\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 83/500, Generator Loss: 0.0802, Discriminator Loss: 0.0047\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 84/500, Generator Loss: 0.0802, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 85/500, Generator Loss: 0.0786, Discriminator Loss: 0.0054\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 86/500, Generator Loss: 0.0819, Discriminator Loss: 0.0064\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 87/500, Generator Loss: 0.0785, Discriminator Loss: 0.0070\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 88/500, Generator Loss: 0.0805, Discriminator Loss: 0.0066\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 89/500, Generator Loss: 0.0787, Discriminator Loss: 0.0073\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 90/500, Generator Loss: 0.0791, Discriminator Loss: 0.0086\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 91/500, Generator Loss: 0.0810, Discriminator Loss: 0.0098\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 92/500, Generator Loss: 0.0776, Discriminator Loss: 0.0097\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 93/500, Generator Loss: 0.0810, Discriminator Loss: 0.0103\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 94/500, Generator Loss: 0.0769, Discriminator Loss: 0.0093\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 95/500, Generator Loss: 0.0801, Discriminator Loss: 0.0119\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 96/500, Generator Loss: 0.0784, Discriminator Loss: 0.0113\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 97/500, Generator Loss: 0.0785, Discriminator Loss: 0.0098\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 98/500, Generator Loss: 0.0764, Discriminator Loss: 0.0051\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 99/500, Generator Loss: 0.0756, Discriminator Loss: 0.0058\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 100/500, Generator Loss: 0.0763, Discriminator Loss: 0.0063\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 101/500, Generator Loss: 0.0750, Discriminator Loss: 0.0074\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 102/500, Generator Loss: 0.0769, Discriminator Loss: 0.0110\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 103/500, Generator Loss: 0.0764, Discriminator Loss: 0.0070\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 104/500, Generator Loss: 0.0735, Discriminator Loss: 0.0088\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 105/500, Generator Loss: 0.0769, Discriminator Loss: 0.0077\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 106/500, Generator Loss: 0.0725, Discriminator Loss: 0.0072\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 107/500, Generator Loss: 0.0763, Discriminator Loss: 0.0084\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 108/500, Generator Loss: 0.0732, Discriminator Loss: 0.0083\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 109/500, Generator Loss: 0.0763, Discriminator Loss: 0.0094\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 110/500, Generator Loss: 0.0732, Discriminator Loss: 0.0062\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 111/500, Generator Loss: 0.0756, Discriminator Loss: 0.0067\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 112/500, Generator Loss: 0.0726, Discriminator Loss: 0.0100\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 113/500, Generator Loss: 0.0751, Discriminator Loss: 0.0097\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 114/500, Generator Loss: 0.0726, Discriminator Loss: 0.0098\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 115/500, Generator Loss: 0.0722, Discriminator Loss: 0.0048\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 116/500, Generator Loss: 0.0707, Discriminator Loss: 0.0048\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 117/500, Generator Loss: 0.0708, Discriminator Loss: 0.0040\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 118/500, Generator Loss: 0.0696, Discriminator Loss: 0.0036\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 119/500, Generator Loss: 0.0699, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 120/500, Generator Loss: 0.0691, Discriminator Loss: 0.0054\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 121/500, Generator Loss: 0.0731, Discriminator Loss: 0.0096\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 122/500, Generator Loss: 0.0697, Discriminator Loss: 0.0087\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 123/500, Generator Loss: 0.0731, Discriminator Loss: 0.0105\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 124/500, Generator Loss: 0.0701, Discriminator Loss: 0.0053\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 125/500, Generator Loss: 0.0696, Discriminator Loss: 0.0050\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 126/500, Generator Loss: 0.0706, Discriminator Loss: 0.0059\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 127/500, Generator Loss: 0.0700, Discriminator Loss: 0.0059\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 128/500, Generator Loss: 0.0714, Discriminator Loss: 0.0067\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 129/500, Generator Loss: 0.0701, Discriminator Loss: 0.0069\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 130/500, Generator Loss: 0.0727, Discriminator Loss: 0.0107\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 131/500, Generator Loss: 0.0689, Discriminator Loss: 0.0055\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 132/500, Generator Loss: 0.0689, Discriminator Loss: 0.0058\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 133/500, Generator Loss: 0.0681, Discriminator Loss: 0.0061\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 134/500, Generator Loss: 0.0722, Discriminator Loss: 0.0081\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 135/500, Generator Loss: 0.0673, Discriminator Loss: 0.0103\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 136/500, Generator Loss: 0.0710, Discriminator Loss: 0.0101\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 137/500, Generator Loss: 0.0672, Discriminator Loss: 0.0058\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 138/500, Generator Loss: 0.0664, Discriminator Loss: 0.0049\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 139/500, Generator Loss: 0.0665, Discriminator Loss: 0.0029\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 140/500, Generator Loss: 0.0647, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 141/500, Generator Loss: 0.0665, Discriminator Loss: 0.0026\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 142/500, Generator Loss: 0.0649, Discriminator Loss: 0.0053\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 143/500, Generator Loss: 0.0696, Discriminator Loss: 0.0101\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 144/500, Generator Loss: 0.0670, Discriminator Loss: 0.0056\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 145/500, Generator Loss: 0.0659, Discriminator Loss: 0.0076\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 146/500, Generator Loss: 0.0685, Discriminator Loss: 0.0073\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 147/500, Generator Loss: 0.0652, Discriminator Loss: 0.0060\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 148/500, Generator Loss: 0.0654, Discriminator Loss: 0.0040\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 149/500, Generator Loss: 0.0639, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 150/500, Generator Loss: 0.0662, Discriminator Loss: 0.0045\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 151/500, Generator Loss: 0.0639, Discriminator Loss: 0.0062\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 152/500, Generator Loss: 0.0695, Discriminator Loss: 0.0105\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 153/500, Generator Loss: 0.0640, Discriminator Loss: 0.0037\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 154/500, Generator Loss: 0.0625, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 155/500, Generator Loss: 0.0649, Discriminator Loss: 0.0042\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 156/500, Generator Loss: 0.0632, Discriminator Loss: 0.0036\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 157/500, Generator Loss: 0.0632, Discriminator Loss: 0.0048\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 158/500, Generator Loss: 0.0641, Discriminator Loss: 0.0051\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 159/500, Generator Loss: 0.0666, Discriminator Loss: 0.0073\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 160/500, Generator Loss: 0.0663, Discriminator Loss: 0.0099\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 161/500, Generator Loss: 0.0713, Discriminator Loss: 0.0130\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 162/500, Generator Loss: 0.0650, Discriminator Loss: 0.0079\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 163/500, Generator Loss: 0.0641, Discriminator Loss: 0.0057\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 164/500, Generator Loss: 0.0635, Discriminator Loss: 0.0053\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 165/500, Generator Loss: 0.0629, Discriminator Loss: 0.0054\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 166/500, Generator Loss: 0.0620, Discriminator Loss: 0.0070\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 167/500, Generator Loss: 0.0659, Discriminator Loss: 0.0122\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 168/500, Generator Loss: 0.0618, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 169/500, Generator Loss: 0.0604, Discriminator Loss: 0.0042\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 170/500, Generator Loss: 0.0624, Discriminator Loss: 0.0036\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 171/500, Generator Loss: 0.0614, Discriminator Loss: 0.0040\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 172/500, Generator Loss: 0.0612, Discriminator Loss: 0.0041\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 173/500, Generator Loss: 0.0613, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 174/500, Generator Loss: 0.0604, Discriminator Loss: 0.0029\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 175/500, Generator Loss: 0.0600, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 176/500, Generator Loss: 0.0605, Discriminator Loss: 0.0027\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 177/500, Generator Loss: 0.0609, Discriminator Loss: 0.0047\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 178/500, Generator Loss: 0.0676, Discriminator Loss: 0.0105\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 179/500, Generator Loss: 0.0637, Discriminator Loss: 0.0059\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 180/500, Generator Loss: 0.0618, Discriminator Loss: 0.0047\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 181/500, Generator Loss: 0.0600, Discriminator Loss: 0.0031\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 182/500, Generator Loss: 0.0596, Discriminator Loss: 0.0031\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 183/500, Generator Loss: 0.0596, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 184/500, Generator Loss: 0.0594, Discriminator Loss: 0.0041\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 185/500, Generator Loss: 0.0599, Discriminator Loss: 0.0046\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 186/500, Generator Loss: 0.0603, Discriminator Loss: 0.0050\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 187/500, Generator Loss: 0.0597, Discriminator Loss: 0.0058\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 188/500, Generator Loss: 0.0617, Discriminator Loss: 0.0063\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 189/500, Generator Loss: 0.0600, Discriminator Loss: 0.0056\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 190/500, Generator Loss: 0.0617, Discriminator Loss: 0.0072\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 191/500, Generator Loss: 0.0610, Discriminator Loss: 0.0086\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 192/500, Generator Loss: 0.0681, Discriminator Loss: 0.0182\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 193/500, Generator Loss: 0.0632, Discriminator Loss: 0.0085\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 194/500, Generator Loss: 0.0609, Discriminator Loss: 0.0050\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 195/500, Generator Loss: 0.0593, Discriminator Loss: 0.0064\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 196/500, Generator Loss: 0.0595, Discriminator Loss: 0.0043\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 197/500, Generator Loss: 0.0612, Discriminator Loss: 0.0080\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 198/500, Generator Loss: 0.0591, Discriminator Loss: 0.0058\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 199/500, Generator Loss: 0.0615, Discriminator Loss: 0.0052\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 200/500, Generator Loss: 0.0581, Discriminator Loss: 0.0055\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 201/500, Generator Loss: 0.0600, Discriminator Loss: 0.0042\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 202/500, Generator Loss: 0.0580, Discriminator Loss: 0.0031\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 203/500, Generator Loss: 0.0571, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 204/500, Generator Loss: 0.0576, Discriminator Loss: 0.0029\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 205/500, Generator Loss: 0.0565, Discriminator Loss: 0.0045\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 206/500, Generator Loss: 0.0606, Discriminator Loss: 0.0068\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 207/500, Generator Loss: 0.0572, Discriminator Loss: 0.0064\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 208/500, Generator Loss: 0.0601, Discriminator Loss: 0.0051\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 209/500, Generator Loss: 0.0567, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 210/500, Generator Loss: 0.0564, Discriminator Loss: 0.0023\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 211/500, Generator Loss: 0.0567, Discriminator Loss: 0.0022\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 212/500, Generator Loss: 0.0555, Discriminator Loss: 0.0029\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 213/500, Generator Loss: 0.0577, Discriminator Loss: 0.0029\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 214/500, Generator Loss: 0.0566, Discriminator Loss: 0.0036\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 215/500, Generator Loss: 0.0597, Discriminator Loss: 0.0055\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 216/500, Generator Loss: 0.0582, Discriminator Loss: 0.0042\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 217/500, Generator Loss: 0.0581, Discriminator Loss: 0.0059\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 218/500, Generator Loss: 0.0588, Discriminator Loss: 0.0062\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 219/500, Generator Loss: 0.0578, Discriminator Loss: 0.0057\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 220/500, Generator Loss: 0.0567, Discriminator Loss: 0.0042\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 221/500, Generator Loss: 0.0556, Discriminator Loss: 0.0027\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 222/500, Generator Loss: 0.0550, Discriminator Loss: 0.0028\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 223/500, Generator Loss: 0.0551, Discriminator Loss: 0.0027\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 224/500, Generator Loss: 0.0558, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 225/500, Generator Loss: 0.0558, Discriminator Loss: 0.0049\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 226/500, Generator Loss: 0.0602, Discriminator Loss: 0.0077\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 227/500, Generator Loss: 0.0602, Discriminator Loss: 0.0081\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 228/500, Generator Loss: 0.0615, Discriminator Loss: 0.0099\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 229/500, Generator Loss: 0.0590, Discriminator Loss: 0.0074\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 230/500, Generator Loss: 0.0561, Discriminator Loss: 0.0097\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 231/500, Generator Loss: 0.0566, Discriminator Loss: 0.0060\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 232/500, Generator Loss: 0.0557, Discriminator Loss: 0.0056\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 233/500, Generator Loss: 0.0546, Discriminator Loss: 0.0058\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 234/500, Generator Loss: 0.0584, Discriminator Loss: 0.0075\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 235/500, Generator Loss: 0.0553, Discriminator Loss: 0.0043\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 236/500, Generator Loss: 0.0568, Discriminator Loss: 0.0071\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 237/500, Generator Loss: 0.0584, Discriminator Loss: 0.0076\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 238/500, Generator Loss: 0.0629, Discriminator Loss: 0.0123\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 239/500, Generator Loss: 0.0570, Discriminator Loss: 0.0074\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 240/500, Generator Loss: 0.0565, Discriminator Loss: 0.0073\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 241/500, Generator Loss: 0.0560, Discriminator Loss: 0.0037\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 242/500, Generator Loss: 0.0541, Discriminator Loss: 0.0047\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 243/500, Generator Loss: 0.0561, Discriminator Loss: 0.0039\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 244/500, Generator Loss: 0.0537, Discriminator Loss: 0.0039\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 245/500, Generator Loss: 0.0549, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 246/500, Generator Loss: 0.0531, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 247/500, Generator Loss: 0.0531, Discriminator Loss: 0.0027\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 248/500, Generator Loss: 0.0526, Discriminator Loss: 0.0020\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 249/500, Generator Loss: 0.0529, Discriminator Loss: 0.0031\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 250/500, Generator Loss: 0.0533, Discriminator Loss: 0.0033\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 251/500, Generator Loss: 0.0560, Discriminator Loss: 0.0064\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 252/500, Generator Loss: 0.0560, Discriminator Loss: 0.0047\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 253/500, Generator Loss: 0.0579, Discriminator Loss: 0.0057\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 254/500, Generator Loss: 0.0550, Discriminator Loss: 0.0031\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 255/500, Generator Loss: 0.0540, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 256/500, Generator Loss: 0.0541, Discriminator Loss: 0.0047\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 257/500, Generator Loss: 0.0554, Discriminator Loss: 0.0057\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 258/500, Generator Loss: 0.0562, Discriminator Loss: 0.0064\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 259/500, Generator Loss: 0.0549, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 260/500, Generator Loss: 0.0527, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 261/500, Generator Loss: 0.0517, Discriminator Loss: 0.0021\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 262/500, Generator Loss: 0.0515, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 263/500, Generator Loss: 0.0527, Discriminator Loss: 0.0031\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 264/500, Generator Loss: 0.0514, Discriminator Loss: 0.0048\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 265/500, Generator Loss: 0.0557, Discriminator Loss: 0.0057\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 266/500, Generator Loss: 0.0524, Discriminator Loss: 0.0053\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 267/500, Generator Loss: 0.0551, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 268/500, Generator Loss: 0.0534, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 269/500, Generator Loss: 0.0528, Discriminator Loss: 0.0037\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 270/500, Generator Loss: 0.0532, Discriminator Loss: 0.0033\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 271/500, Generator Loss: 0.0541, Discriminator Loss: 0.0051\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 272/500, Generator Loss: 0.0534, Discriminator Loss: 0.0035\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 273/500, Generator Loss: 0.0530, Discriminator Loss: 0.0052\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 274/500, Generator Loss: 0.0517, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 275/500, Generator Loss: 0.0516, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 276/500, Generator Loss: 0.0514, Discriminator Loss: 0.0036\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 277/500, Generator Loss: 0.0522, Discriminator Loss: 0.0037\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 278/500, Generator Loss: 0.0523, Discriminator Loss: 0.0041\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 279/500, Generator Loss: 0.0525, Discriminator Loss: 0.0045\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 280/500, Generator Loss: 0.0534, Discriminator Loss: 0.0047\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 281/500, Generator Loss: 0.0521, Discriminator Loss: 0.0049\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 282/500, Generator Loss: 0.0536, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 283/500, Generator Loss: 0.0511, Discriminator Loss: 0.0033\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 284/500, Generator Loss: 0.0522, Discriminator Loss: 0.0027\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 285/500, Generator Loss: 0.0521, Discriminator Loss: 0.0029\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 286/500, Generator Loss: 0.0536, Discriminator Loss: 0.0031\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 287/500, Generator Loss: 0.0527, Discriminator Loss: 0.0037\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 288/500, Generator Loss: 0.0552, Discriminator Loss: 0.0051\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 289/500, Generator Loss: 0.0518, Discriminator Loss: 0.0028\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 290/500, Generator Loss: 0.0520, Discriminator Loss: 0.0052\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 291/500, Generator Loss: 0.0540, Discriminator Loss: 0.0058\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 292/500, Generator Loss: 0.0542, Discriminator Loss: 0.0080\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 293/500, Generator Loss: 0.0535, Discriminator Loss: 0.0049\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 294/500, Generator Loss: 0.0508, Discriminator Loss: 0.0023\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 295/500, Generator Loss: 0.0488, Discriminator Loss: 0.0022\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 296/500, Generator Loss: 0.0501, Discriminator Loss: 0.0016\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 297/500, Generator Loss: 0.0490, Discriminator Loss: 0.0028\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 298/500, Generator Loss: 0.0510, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 299/500, Generator Loss: 0.0506, Discriminator Loss: 0.0049\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 300/500, Generator Loss: 0.0533, Discriminator Loss: 0.0056\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 301/500, Generator Loss: 0.0511, Discriminator Loss: 0.0041\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 302/500, Generator Loss: 0.0511, Discriminator Loss: 0.0037\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 303/500, Generator Loss: 0.0505, Discriminator Loss: 0.0032\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 304/500, Generator Loss: 0.0514, Discriminator Loss: 0.0055\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 305/500, Generator Loss: 0.0512, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 306/500, Generator Loss: 0.0523, Discriminator Loss: 0.0069\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 307/500, Generator Loss: 0.0516, Discriminator Loss: 0.0043\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 308/500, Generator Loss: 0.0535, Discriminator Loss: 0.0058\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 309/500, Generator Loss: 0.0531, Discriminator Loss: 0.0052\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 310/500, Generator Loss: 0.0531, Discriminator Loss: 0.0053\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 311/500, Generator Loss: 0.0495, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 312/500, Generator Loss: 0.0512, Discriminator Loss: 0.0038\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 313/500, Generator Loss: 0.0496, Discriminator Loss: 0.0024\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 314/500, Generator Loss: 0.0484, Discriminator Loss: 0.0031\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 315/500, Generator Loss: 0.0503, Discriminator Loss: 0.0021\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 316/500, Generator Loss: 0.0492, Discriminator Loss: 0.0037\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 317/500, Generator Loss: 0.0518, Discriminator Loss: 0.0039\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 318/500, Generator Loss: 0.0508, Discriminator Loss: 0.0046\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 319/500, Generator Loss: 0.0524, Discriminator Loss: 0.0056\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 320/500, Generator Loss: 0.0510, Discriminator Loss: 0.0047\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 321/500, Generator Loss: 0.0512, Discriminator Loss: 0.0055\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 322/500, Generator Loss: 0.0497, Discriminator Loss: 0.0040\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 323/500, Generator Loss: 0.0494, Discriminator Loss: 0.0040\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 324/500, Generator Loss: 0.0481, Discriminator Loss: 0.0021\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 325/500, Generator Loss: 0.0476, Discriminator Loss: 0.0018\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 326/500, Generator Loss: 0.0473, Discriminator Loss: 0.0022\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 327/500, Generator Loss: 0.0481, Discriminator Loss: 0.0024\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 328/500, Generator Loss: 0.0481, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 329/500, Generator Loss: 0.0520, Discriminator Loss: 0.0043\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 330/500, Generator Loss: 0.0512, Discriminator Loss: 0.0058\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 331/500, Generator Loss: 0.0579, Discriminator Loss: 0.0089\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 332/500, Generator Loss: 0.0517, Discriminator Loss: 0.0039\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 333/500, Generator Loss: 0.0477, Discriminator Loss: 0.0052\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 334/500, Generator Loss: 0.0506, Discriminator Loss: 0.0029\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 335/500, Generator Loss: 0.0472, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 336/500, Generator Loss: 0.0475, Discriminator Loss: 0.0023\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 337/500, Generator Loss: 0.0486, Discriminator Loss: 0.0026\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 338/500, Generator Loss: 0.0482, Discriminator Loss: 0.0040\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 339/500, Generator Loss: 0.0493, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 340/500, Generator Loss: 0.0503, Discriminator Loss: 0.0055\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 341/500, Generator Loss: 0.0495, Discriminator Loss: 0.0043\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 342/500, Generator Loss: 0.0497, Discriminator Loss: 0.0052\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 343/500, Generator Loss: 0.0499, Discriminator Loss: 0.0053\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 344/500, Generator Loss: 0.0505, Discriminator Loss: 0.0049\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 345/500, Generator Loss: 0.0488, Discriminator Loss: 0.0036\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 346/500, Generator Loss: 0.0503, Discriminator Loss: 0.0043\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 347/500, Generator Loss: 0.0488, Discriminator Loss: 0.0043\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 348/500, Generator Loss: 0.0514, Discriminator Loss: 0.0071\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 349/500, Generator Loss: 0.0498, Discriminator Loss: 0.0049\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 350/500, Generator Loss: 0.0501, Discriminator Loss: 0.0052\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 351/500, Generator Loss: 0.0483, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 352/500, Generator Loss: 0.0481, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 353/500, Generator Loss: 0.0472, Discriminator Loss: 0.0024\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 354/500, Generator Loss: 0.0472, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 355/500, Generator Loss: 0.0474, Discriminator Loss: 0.0029\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 356/500, Generator Loss: 0.0479, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 357/500, Generator Loss: 0.0492, Discriminator Loss: 0.0049\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 358/500, Generator Loss: 0.0496, Discriminator Loss: 0.0038\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 359/500, Generator Loss: 0.0491, Discriminator Loss: 0.0050\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 360/500, Generator Loss: 0.0494, Discriminator Loss: 0.0033\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 361/500, Generator Loss: 0.0482, Discriminator Loss: 0.0041\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 362/500, Generator Loss: 0.0485, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 363/500, Generator Loss: 0.0479, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 364/500, Generator Loss: 0.0469, Discriminator Loss: 0.0039\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 365/500, Generator Loss: 0.0475, Discriminator Loss: 0.0028\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 366/500, Generator Loss: 0.0470, Discriminator Loss: 0.0036\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 367/500, Generator Loss: 0.0471, Discriminator Loss: 0.0031\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 368/500, Generator Loss: 0.0485, Discriminator Loss: 0.0035\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 369/500, Generator Loss: 0.0487, Discriminator Loss: 0.0042\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 370/500, Generator Loss: 0.0536, Discriminator Loss: 0.0076\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 371/500, Generator Loss: 0.0492, Discriminator Loss: 0.0039\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 372/500, Generator Loss: 0.0470, Discriminator Loss: 0.0037\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 373/500, Generator Loss: 0.0462, Discriminator Loss: 0.0022\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 374/500, Generator Loss: 0.0456, Discriminator Loss: 0.0021\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 375/500, Generator Loss: 0.0455, Discriminator Loss: 0.0022\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 376/500, Generator Loss: 0.0460, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 377/500, Generator Loss: 0.0457, Discriminator Loss: 0.0033\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 378/500, Generator Loss: 0.0469, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 379/500, Generator Loss: 0.0469, Discriminator Loss: 0.0043\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 380/500, Generator Loss: 0.0479, Discriminator Loss: 0.0059\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 381/500, Generator Loss: 0.0474, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 382/500, Generator Loss: 0.0483, Discriminator Loss: 0.0054\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 383/500, Generator Loss: 0.0475, Discriminator Loss: 0.0039\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 384/500, Generator Loss: 0.0499, Discriminator Loss: 0.0045\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 385/500, Generator Loss: 0.0475, Discriminator Loss: 0.0027\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 386/500, Generator Loss: 0.0475, Discriminator Loss: 0.0028\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 387/500, Generator Loss: 0.0480, Discriminator Loss: 0.0042\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 388/500, Generator Loss: 0.0496, Discriminator Loss: 0.0048\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 389/500, Generator Loss: 0.0491, Discriminator Loss: 0.0042\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 390/500, Generator Loss: 0.0489, Discriminator Loss: 0.0036\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 391/500, Generator Loss: 0.0470, Discriminator Loss: 0.0031\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 392/500, Generator Loss: 0.0452, Discriminator Loss: 0.0035\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 393/500, Generator Loss: 0.0466, Discriminator Loss: 0.0033\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 394/500, Generator Loss: 0.0461, Discriminator Loss: 0.0041\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 395/500, Generator Loss: 0.0475, Discriminator Loss: 0.0040\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 396/500, Generator Loss: 0.0458, Discriminator Loss: 0.0037\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 397/500, Generator Loss: 0.0461, Discriminator Loss: 0.0038\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 398/500, Generator Loss: 0.0467, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 399/500, Generator Loss: 0.0474, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 400/500, Generator Loss: 0.0494, Discriminator Loss: 0.0061\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 401/500, Generator Loss: 0.0491, Discriminator Loss: 0.0055\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 402/500, Generator Loss: 0.0516, Discriminator Loss: 0.0077\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 403/500, Generator Loss: 0.0481, Discriminator Loss: 0.0038\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 404/500, Generator Loss: 0.0467, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 405/500, Generator Loss: 0.0448, Discriminator Loss: 0.0027\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 406/500, Generator Loss: 0.0454, Discriminator Loss: 0.0020\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 407/500, Generator Loss: 0.0440, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 408/500, Generator Loss: 0.0454, Discriminator Loss: 0.0022\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 409/500, Generator Loss: 0.0449, Discriminator Loss: 0.0032\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 410/500, Generator Loss: 0.0461, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 411/500, Generator Loss: 0.0460, Discriminator Loss: 0.0037\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 412/500, Generator Loss: 0.0464, Discriminator Loss: 0.0026\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 413/500, Generator Loss: 0.0469, Discriminator Loss: 0.0046\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 414/500, Generator Loss: 0.0474, Discriminator Loss: 0.0046\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 415/500, Generator Loss: 0.0516, Discriminator Loss: 0.0081\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 416/500, Generator Loss: 0.0462, Discriminator Loss: 0.0039\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 417/500, Generator Loss: 0.0448, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 418/500, Generator Loss: 0.0445, Discriminator Loss: 0.0032\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 419/500, Generator Loss: 0.0442, Discriminator Loss: 0.0022\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 420/500, Generator Loss: 0.0437, Discriminator Loss: 0.0022\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 421/500, Generator Loss: 0.0438, Discriminator Loss: 0.0019\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 422/500, Generator Loss: 0.0438, Discriminator Loss: 0.0021\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 423/500, Generator Loss: 0.0445, Discriminator Loss: 0.0023\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 424/500, Generator Loss: 0.0447, Discriminator Loss: 0.0026\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 425/500, Generator Loss: 0.0458, Discriminator Loss: 0.0033\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 426/500, Generator Loss: 0.0454, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 427/500, Generator Loss: 0.0455, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 428/500, Generator Loss: 0.0443, Discriminator Loss: 0.0028\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 429/500, Generator Loss: 0.0457, Discriminator Loss: 0.0029\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 430/500, Generator Loss: 0.0450, Discriminator Loss: 0.0042\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 431/500, Generator Loss: 0.0494, Discriminator Loss: 0.0055\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 432/500, Generator Loss: 0.0477, Discriminator Loss: 0.0054\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 433/500, Generator Loss: 0.0482, Discriminator Loss: 0.0049\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 434/500, Generator Loss: 0.0453, Discriminator Loss: 0.0026\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 435/500, Generator Loss: 0.0431, Discriminator Loss: 0.0027\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 436/500, Generator Loss: 0.0445, Discriminator Loss: 0.0019\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 437/500, Generator Loss: 0.0441, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 438/500, Generator Loss: 0.0452, Discriminator Loss: 0.0035\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 439/500, Generator Loss: 0.0469, Discriminator Loss: 0.0058\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 440/500, Generator Loss: 0.0451, Discriminator Loss: 0.0050\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 441/500, Generator Loss: 0.0478, Discriminator Loss: 0.0073\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 442/500, Generator Loss: 0.0458, Discriminator Loss: 0.0036\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 443/500, Generator Loss: 0.0460, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 444/500, Generator Loss: 0.0472, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 445/500, Generator Loss: 0.0447, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 446/500, Generator Loss: 0.0436, Discriminator Loss: 0.0026\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 447/500, Generator Loss: 0.0441, Discriminator Loss: 0.0026\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 448/500, Generator Loss: 0.0433, Discriminator Loss: 0.0023\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 449/500, Generator Loss: 0.0428, Discriminator Loss: 0.0027\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 450/500, Generator Loss: 0.0438, Discriminator Loss: 0.0021\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 451/500, Generator Loss: 0.0426, Discriminator Loss: 0.0031\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 452/500, Generator Loss: 0.0439, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 453/500, Generator Loss: 0.0430, Discriminator Loss: 0.0032\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 454/500, Generator Loss: 0.0436, Discriminator Loss: 0.0033\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 455/500, Generator Loss: 0.0450, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 456/500, Generator Loss: 0.0455, Discriminator Loss: 0.0038\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 457/500, Generator Loss: 0.0465, Discriminator Loss: 0.0038\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 458/500, Generator Loss: 0.0458, Discriminator Loss: 0.0033\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 459/500, Generator Loss: 0.0439, Discriminator Loss: 0.0039\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 460/500, Generator Loss: 0.0437, Discriminator Loss: 0.0029\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 461/500, Generator Loss: 0.0425, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 462/500, Generator Loss: 0.0433, Discriminator Loss: 0.0023\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 463/500, Generator Loss: 0.0424, Discriminator Loss: 0.0028\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 464/500, Generator Loss: 0.0445, Discriminator Loss: 0.0039\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 465/500, Generator Loss: 0.0451, Discriminator Loss: 0.0049\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 466/500, Generator Loss: 0.0498, Discriminator Loss: 0.0079\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 467/500, Generator Loss: 0.0475, Discriminator Loss: 0.0059\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 468/500, Generator Loss: 0.0486, Discriminator Loss: 0.0096\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 469/500, Generator Loss: 0.0454, Discriminator Loss: 0.0055\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 470/500, Generator Loss: 0.0428, Discriminator Loss: 0.0035\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 471/500, Generator Loss: 0.0421, Discriminator Loss: 0.0019\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 472/500, Generator Loss: 0.0420, Discriminator Loss: 0.0023\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 473/500, Generator Loss: 0.0431, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 474/500, Generator Loss: 0.0429, Discriminator Loss: 0.0037\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 475/500, Generator Loss: 0.0442, Discriminator Loss: 0.0037\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 476/500, Generator Loss: 0.0436, Discriminator Loss: 0.0057\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 477/500, Generator Loss: 0.0436, Discriminator Loss: 0.0036\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 478/500, Generator Loss: 0.0436, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 479/500, Generator Loss: 0.0434, Discriminator Loss: 0.0022\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 480/500, Generator Loss: 0.0448, Discriminator Loss: 0.0024\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 481/500, Generator Loss: 0.0441, Discriminator Loss: 0.0024\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 482/500, Generator Loss: 0.0453, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 483/500, Generator Loss: 0.0431, Discriminator Loss: 0.0022\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 484/500, Generator Loss: 0.0423, Discriminator Loss: 0.0025\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 485/500, Generator Loss: 0.0428, Discriminator Loss: 0.0019\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 486/500, Generator Loss: 0.0427, Discriminator Loss: 0.0032\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 487/500, Generator Loss: 0.0458, Discriminator Loss: 0.0032\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 488/500, Generator Loss: 0.0463, Discriminator Loss: 0.0050\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 489/500, Generator Loss: 0.0451, Discriminator Loss: 0.0032\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 490/500, Generator Loss: 0.0451, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 491/500, Generator Loss: 0.0427, Discriminator Loss: 0.0039\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 492/500, Generator Loss: 0.0454, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 493/500, Generator Loss: 0.0428, Discriminator Loss: 0.0030\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 494/500, Generator Loss: 0.0430, Discriminator Loss: 0.0029\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 495/500, Generator Loss: 0.0430, Discriminator Loss: 0.0027\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 496/500, Generator Loss: 0.0427, Discriminator Loss: 0.0034\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 497/500, Generator Loss: 0.0441, Discriminator Loss: 0.0044\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 498/500, Generator Loss: 0.0444, Discriminator Loss: 0.0051\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 499/500, Generator Loss: 0.0460, Discriminator Loss: 0.0059\n",
            "Generator loss threshold reached. Stopping training.\n",
            "Epoch 500/500, Generator Loss: 0.0439, Discriminator Loss: 0.0033\n",
            "Generator loss threshold reached. Stopping training.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU, Input, Conv2DTranspose, Add\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Function to add noise to an image\n",
        "def add_noise(image, noise_level=0.15):\n",
        "    noise = np.random.normal(0, noise_level, image.shape)\n",
        "    noisy_image = image + noise\n",
        "    return np.clip(noisy_image, 0, 1)\n",
        "\n",
        "# Load the clean MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Select a random image from the dataset\n",
        "index = np.random.randint(0, x_train.shape[0])\n",
        "\n",
        "# Clean image\n",
        "clean_image = x_train[index] / 255.0\n",
        "\n",
        "# Noisy image\n",
        "noisy_image = add_noise(clean_image)\n",
        "\n",
        "# Define the GAN, Generator, and Discriminator\n",
        "\n",
        "# Function to build a convolutional residual block\n",
        "def residual_block(x, filters, kernel_size=3):\n",
        "    y = Conv2D(filters, kernel_size, padding='same')(x)\n",
        "    y = BatchNormalization()(y)\n",
        "    y = LeakyReLU(alpha=0.2)(y)\n",
        "    y = Conv2D(filters, kernel_size, padding='same')(y)\n",
        "    y = BatchNormalization()(y)\n",
        "    return Add()([x, y])\n",
        "\n",
        "# Generator model\n",
        "def build_generator(input_shape=(28, 28, 1), num_residual_blocks=9):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Initial convolutional layer with LeakyReLU activation\n",
        "    x = Conv2D(32, (3, 3), activation=\"linear\", padding='same')(inputs)\n",
        "    x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "    # Downsample with convolutional blocks\n",
        "    for _ in range(3):\n",
        "        x = Conv2D(64, 4, strides=1, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Residual blocks\n",
        "    for _ in range(num_residual_blocks):\n",
        "        x = residual_block(x, 64)\n",
        "\n",
        "    # Upsample with transposed convolutional blocks\n",
        "    for _ in range(3):\n",
        "        x = Conv2DTranspose(64, 4, strides=1, padding='same')(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Output convolution\n",
        "    outputs = Conv2D(1, 3, activation='tanh', padding='same')(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# PatchGAN Discriminator model\n",
        "def build_patchgan_discriminator(input_shape=(28, 28, 1)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(64, (4, 4), strides=2, padding='same')(inputs)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(128, (4, 4), strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, (4, 4), strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(1, (4, 4), padding='same')(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=x)\n",
        "\n",
        "# Create the PatchGAN model\n",
        "def build_patchgan(generator_A, discriminator_A):\n",
        "    input_A = Input(shape=generator_A.input.shape[1:])\n",
        "\n",
        "    fake_A = generator_A(input_A)\n",
        "\n",
        "    discriminator_A.trainable = False\n",
        "\n",
        "    valid_A = discriminator_A(fake_A)\n",
        "\n",
        "    return Model(inputs=input_A, outputs=[valid_A, fake_A])\n",
        "\n",
        "# Train the PatchGAN to denoise MNIST data\n",
        "def train_patchgan(generator_A, discriminator_A, noisy_data, clean_data, batch_size, epochs, generator_loss_threshold=0.15):\n",
        "    patchgan_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        gen_losses = []\n",
        "        disc_losses = []\n",
        "\n",
        "        num_batches = len(noisy_data) // batch_size\n",
        "\n",
        "        for batch in range(num_batches):\n",
        "            batch_start = batch * batch_size\n",
        "            batch_end = (batch + 1) * batch_size\n",
        "            real_A = noisy_data[batch_start:batch_end]\n",
        "            real_A = tf.convert_to_tensor(real_A, dtype=tf.float32)\n",
        "\n",
        "            with tf.GradientTape(persistent=True) as tape:\n",
        "                fake_A = generator_A(real_A, training=True)\n",
        "\n",
        "                valid_A = discriminator_A(fake_A, training=True)\n",
        "\n",
        "                loss_G = tf.reduce_mean(tf.abs(real_A - fake_A))\n",
        "                loss_D_A = tf.reduce_mean(tf.square(valid_A))\n",
        "                total_loss = loss_G + loss_D_A\n",
        "\n",
        "            gradients = tape.gradient(total_loss, generator_A.trainable_variables)\n",
        "            patchgan_optimizer.apply_gradients(zip(gradients, generator_A.trainable_variables))\n",
        "\n",
        "            gen_losses.append(loss_G)\n",
        "            disc_losses.append(loss_D_A)\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}/{epochs}, Generator Loss: {tf.reduce_mean(gen_losses):.4f}, Discriminator Loss: {tf.reduce_mean(disc_losses):.4f}\")\n",
        "\n",
        "            if tf.reduce_mean(gen_losses) < generator_loss_threshold:\n",
        "                print(\"Generator loss threshold reached. Stopping training.\")\n",
        "                break\n",
        "\n",
        "    # Generate and print a noisy image and its denoised counterpart\n",
        "    sample_noisy = noisy_data[0:1]\n",
        "    sample_denoised = generator_A(sample_noisy, training=False)\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Noisy Image\")\n",
        "    plt.imshow(sample_noisy[0].reshape(28, 28), cmap='gray')\n",
        "\n",
        "    plt.axis('off')\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Denoised Image\")\n",
        "    plt.imshow(sample_denoised[0].numpy().reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Set hyperparameters\n",
        "batch_size = 50\n",
        "epochs_patchgan = 500\n",
        "\n",
        "# Prepare data\n",
        "num_samples = x_train.shape[0]\n",
        "noisy_data = np.array([add_noise(image / 255.0) for image in x_train])\n",
        "noisy_data = np.expand_dims(noisy_data, axis=-1)\n",
        "clean_data = np.expand_dims(x_train / 255.0, axis=-1)\n",
        "\n",
        "# Create and train the PatchGAN\n",
        "generator_A = build_generator()\n",
        "discriminator_A = build_patchgan_discriminator()  # Use PatchGAN discriminator\n",
        "\n",
        "# Train the PatchGAN with generator loss threshold\n",
        "train_patchgan(generator_A, discriminator_A, noisy_data, clean_data, batch_size, epochs_patchgan, generator_loss_threshold=0.15)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mr22FH9PlAig",
        "outputId": "e1e06772-5ada-40b1-993b-a74ba1889e2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 1, Gen Loss: 0.8209, Disc Loss: 3.0024\n",
            "Epoch 1, Batch 2, Gen Loss: 0.6531, Disc Loss: 1.6663\n",
            "Epoch 1, Batch 3, Gen Loss: 0.2939, Disc Loss: 1.2227\n",
            "Epoch 1, Batch 4, Gen Loss: 0.2708, Disc Loss: 1.0997\n",
            "Epoch 1, Batch 5, Gen Loss: 0.2012, Disc Loss: 0.9254\n",
            "Epoch 1, Batch 6, Gen Loss: 0.1526, Disc Loss: 0.8171\n",
            "Epoch 1, Batch 7, Gen Loss: 0.1173, Disc Loss: 0.7573\n",
            "Epoch 1, Batch 8, Gen Loss: 0.1062, Disc Loss: 0.7345\n",
            "Epoch 1, Batch 9, Gen Loss: 0.0971, Disc Loss: 0.7015\n",
            "Epoch 1, Batch 10, Gen Loss: 0.0838, Disc Loss: 0.5989\n",
            "Epoch 1, Batch 11, Gen Loss: 0.0761, Disc Loss: 0.5848\n",
            "Epoch 1, Batch 12, Gen Loss: 0.0689, Disc Loss: 0.6362\n",
            "Epoch 1, Batch 13, Gen Loss: 0.0687, Disc Loss: 0.6350\n",
            "Epoch 1, Batch 14, Gen Loss: 0.0609, Disc Loss: 0.5693\n",
            "Epoch 1, Batch 15, Gen Loss: 0.0630, Disc Loss: 0.5744\n",
            "Epoch 1, Batch 16, Gen Loss: 0.0591, Disc Loss: 0.5853\n",
            "Epoch 1, Batch 17, Gen Loss: 0.0568, Disc Loss: 0.6101\n",
            "Epoch 1, Batch 18, Gen Loss: 0.0529, Disc Loss: 0.5758\n",
            "Epoch 1, Batch 19, Gen Loss: 0.0500, Disc Loss: 0.5631\n",
            "Epoch 1, Batch 20, Gen Loss: 0.0498, Disc Loss: 0.4940\n",
            "Epoch 1, Batch 21, Gen Loss: 0.0461, Disc Loss: 0.5480\n",
            "Epoch 1, Batch 22, Gen Loss: 0.0437, Disc Loss: 0.4922\n",
            "Epoch 1, Batch 23, Gen Loss: 0.0451, Disc Loss: 0.4828\n",
            "Epoch 1, Batch 24, Gen Loss: 0.0463, Disc Loss: 0.5501\n",
            "Epoch 1, Batch 25, Gen Loss: 0.0420, Disc Loss: 0.5644\n",
            "Epoch 1, Batch 26, Gen Loss: 0.0359, Disc Loss: 0.7777\n",
            "Epoch 1, Batch 27, Gen Loss: 0.0372, Disc Loss: 0.7717\n",
            "Epoch 1, Batch 28, Gen Loss: 0.0385, Disc Loss: 0.5677\n",
            "Epoch 1, Batch 29, Gen Loss: 0.0370, Disc Loss: 0.5104\n",
            "Epoch 1, Batch 30, Gen Loss: 0.0348, Disc Loss: 0.5092\n",
            "Epoch 1, Batch 31, Gen Loss: 0.0375, Disc Loss: 0.4868\n",
            "Epoch 1, Batch 32, Gen Loss: 0.0348, Disc Loss: 0.4607\n",
            "Epoch 1, Batch 33, Gen Loss: 0.0384, Disc Loss: 0.4948\n",
            "Epoch 1, Batch 34, Gen Loss: 0.0328, Disc Loss: 0.4433\n",
            "Epoch 1, Batch 35, Gen Loss: 0.0358, Disc Loss: 0.4634\n",
            "Epoch 1, Batch 36, Gen Loss: 0.0380, Disc Loss: 0.4588\n",
            "Epoch 1, Batch 37, Gen Loss: 0.0399, Disc Loss: 0.3920\n",
            "Epoch 1, Batch 38, Gen Loss: 0.0380, Disc Loss: 0.4847\n",
            "Epoch 1, Batch 39, Gen Loss: 0.0330, Disc Loss: 0.4912\n",
            "Epoch 1, Batch 40, Gen Loss: 0.0374, Disc Loss: 0.4355\n",
            "Epoch 1, Batch 41, Gen Loss: 0.0430, Disc Loss: 0.4953\n",
            "Epoch 1, Batch 42, Gen Loss: 0.0398, Disc Loss: 0.4209\n",
            "Epoch 1, Batch 43, Gen Loss: 0.0300, Disc Loss: 0.5439\n",
            "Epoch 1, Batch 44, Gen Loss: 0.0252, Disc Loss: 0.5337\n",
            "Epoch 1, Batch 45, Gen Loss: 0.0352, Disc Loss: 0.4677\n",
            "Epoch 1, Batch 46, Gen Loss: 0.0287, Disc Loss: 0.5718\n",
            "Epoch 1, Batch 47, Gen Loss: 0.0294, Disc Loss: 0.4817\n",
            "Epoch 1, Batch 48, Gen Loss: 0.0297, Disc Loss: 0.4802\n",
            "Epoch 1, Batch 49, Gen Loss: 0.0285, Disc Loss: 0.4236\n",
            "Epoch 1, Batch 50, Gen Loss: 0.0272, Disc Loss: 0.4114\n",
            "Epoch 1, Batch 51, Gen Loss: 0.0265, Disc Loss: 0.4237\n",
            "Epoch 1, Batch 52, Gen Loss: 0.0263, Disc Loss: 0.3883\n",
            "Epoch 1, Batch 53, Gen Loss: 0.0261, Disc Loss: 0.4185\n",
            "Epoch 1, Batch 54, Gen Loss: 0.0228, Disc Loss: 0.3922\n",
            "Epoch 1, Batch 55, Gen Loss: 0.0232, Disc Loss: 0.4019\n",
            "Epoch 1, Batch 56, Gen Loss: 0.0254, Disc Loss: 0.3729\n",
            "Epoch 1, Batch 57, Gen Loss: 0.0252, Disc Loss: 0.3856\n",
            "Epoch 1, Batch 58, Gen Loss: 0.0263, Disc Loss: 0.3905\n",
            "Epoch 1, Batch 59, Gen Loss: 0.0272, Disc Loss: 0.4201\n",
            "Epoch 1, Batch 60, Gen Loss: 0.0230, Disc Loss: 0.4156\n",
            "Epoch 1, Batch 61, Gen Loss: 0.0213, Disc Loss: 0.3712\n",
            "Epoch 1, Batch 62, Gen Loss: 0.0217, Disc Loss: 0.3479\n",
            "Epoch 1, Batch 63, Gen Loss: 0.0210, Disc Loss: 0.3888\n",
            "Epoch 1, Batch 64, Gen Loss: 0.0209, Disc Loss: 0.4153\n",
            "Epoch 1, Batch 65, Gen Loss: 0.0234, Disc Loss: 0.3767\n",
            "Epoch 1, Batch 66, Gen Loss: 0.0194, Disc Loss: 0.4080\n",
            "Epoch 1, Batch 67, Gen Loss: 0.0206, Disc Loss: 0.4011\n",
            "Epoch 1, Batch 68, Gen Loss: 0.0200, Disc Loss: 0.3449\n",
            "Epoch 1, Batch 69, Gen Loss: 0.0218, Disc Loss: 0.3959\n",
            "Epoch 1, Batch 70, Gen Loss: 0.0238, Disc Loss: 0.4347\n",
            "Epoch 1, Batch 71, Gen Loss: 0.0212, Disc Loss: 0.3741\n",
            "Epoch 1, Batch 72, Gen Loss: 0.0213, Disc Loss: 0.3649\n",
            "Epoch 1, Batch 73, Gen Loss: 0.0196, Disc Loss: 0.4678\n",
            "Epoch 1, Batch 74, Gen Loss: 0.0217, Disc Loss: 0.4371\n",
            "Epoch 1, Batch 75, Gen Loss: 0.0257, Disc Loss: 0.3770\n",
            "Epoch 1, Batch 76, Gen Loss: 0.0243, Disc Loss: 0.3605\n",
            "Epoch 1, Batch 77, Gen Loss: 0.0226, Disc Loss: 0.3421\n",
            "Epoch 1, Batch 78, Gen Loss: 0.0235, Disc Loss: 0.3114\n",
            "Epoch 1, Batch 79, Gen Loss: 0.0229, Disc Loss: 0.3562\n",
            "Epoch 1, Batch 80, Gen Loss: 0.0199, Disc Loss: 0.4137\n",
            "Epoch 1, Batch 81, Gen Loss: 0.0174, Disc Loss: 0.3924\n",
            "Epoch 1, Batch 82, Gen Loss: 0.0177, Disc Loss: 0.4782\n",
            "Epoch 1, Batch 83, Gen Loss: 0.0205, Disc Loss: 0.4737\n",
            "Epoch 1, Batch 84, Gen Loss: 0.0197, Disc Loss: 0.3725\n",
            "Epoch 1, Batch 85, Gen Loss: 0.0172, Disc Loss: 0.4245\n",
            "Epoch 1, Batch 86, Gen Loss: 0.0189, Disc Loss: 0.4144\n",
            "Epoch 1, Batch 87, Gen Loss: 0.0186, Disc Loss: 0.3483\n",
            "Epoch 1, Batch 88, Gen Loss: 0.0171, Disc Loss: 0.3023\n",
            "Epoch 1, Batch 89, Gen Loss: 0.0178, Disc Loss: 0.3079\n",
            "Epoch 1, Batch 90, Gen Loss: 0.0167, Disc Loss: 0.2857\n",
            "Epoch 1, Batch 91, Gen Loss: 0.0217, Disc Loss: 0.2466\n",
            "Epoch 1, Batch 92, Gen Loss: 0.0226, Disc Loss: 0.2504\n",
            "Epoch 1, Batch 93, Gen Loss: 0.0219, Disc Loss: 0.2653\n",
            "Epoch 1, Batch 94, Gen Loss: 0.0181, Disc Loss: 0.2894\n",
            "Epoch 1, Batch 95, Gen Loss: 0.0185, Disc Loss: 0.2751\n",
            "Epoch 1, Batch 96, Gen Loss: 0.0209, Disc Loss: 0.2360\n",
            "Epoch 1, Batch 97, Gen Loss: 0.0239, Disc Loss: 0.2477\n",
            "Epoch 1, Batch 98, Gen Loss: 0.0199, Disc Loss: 0.2038\n",
            "Epoch 1, Batch 99, Gen Loss: 0.0174, Disc Loss: 0.2688\n",
            "Epoch 1, Batch 100, Gen Loss: 0.0155, Disc Loss: 0.3317\n",
            "Epoch 1, Batch 101, Gen Loss: 0.0144, Disc Loss: 0.3085\n",
            "Epoch 1, Batch 102, Gen Loss: 0.0168, Disc Loss: 0.2775\n",
            "Epoch 1, Batch 103, Gen Loss: 0.0211, Disc Loss: 0.2852\n",
            "Epoch 1, Batch 104, Gen Loss: 0.0183, Disc Loss: 0.3636\n",
            "Epoch 1, Batch 105, Gen Loss: 0.0149, Disc Loss: 0.3373\n",
            "Epoch 1, Batch 106, Gen Loss: 0.0143, Disc Loss: 0.2564\n",
            "Epoch 1, Batch 107, Gen Loss: 0.0144, Disc Loss: 0.2600\n",
            "Epoch 1, Batch 108, Gen Loss: 0.0143, Disc Loss: 0.2704\n",
            "Epoch 1, Batch 109, Gen Loss: 0.0142, Disc Loss: 0.2651\n",
            "Epoch 1, Batch 110, Gen Loss: 0.0152, Disc Loss: 0.3374\n",
            "Epoch 1, Batch 111, Gen Loss: 0.0154, Disc Loss: 0.2854\n",
            "Epoch 1, Batch 112, Gen Loss: 0.0161, Disc Loss: 0.2759\n",
            "Epoch 1, Batch 113, Gen Loss: 0.0146, Disc Loss: 0.2206\n",
            "Epoch 1, Batch 114, Gen Loss: 0.0148, Disc Loss: 0.2123\n",
            "Epoch 1, Batch 115, Gen Loss: 0.0167, Disc Loss: 0.2346\n",
            "Epoch 1, Batch 116, Gen Loss: 0.0159, Disc Loss: 0.1987\n",
            "Epoch 1, Batch 117, Gen Loss: 0.0144, Disc Loss: 0.2890\n",
            "Epoch 1, Batch 118, Gen Loss: 0.0147, Disc Loss: 0.2647\n",
            "Epoch 1, Batch 119, Gen Loss: 0.0134, Disc Loss: 0.2683\n",
            "Epoch 1, Batch 120, Gen Loss: 0.0144, Disc Loss: 0.2568\n",
            "Epoch 1, Batch 121, Gen Loss: 0.0136, Disc Loss: 0.2199\n",
            "Epoch 1, Batch 122, Gen Loss: 0.0136, Disc Loss: 0.2315\n",
            "Epoch 1, Batch 123, Gen Loss: 0.0143, Disc Loss: 0.2062\n",
            "Epoch 1, Batch 124, Gen Loss: 0.0137, Disc Loss: 0.2167\n",
            "Epoch 1, Batch 125, Gen Loss: 0.0148, Disc Loss: 0.2420\n",
            "Epoch 1, Batch 126, Gen Loss: 0.0126, Disc Loss: 0.2959\n",
            "Epoch 1, Batch 127, Gen Loss: 0.0135, Disc Loss: 0.2502\n",
            "Epoch 1, Batch 128, Gen Loss: 0.0129, Disc Loss: 0.2162\n",
            "Epoch 1, Batch 129, Gen Loss: 0.0134, Disc Loss: 0.3524\n",
            "Epoch 1, Batch 130, Gen Loss: 0.0130, Disc Loss: 0.3441\n",
            "Epoch 1, Batch 131, Gen Loss: 0.0125, Disc Loss: 0.3200\n",
            "Epoch 1, Batch 132, Gen Loss: 0.0123, Disc Loss: 0.2555\n",
            "Epoch 1, Batch 133, Gen Loss: 0.0133, Disc Loss: 0.1466\n",
            "Epoch 1, Batch 134, Gen Loss: 0.0137, Disc Loss: 0.2450\n",
            "Epoch 1, Batch 135, Gen Loss: 0.0118, Disc Loss: 0.2405\n",
            "Epoch 1, Batch 136, Gen Loss: 0.0129, Disc Loss: 0.2052\n",
            "Epoch 1, Batch 137, Gen Loss: 0.0139, Disc Loss: 0.2642\n",
            "Epoch 1, Batch 138, Gen Loss: 0.0122, Disc Loss: 0.2434\n",
            "Epoch 1, Batch 139, Gen Loss: 0.0124, Disc Loss: 0.2701\n",
            "Epoch 1, Batch 140, Gen Loss: 0.0123, Disc Loss: 0.2074\n",
            "Epoch 1, Batch 141, Gen Loss: 0.0131, Disc Loss: 0.2235\n",
            "Epoch 1, Batch 142, Gen Loss: 0.0121, Disc Loss: 0.2336\n",
            "Epoch 1, Batch 143, Gen Loss: 0.0106, Disc Loss: 0.2754\n",
            "Epoch 1, Batch 144, Gen Loss: 0.0130, Disc Loss: 0.3082\n",
            "Epoch 1, Batch 145, Gen Loss: 0.0120, Disc Loss: 0.1786\n",
            "Epoch 1, Batch 146, Gen Loss: 0.0110, Disc Loss: 0.2313\n",
            "Epoch 1, Batch 147, Gen Loss: 0.0125, Disc Loss: 0.2566\n",
            "Epoch 1, Batch 148, Gen Loss: 0.0143, Disc Loss: 0.2625\n",
            "Epoch 1, Batch 149, Gen Loss: 0.0143, Disc Loss: 0.4283\n",
            "Epoch 1, Batch 150, Gen Loss: 0.0122, Disc Loss: 0.3024\n",
            "Epoch 1, Batch 151, Gen Loss: 0.0122, Disc Loss: 0.2866\n",
            "Epoch 1, Batch 152, Gen Loss: 0.0135, Disc Loss: 0.2928\n",
            "Epoch 1, Batch 153, Gen Loss: 0.0119, Disc Loss: 0.2196\n",
            "Epoch 1, Batch 154, Gen Loss: 0.0116, Disc Loss: 0.2905\n",
            "Epoch 1, Batch 155, Gen Loss: 0.0120, Disc Loss: 0.2815\n",
            "Epoch 1, Batch 156, Gen Loss: 0.0121, Disc Loss: 0.1917\n",
            "Epoch 1, Batch 157, Gen Loss: 0.0127, Disc Loss: 0.2523\n",
            "Epoch 1, Batch 158, Gen Loss: 0.0127, Disc Loss: 0.1588\n",
            "Epoch 1, Batch 159, Gen Loss: 0.0116, Disc Loss: 0.2199\n",
            "Epoch 1, Batch 160, Gen Loss: 0.0106, Disc Loss: 0.1424\n",
            "Epoch 1, Batch 161, Gen Loss: 0.0106, Disc Loss: 0.1748\n",
            "Epoch 1, Batch 162, Gen Loss: 0.0123, Disc Loss: 0.1806\n",
            "Epoch 1, Batch 163, Gen Loss: 0.0129, Disc Loss: 0.1451\n",
            "Epoch 1, Batch 164, Gen Loss: 0.0117, Disc Loss: 0.2595\n",
            "Epoch 1, Batch 165, Gen Loss: 0.0113, Disc Loss: 0.2180\n",
            "Epoch 1, Batch 166, Gen Loss: 0.0109, Disc Loss: 0.2699\n",
            "Epoch 1, Batch 167, Gen Loss: 0.0132, Disc Loss: 0.2565\n",
            "Epoch 1, Batch 168, Gen Loss: 0.0114, Disc Loss: 0.1806\n",
            "Epoch 1, Batch 169, Gen Loss: 0.0111, Disc Loss: 0.3516\n",
            "Epoch 1, Batch 170, Gen Loss: 0.0109, Disc Loss: 0.2393\n",
            "Epoch 1, Batch 171, Gen Loss: 0.0102, Disc Loss: 0.2689\n",
            "Epoch 1, Batch 172, Gen Loss: 0.0092, Disc Loss: 0.2727\n",
            "Epoch 1, Batch 173, Gen Loss: 0.0111, Disc Loss: 0.2760\n",
            "Epoch 1, Batch 174, Gen Loss: 0.0116, Disc Loss: 0.2105\n",
            "Epoch 1, Batch 175, Gen Loss: 0.0103, Disc Loss: 0.1665\n",
            "Epoch 1, Batch 176, Gen Loss: 0.0112, Disc Loss: 0.2207\n",
            "Epoch 1, Batch 177, Gen Loss: 0.0097, Disc Loss: 0.1818\n",
            "Epoch 1, Batch 178, Gen Loss: 0.0109, Disc Loss: 0.1487\n",
            "Epoch 1, Batch 179, Gen Loss: 0.0109, Disc Loss: 0.2809\n",
            "Epoch 1, Batch 180, Gen Loss: 0.0103, Disc Loss: 0.3133\n",
            "Epoch 1, Batch 181, Gen Loss: 0.0103, Disc Loss: 0.4051\n",
            "Epoch 1, Batch 182, Gen Loss: 0.0121, Disc Loss: 0.3411\n",
            "Epoch 1, Batch 183, Gen Loss: 0.0124, Disc Loss: 0.2470\n",
            "Epoch 1, Batch 184, Gen Loss: 0.0111, Disc Loss: 0.4148\n",
            "Epoch 1, Batch 185, Gen Loss: 0.0100, Disc Loss: 0.2263\n",
            "Epoch 1, Batch 186, Gen Loss: 0.0095, Disc Loss: 0.2079\n",
            "Epoch 1, Batch 187, Gen Loss: 0.0123, Disc Loss: 0.1674\n",
            "Epoch 1, Batch 188, Gen Loss: 0.0129, Disc Loss: 0.0962\n",
            "Epoch 1, Batch 189, Gen Loss: 0.0116, Disc Loss: 0.4014\n",
            "Epoch 1, Batch 190, Gen Loss: 0.0093, Disc Loss: 0.2225\n",
            "Epoch 1, Batch 191, Gen Loss: 0.0092, Disc Loss: 0.2583\n",
            "Epoch 1, Batch 192, Gen Loss: 0.0097, Disc Loss: 0.2222\n",
            "Epoch 1, Batch 193, Gen Loss: 0.0104, Disc Loss: 0.1876\n",
            "Epoch 1, Batch 194, Gen Loss: 0.0101, Disc Loss: 0.2125\n",
            "Epoch 1, Batch 195, Gen Loss: 0.0090, Disc Loss: 0.2097\n",
            "Epoch 1, Batch 196, Gen Loss: 0.0094, Disc Loss: 0.1799\n",
            "Epoch 1, Batch 197, Gen Loss: 0.0087, Disc Loss: 0.1497\n",
            "Epoch 1, Batch 198, Gen Loss: 0.0092, Disc Loss: 0.1228\n",
            "Epoch 1, Batch 199, Gen Loss: 0.0095, Disc Loss: 0.1852\n",
            "Epoch 1, Batch 200, Gen Loss: 0.0094, Disc Loss: 0.1729\n",
            "Epoch 1, Batch 201, Gen Loss: 0.0086, Disc Loss: 0.2219\n",
            "Epoch 1, Batch 202, Gen Loss: 0.0091, Disc Loss: 0.1925\n",
            "Epoch 1, Batch 203, Gen Loss: 0.0096, Disc Loss: 0.1628\n",
            "Epoch 1, Batch 204, Gen Loss: 0.0103, Disc Loss: 0.1615\n",
            "Epoch 1, Batch 205, Gen Loss: 0.0097, Disc Loss: 0.1049\n",
            "Epoch 1, Batch 206, Gen Loss: 0.0100, Disc Loss: 0.1591\n",
            "Epoch 1, Batch 207, Gen Loss: 0.0100, Disc Loss: 0.1742\n",
            "Epoch 1, Batch 208, Gen Loss: 0.0132, Disc Loss: 0.1208\n",
            "Epoch 1, Batch 209, Gen Loss: 0.0114, Disc Loss: 0.4327\n",
            "Epoch 1, Batch 210, Gen Loss: 0.0117, Disc Loss: 0.3286\n",
            "Epoch 1, Batch 211, Gen Loss: 0.0125, Disc Loss: 0.2104\n",
            "Epoch 1, Batch 212, Gen Loss: 0.0115, Disc Loss: 0.2161\n",
            "Epoch 1, Batch 213, Gen Loss: 0.0133, Disc Loss: 0.1126\n",
            "Epoch 1, Batch 214, Gen Loss: 0.0112, Disc Loss: 0.1336\n",
            "Epoch 1, Batch 215, Gen Loss: 0.0118, Disc Loss: 0.1792\n",
            "Epoch 1, Batch 216, Gen Loss: 0.0113, Disc Loss: 0.1566\n",
            "Epoch 1, Batch 217, Gen Loss: 0.0094, Disc Loss: 0.2003\n",
            "Epoch 1, Batch 218, Gen Loss: 0.0126, Disc Loss: 0.1706\n",
            "Epoch 1, Batch 219, Gen Loss: 0.0158, Disc Loss: 0.2178\n",
            "Epoch 1, Batch 220, Gen Loss: 0.0140, Disc Loss: 0.2456\n",
            "Epoch 1, Batch 221, Gen Loss: 0.0131, Disc Loss: 0.1326\n",
            "Epoch 1, Batch 222, Gen Loss: 0.0097, Disc Loss: 0.1814\n",
            "Epoch 1, Batch 223, Gen Loss: 0.0094, Disc Loss: 0.1698\n",
            "Epoch 1, Batch 224, Gen Loss: 0.0095, Disc Loss: 0.1204\n",
            "Epoch 1, Batch 225, Gen Loss: 0.0106, Disc Loss: 0.1384\n",
            "Epoch 1, Batch 226, Gen Loss: 0.0127, Disc Loss: 0.1450\n",
            "Epoch 1, Batch 227, Gen Loss: 0.0101, Disc Loss: 0.1272\n",
            "Epoch 1, Batch 228, Gen Loss: 0.0108, Disc Loss: 0.1276\n",
            "Epoch 1, Batch 229, Gen Loss: 0.0110, Disc Loss: 0.1289\n",
            "Epoch 1, Batch 230, Gen Loss: 0.0111, Disc Loss: 0.1588\n",
            "Epoch 1, Batch 231, Gen Loss: 0.0102, Disc Loss: 0.1317\n",
            "Epoch 1, Batch 232, Gen Loss: 0.0087, Disc Loss: 0.1059\n",
            "Epoch 1, Batch 233, Gen Loss: 0.0088, Disc Loss: 0.1668\n",
            "Epoch 1, Batch 234, Gen Loss: 0.0090, Disc Loss: 0.1086\n",
            "Epoch 1, Batch 235, Gen Loss: 0.0101, Disc Loss: 0.1303\n",
            "Epoch 1, Batch 236, Gen Loss: 0.0083, Disc Loss: 0.3210\n",
            "Epoch 1, Batch 237, Gen Loss: 0.0078, Disc Loss: 0.2587\n",
            "Epoch 1, Batch 238, Gen Loss: 0.0083, Disc Loss: 0.1974\n",
            "Epoch 1, Batch 239, Gen Loss: 0.0098, Disc Loss: 0.1150\n",
            "Epoch 1, Batch 240, Gen Loss: 0.0096, Disc Loss: 0.0833\n",
            "Epoch 1, Batch 241, Gen Loss: 0.0093, Disc Loss: 0.2112\n",
            "Epoch 1, Batch 242, Gen Loss: 0.0099, Disc Loss: 0.1491\n",
            "Epoch 1, Batch 243, Gen Loss: 0.0090, Disc Loss: 0.1710\n",
            "Epoch 1, Batch 244, Gen Loss: 0.0106, Disc Loss: 0.1096\n",
            "Epoch 1, Batch 245, Gen Loss: 0.0096, Disc Loss: 0.0683\n",
            "Epoch 1, Batch 246, Gen Loss: 0.0100, Disc Loss: 0.1755\n",
            "Epoch 1, Batch 247, Gen Loss: 0.0087, Disc Loss: 0.1113\n",
            "Epoch 1, Batch 248, Gen Loss: 0.0095, Disc Loss: 0.0924\n",
            "Epoch 1, Batch 249, Gen Loss: 0.0083, Disc Loss: 0.2381\n",
            "Epoch 1, Batch 250, Gen Loss: 0.0082, Disc Loss: 0.2300\n",
            "Epoch 1, Batch 251, Gen Loss: 0.0092, Disc Loss: 0.1413\n",
            "Epoch 1, Batch 252, Gen Loss: 0.0098, Disc Loss: 0.1420\n",
            "Epoch 1, Batch 253, Gen Loss: 0.0101, Disc Loss: 0.1979\n",
            "Epoch 1, Batch 254, Gen Loss: 0.0109, Disc Loss: 0.2978\n",
            "Epoch 1, Batch 255, Gen Loss: 0.0090, Disc Loss: 0.3367\n",
            "Epoch 1, Batch 256, Gen Loss: 0.0088, Disc Loss: 0.1856\n",
            "Epoch 1, Batch 257, Gen Loss: 0.0089, Disc Loss: 0.1889\n",
            "Epoch 1, Batch 258, Gen Loss: 0.0084, Disc Loss: 0.0882\n",
            "Epoch 1, Batch 259, Gen Loss: 0.0104, Disc Loss: 0.0736\n",
            "Epoch 1, Batch 260, Gen Loss: 0.0116, Disc Loss: 0.0895\n",
            "Epoch 1, Batch 261, Gen Loss: 0.0100, Disc Loss: 0.2409\n",
            "Epoch 1, Batch 262, Gen Loss: 0.0079, Disc Loss: 0.1560\n",
            "Epoch 1, Batch 263, Gen Loss: 0.0095, Disc Loss: 0.2799\n",
            "Epoch 1, Batch 264, Gen Loss: 0.0085, Disc Loss: 0.2523\n",
            "Epoch 1, Batch 265, Gen Loss: 0.0129, Disc Loss: 0.1518\n",
            "Epoch 1, Batch 266, Gen Loss: 0.0127, Disc Loss: 0.3283\n",
            "Epoch 1, Batch 267, Gen Loss: 0.0091, Disc Loss: 0.4156\n",
            "Epoch 1, Batch 268, Gen Loss: 0.0081, Disc Loss: 0.2136\n",
            "Epoch 1, Batch 269, Gen Loss: 0.0084, Disc Loss: 0.3210\n",
            "Epoch 1, Batch 270, Gen Loss: 0.0076, Disc Loss: 0.1966\n",
            "Epoch 1, Batch 271, Gen Loss: 0.0077, Disc Loss: 0.1879\n",
            "Epoch 1, Batch 272, Gen Loss: 0.0087, Disc Loss: 0.2132\n",
            "Epoch 1, Batch 273, Gen Loss: 0.0078, Disc Loss: 0.1904\n",
            "Epoch 1, Batch 274, Gen Loss: 0.0080, Disc Loss: 0.1965\n",
            "Epoch 1, Batch 275, Gen Loss: 0.0076, Disc Loss: 0.1860\n",
            "Epoch 1, Batch 276, Gen Loss: 0.0072, Disc Loss: 0.1938\n",
            "Epoch 1, Batch 277, Gen Loss: 0.0077, Disc Loss: 0.1797\n",
            "Epoch 1, Batch 278, Gen Loss: 0.0077, Disc Loss: 0.1888\n",
            "Epoch 1, Batch 279, Gen Loss: 0.0069, Disc Loss: 0.0960\n",
            "Epoch 1, Batch 280, Gen Loss: 0.0080, Disc Loss: 0.0882\n",
            "Epoch 1, Batch 281, Gen Loss: 0.0069, Disc Loss: 0.0990\n",
            "Epoch 1, Batch 282, Gen Loss: 0.0079, Disc Loss: 0.2067\n",
            "Epoch 1, Batch 283, Gen Loss: 0.0074, Disc Loss: 0.1771\n",
            "Epoch 1, Batch 284, Gen Loss: 0.0078, Disc Loss: 0.0844\n",
            "Epoch 1, Batch 285, Gen Loss: 0.0085, Disc Loss: 0.2139\n",
            "Epoch 1, Batch 286, Gen Loss: 0.0091, Disc Loss: 0.1680\n",
            "Epoch 1, Batch 287, Gen Loss: 0.0083, Disc Loss: 0.1538\n",
            "Epoch 1, Batch 288, Gen Loss: 0.0081, Disc Loss: 0.1142\n",
            "Epoch 1, Batch 289, Gen Loss: 0.0084, Disc Loss: 0.2259\n",
            "Epoch 1, Batch 290, Gen Loss: 0.0085, Disc Loss: 0.1906\n",
            "Epoch 1, Batch 291, Gen Loss: 0.0084, Disc Loss: 0.1263\n",
            "Epoch 1, Batch 292, Gen Loss: 0.0094, Disc Loss: 0.0706\n",
            "Epoch 1, Batch 293, Gen Loss: 0.0088, Disc Loss: 0.2386\n",
            "Epoch 1, Batch 294, Gen Loss: 0.0072, Disc Loss: 0.1399\n",
            "Epoch 1, Batch 295, Gen Loss: 0.0076, Disc Loss: 0.1877\n",
            "Epoch 1, Batch 296, Gen Loss: 0.0072, Disc Loss: 0.1034\n",
            "Epoch 1, Batch 297, Gen Loss: 0.0081, Disc Loss: 0.1394\n",
            "Epoch 1, Batch 298, Gen Loss: 0.0083, Disc Loss: 0.1227\n",
            "Epoch 1, Batch 299, Gen Loss: 0.0103, Disc Loss: 0.1045\n",
            "Epoch 1, Batch 300, Gen Loss: 0.0091, Disc Loss: 0.1766\n",
            "Epoch 1, Batch 301, Gen Loss: 0.0073, Disc Loss: 0.1508\n",
            "Epoch 1, Batch 302, Gen Loss: 0.0084, Disc Loss: 0.1345\n",
            "Epoch 1, Batch 303, Gen Loss: 0.0073, Disc Loss: 0.0880\n",
            "Epoch 1, Batch 304, Gen Loss: 0.0076, Disc Loss: 0.1049\n",
            "Epoch 1, Batch 305, Gen Loss: 0.0074, Disc Loss: 0.0993\n",
            "Epoch 1, Batch 306, Gen Loss: 0.0081, Disc Loss: 0.1170\n",
            "Epoch 1, Batch 307, Gen Loss: 0.0087, Disc Loss: 0.1076\n",
            "Epoch 1, Batch 308, Gen Loss: 0.0101, Disc Loss: 0.1154\n",
            "Epoch 1, Batch 309, Gen Loss: 0.0079, Disc Loss: 0.1242\n",
            "Epoch 1, Batch 310, Gen Loss: 0.0085, Disc Loss: 0.1716\n",
            "Epoch 1, Batch 311, Gen Loss: 0.0109, Disc Loss: 0.1174\n",
            "Epoch 1, Batch 312, Gen Loss: 0.0076, Disc Loss: 0.1173\n",
            "Epoch 1, Batch 313, Gen Loss: 0.0080, Disc Loss: 0.1745\n",
            "Epoch 1, Batch 314, Gen Loss: 0.0079, Disc Loss: 0.3797\n",
            "Epoch 1, Batch 315, Gen Loss: 0.0088, Disc Loss: 0.1233\n",
            "Epoch 1, Batch 316, Gen Loss: 0.0079, Disc Loss: 0.2140\n",
            "Epoch 1, Batch 317, Gen Loss: 0.0069, Disc Loss: 0.1731\n",
            "Epoch 1, Batch 318, Gen Loss: 0.0073, Disc Loss: 0.1824\n",
            "Epoch 1, Batch 319, Gen Loss: 0.0115, Disc Loss: 0.1638\n",
            "Epoch 1, Batch 320, Gen Loss: 0.0124, Disc Loss: 0.2591\n",
            "Epoch 1, Batch 321, Gen Loss: 0.0104, Disc Loss: 0.3300\n",
            "Epoch 1, Batch 322, Gen Loss: 0.0085, Disc Loss: 0.3464\n",
            "Epoch 1, Batch 323, Gen Loss: 0.0089, Disc Loss: 0.2987\n",
            "Epoch 1, Batch 324, Gen Loss: 0.0085, Disc Loss: 0.3409\n",
            "Epoch 1, Batch 325, Gen Loss: 0.0087, Disc Loss: 0.3055\n",
            "Epoch 1, Batch 326, Gen Loss: 0.0087, Disc Loss: 0.1357\n",
            "Epoch 1, Batch 327, Gen Loss: 0.0084, Disc Loss: 0.1172\n",
            "Epoch 1, Batch 328, Gen Loss: 0.0078, Disc Loss: 0.2545\n",
            "Epoch 1, Batch 329, Gen Loss: 0.0085, Disc Loss: 0.1577\n",
            "Epoch 1, Batch 330, Gen Loss: 0.0080, Disc Loss: 0.1174\n",
            "Epoch 1, Batch 331, Gen Loss: 0.0080, Disc Loss: 0.2294\n",
            "Epoch 1, Batch 332, Gen Loss: 0.0073, Disc Loss: 0.2028\n",
            "Epoch 1, Batch 333, Gen Loss: 0.0078, Disc Loss: 0.1330\n",
            "Epoch 1, Batch 334, Gen Loss: 0.0077, Disc Loss: 0.1702\n",
            "Epoch 1, Batch 335, Gen Loss: 0.0066, Disc Loss: 0.0890\n",
            "Epoch 1, Batch 336, Gen Loss: 0.0085, Disc Loss: 0.1137\n",
            "Epoch 1, Batch 337, Gen Loss: 0.0082, Disc Loss: 0.0615\n",
            "Epoch 1, Batch 338, Gen Loss: 0.0092, Disc Loss: 0.1747\n",
            "Epoch 1, Batch 339, Gen Loss: 0.0084, Disc Loss: 0.2012\n",
            "Epoch 1, Batch 340, Gen Loss: 0.0076, Disc Loss: 0.1859\n",
            "Epoch 1, Batch 341, Gen Loss: 0.0065, Disc Loss: 0.1884\n",
            "Epoch 1, Batch 342, Gen Loss: 0.0059, Disc Loss: 0.2366\n",
            "Epoch 1, Batch 343, Gen Loss: 0.0076, Disc Loss: 0.1038\n",
            "Epoch 1, Batch 344, Gen Loss: 0.0069, Disc Loss: 0.0844\n",
            "Epoch 1, Batch 345, Gen Loss: 0.0084, Disc Loss: 0.1330\n",
            "Epoch 1, Batch 346, Gen Loss: 0.0090, Disc Loss: 0.0698\n",
            "Epoch 1, Batch 347, Gen Loss: 0.0075, Disc Loss: 0.1568\n",
            "Epoch 1, Batch 348, Gen Loss: 0.0068, Disc Loss: 0.1440\n",
            "Epoch 1, Batch 349, Gen Loss: 0.0071, Disc Loss: 0.0845\n",
            "Epoch 1, Batch 350, Gen Loss: 0.0079, Disc Loss: 0.1130\n",
            "Epoch 1, Batch 351, Gen Loss: 0.0061, Disc Loss: 0.0578\n",
            "Epoch 1, Batch 352, Gen Loss: 0.0059, Disc Loss: 0.1010\n",
            "Epoch 1, Batch 353, Gen Loss: 0.0060, Disc Loss: 0.1187\n",
            "Epoch 1, Batch 354, Gen Loss: 0.0062, Disc Loss: 0.1149\n",
            "Epoch 1, Batch 355, Gen Loss: 0.0060, Disc Loss: 0.0843\n",
            "Epoch 1, Batch 356, Gen Loss: 0.0065, Disc Loss: 0.0577\n",
            "Epoch 1, Batch 357, Gen Loss: 0.0073, Disc Loss: 0.0994\n",
            "Epoch 1, Batch 358, Gen Loss: 0.0065, Disc Loss: 0.1254\n",
            "Epoch 1, Batch 359, Gen Loss: 0.0077, Disc Loss: 0.0879\n",
            "Epoch 1, Batch 360, Gen Loss: 0.0069, Disc Loss: 0.0879\n",
            "Epoch 1, Batch 361, Gen Loss: 0.0067, Disc Loss: 0.1004\n",
            "Epoch 1, Batch 362, Gen Loss: 0.0065, Disc Loss: 0.0761\n",
            "Epoch 1, Batch 363, Gen Loss: 0.0068, Disc Loss: 0.0780\n",
            "Epoch 1, Batch 364, Gen Loss: 0.0060, Disc Loss: 0.1112\n",
            "Epoch 1, Batch 365, Gen Loss: 0.0063, Disc Loss: 0.1270\n",
            "Epoch 1, Batch 366, Gen Loss: 0.0065, Disc Loss: 0.1448\n",
            "Epoch 1, Batch 367, Gen Loss: 0.0066, Disc Loss: 0.1196\n",
            "Epoch 1, Batch 368, Gen Loss: 0.0061, Disc Loss: 0.1275\n",
            "Epoch 1, Batch 369, Gen Loss: 0.0070, Disc Loss: 0.1033\n",
            "Epoch 1, Batch 370, Gen Loss: 0.0075, Disc Loss: 0.0666\n",
            "Epoch 1, Batch 371, Gen Loss: 0.0082, Disc Loss: 0.1004\n",
            "Epoch 1, Batch 372, Gen Loss: 0.0072, Disc Loss: 0.0600\n",
            "Epoch 1, Batch 373, Gen Loss: 0.0065, Disc Loss: 0.0701\n",
            "Epoch 1, Batch 374, Gen Loss: 0.0071, Disc Loss: 0.0944\n",
            "Epoch 1, Batch 375, Gen Loss: 0.0107, Disc Loss: 0.1407\n",
            "Epoch 1, Batch 376, Gen Loss: 0.0124, Disc Loss: 0.1862\n",
            "Epoch 1, Batch 377, Gen Loss: 0.0071, Disc Loss: 0.5992\n",
            "Epoch 1, Batch 378, Gen Loss: 0.0082, Disc Loss: 0.2134\n",
            "Epoch 1, Batch 379, Gen Loss: 0.0081, Disc Loss: 0.3553\n",
            "Epoch 1, Batch 380, Gen Loss: 0.0056, Disc Loss: 0.2314\n",
            "Epoch 1, Batch 381, Gen Loss: 0.0077, Disc Loss: 0.2088\n",
            "Epoch 1, Batch 382, Gen Loss: 0.0058, Disc Loss: 0.1805\n",
            "Epoch 1, Batch 383, Gen Loss: 0.0065, Disc Loss: 0.1090\n",
            "Epoch 1, Batch 384, Gen Loss: 0.0083, Disc Loss: 0.1082\n",
            "Epoch 1, Batch 385, Gen Loss: 0.0092, Disc Loss: 0.0895\n",
            "Epoch 1, Batch 386, Gen Loss: 0.0077, Disc Loss: 0.1091\n",
            "Epoch 1, Batch 387, Gen Loss: 0.0064, Disc Loss: 0.1626\n",
            "Epoch 1, Batch 388, Gen Loss: 0.0059, Disc Loss: 0.1180\n",
            "Epoch 1, Batch 389, Gen Loss: 0.0067, Disc Loss: 0.1035\n",
            "Epoch 1, Batch 390, Gen Loss: 0.0064, Disc Loss: 0.1290\n",
            "Epoch 1, Batch 391, Gen Loss: 0.0066, Disc Loss: 0.1198\n",
            "Epoch 1, Batch 392, Gen Loss: 0.0065, Disc Loss: 0.1163\n",
            "Epoch 1, Batch 393, Gen Loss: 0.0074, Disc Loss: 0.1097\n",
            "Epoch 1, Batch 394, Gen Loss: 0.0075, Disc Loss: 0.0680\n",
            "Epoch 1, Batch 395, Gen Loss: 0.0084, Disc Loss: 0.1623\n",
            "Epoch 1, Batch 396, Gen Loss: 0.0072, Disc Loss: 0.2358\n",
            "Epoch 1, Batch 397, Gen Loss: 0.0078, Disc Loss: 0.1894\n",
            "Epoch 1, Batch 398, Gen Loss: 0.0084, Disc Loss: 0.0733\n",
            "Epoch 1, Batch 399, Gen Loss: 0.0079, Disc Loss: 0.1369\n",
            "Epoch 1, Batch 400, Gen Loss: 0.0064, Disc Loss: 0.2853\n",
            "Epoch 1, Batch 401, Gen Loss: 0.0077, Disc Loss: 0.1639\n",
            "Epoch 1, Batch 402, Gen Loss: 0.0074, Disc Loss: 0.0847\n",
            "Epoch 1, Batch 403, Gen Loss: 0.0077, Disc Loss: 0.1174\n",
            "Epoch 1, Batch 404, Gen Loss: 0.0098, Disc Loss: 0.1324\n",
            "Epoch 1, Batch 405, Gen Loss: 0.0090, Disc Loss: 0.0827\n",
            "Epoch 1, Batch 406, Gen Loss: 0.0072, Disc Loss: 0.2609\n",
            "Epoch 1, Batch 407, Gen Loss: 0.0070, Disc Loss: 0.1440\n",
            "Epoch 1, Batch 408, Gen Loss: 0.0067, Disc Loss: 0.2076\n",
            "Epoch 1, Batch 409, Gen Loss: 0.0074, Disc Loss: 0.1156\n",
            "Epoch 1, Batch 410, Gen Loss: 0.0072, Disc Loss: 0.1505\n",
            "Epoch 1, Batch 411, Gen Loss: 0.0066, Disc Loss: 0.1300\n",
            "Epoch 1, Batch 412, Gen Loss: 0.0072, Disc Loss: 0.1662\n",
            "Epoch 1, Batch 413, Gen Loss: 0.0071, Disc Loss: 0.0679\n",
            "Epoch 1, Batch 414, Gen Loss: 0.0069, Disc Loss: 0.0705\n",
            "Epoch 1, Batch 415, Gen Loss: 0.0068, Disc Loss: 0.1326\n",
            "Epoch 1, Batch 416, Gen Loss: 0.0073, Disc Loss: 0.0737\n",
            "Epoch 1, Batch 417, Gen Loss: 0.0069, Disc Loss: 0.0806\n",
            "Epoch 1, Batch 418, Gen Loss: 0.0074, Disc Loss: 0.0696\n",
            "Epoch 1, Batch 419, Gen Loss: 0.0061, Disc Loss: 0.1696\n",
            "Epoch 1, Batch 420, Gen Loss: 0.0069, Disc Loss: 0.1782\n",
            "Epoch 1, Batch 421, Gen Loss: 0.0070, Disc Loss: 0.0865\n",
            "Epoch 1, Batch 422, Gen Loss: 0.0072, Disc Loss: 0.1944\n",
            "Epoch 1, Batch 423, Gen Loss: 0.0063, Disc Loss: 0.0805\n",
            "Epoch 1, Batch 424, Gen Loss: 0.0067, Disc Loss: 0.0802\n",
            "Epoch 1, Batch 425, Gen Loss: 0.0060, Disc Loss: 0.1458\n",
            "Epoch 1, Batch 426, Gen Loss: 0.0078, Disc Loss: 0.1429\n",
            "Epoch 1, Batch 427, Gen Loss: 0.0074, Disc Loss: 0.1190\n",
            "Epoch 1, Batch 428, Gen Loss: 0.0067, Disc Loss: 0.1465\n",
            "Epoch 1, Batch 429, Gen Loss: 0.0086, Disc Loss: 0.1269\n",
            "Epoch 1, Batch 430, Gen Loss: 0.0091, Disc Loss: 0.0883\n",
            "Epoch 1, Batch 431, Gen Loss: 0.0073, Disc Loss: 0.1137\n",
            "Epoch 1, Batch 432, Gen Loss: 0.0061, Disc Loss: 0.1464\n",
            "Epoch 1, Batch 433, Gen Loss: 0.0063, Disc Loss: 0.0849\n",
            "Epoch 1, Batch 434, Gen Loss: 0.0061, Disc Loss: 0.1965\n",
            "Epoch 1, Batch 435, Gen Loss: 0.0061, Disc Loss: 0.1302\n",
            "Epoch 1, Batch 436, Gen Loss: 0.0066, Disc Loss: 0.1766\n",
            "Epoch 1, Batch 437, Gen Loss: 0.0064, Disc Loss: 0.1436\n",
            "Epoch 1, Batch 438, Gen Loss: 0.0060, Disc Loss: 0.1182\n",
            "Epoch 1, Batch 439, Gen Loss: 0.0090, Disc Loss: 0.0791\n",
            "Epoch 1, Batch 440, Gen Loss: 0.0068, Disc Loss: 0.0567\n",
            "Epoch 1, Batch 441, Gen Loss: 0.0065, Disc Loss: 0.1777\n",
            "Epoch 1, Batch 442, Gen Loss: 0.0070, Disc Loss: 0.1310\n",
            "Epoch 1, Batch 443, Gen Loss: 0.0093, Disc Loss: 0.1933\n",
            "Epoch 1, Batch 444, Gen Loss: 0.0092, Disc Loss: 0.1130\n",
            "Epoch 1, Batch 445, Gen Loss: 0.0061, Disc Loss: 0.2319\n",
            "Epoch 1, Batch 446, Gen Loss: 0.0054, Disc Loss: 0.2116\n",
            "Epoch 1, Batch 447, Gen Loss: 0.0064, Disc Loss: 0.2296\n",
            "Epoch 1, Batch 448, Gen Loss: 0.0055, Disc Loss: 0.0916\n",
            "Epoch 1, Batch 449, Gen Loss: 0.0063, Disc Loss: 0.2072\n",
            "Epoch 1, Batch 450, Gen Loss: 0.0067, Disc Loss: 0.1176\n",
            "Epoch 1, Batch 451, Gen Loss: 0.0066, Disc Loss: 0.1282\n",
            "Epoch 1, Batch 452, Gen Loss: 0.0060, Disc Loss: 0.2001\n",
            "Epoch 1, Batch 453, Gen Loss: 0.0074, Disc Loss: 0.1535\n",
            "Epoch 1, Batch 454, Gen Loss: 0.0100, Disc Loss: 0.1221\n",
            "Epoch 1, Batch 455, Gen Loss: 0.0085, Disc Loss: 0.2169\n",
            "Epoch 1, Batch 456, Gen Loss: 0.0059, Disc Loss: 0.0775\n",
            "Epoch 1, Batch 457, Gen Loss: 0.0060, Disc Loss: 0.0906\n",
            "Epoch 1, Batch 458, Gen Loss: 0.0064, Disc Loss: 0.0958\n",
            "Epoch 1, Batch 459, Gen Loss: 0.0062, Disc Loss: 0.1096\n",
            "Epoch 1, Batch 460, Gen Loss: 0.0067, Disc Loss: 0.1100\n",
            "Epoch 1, Batch 461, Gen Loss: 0.0064, Disc Loss: 0.0549\n",
            "Epoch 1, Batch 462, Gen Loss: 0.0063, Disc Loss: 0.2086\n",
            "Epoch 1, Batch 463, Gen Loss: 0.0068, Disc Loss: 0.1486\n",
            "Epoch 1, Batch 464, Gen Loss: 0.0056, Disc Loss: 0.0981\n",
            "Epoch 1, Batch 465, Gen Loss: 0.0067, Disc Loss: 0.0675\n",
            "Epoch 1, Batch 466, Gen Loss: 0.0059, Disc Loss: 0.2183\n",
            "Epoch 1, Batch 467, Gen Loss: 0.0062, Disc Loss: 0.1197\n",
            "Epoch 1, Batch 468, Gen Loss: 0.0055, Disc Loss: 0.0814\n",
            "Epoch 1, Batch 469, Gen Loss: 0.0055, Disc Loss: 0.1056\n",
            "Epoch 1, Batch 470, Gen Loss: 0.0062, Disc Loss: 0.0871\n",
            "Epoch 1, Batch 471, Gen Loss: 0.0063, Disc Loss: 0.0606\n",
            "Epoch 1, Batch 472, Gen Loss: 0.0061, Disc Loss: 0.0589\n",
            "Epoch 1, Batch 473, Gen Loss: 0.0064, Disc Loss: 0.0972\n",
            "Epoch 1, Batch 474, Gen Loss: 0.0062, Disc Loss: 0.1008\n",
            "Epoch 1, Batch 475, Gen Loss: 0.0063, Disc Loss: 0.1270\n",
            "Epoch 1, Batch 476, Gen Loss: 0.0067, Disc Loss: 0.1089\n",
            "Epoch 1, Batch 477, Gen Loss: 0.0074, Disc Loss: 0.1567\n",
            "Epoch 1, Batch 478, Gen Loss: 0.0059, Disc Loss: 0.2879\n",
            "Epoch 1, Batch 479, Gen Loss: 0.0066, Disc Loss: 0.1006\n",
            "Epoch 1, Batch 480, Gen Loss: 0.0061, Disc Loss: 0.1334\n",
            "Epoch 1, Batch 481, Gen Loss: 0.0061, Disc Loss: 0.0758\n",
            "Epoch 1, Batch 482, Gen Loss: 0.0068, Disc Loss: 0.0840\n",
            "Epoch 1, Batch 483, Gen Loss: 0.0064, Disc Loss: 0.0619\n",
            "Epoch 1, Batch 484, Gen Loss: 0.0081, Disc Loss: 0.0730\n",
            "Epoch 1, Batch 485, Gen Loss: 0.0069, Disc Loss: 0.1015\n",
            "Epoch 1, Batch 486, Gen Loss: 0.0057, Disc Loss: 0.1948\n",
            "Epoch 1, Batch 487, Gen Loss: 0.0066, Disc Loss: 0.1111\n",
            "Epoch 1, Batch 488, Gen Loss: 0.0063, Disc Loss: 0.1861\n",
            "Epoch 1, Batch 489, Gen Loss: 0.0060, Disc Loss: 0.0910\n",
            "Epoch 1, Batch 490, Gen Loss: 0.0055, Disc Loss: 0.1391\n",
            "Epoch 1, Batch 491, Gen Loss: 0.0065, Disc Loss: 0.1242\n",
            "Epoch 1, Batch 492, Gen Loss: 0.0076, Disc Loss: 0.0845\n",
            "Epoch 1, Batch 493, Gen Loss: 0.0072, Disc Loss: 0.1001\n",
            "Epoch 1, Batch 494, Gen Loss: 0.0060, Disc Loss: 0.0821\n",
            "Epoch 1, Batch 495, Gen Loss: 0.0064, Disc Loss: 0.0807\n",
            "Epoch 1, Batch 496, Gen Loss: 0.0060, Disc Loss: 0.0842\n",
            "Epoch 1, Batch 497, Gen Loss: 0.0073, Disc Loss: 0.1142\n",
            "Epoch 1, Batch 498, Gen Loss: 0.0070, Disc Loss: 0.0663\n",
            "Epoch 1, Batch 499, Gen Loss: 0.0056, Disc Loss: 0.3096\n",
            "Epoch 1, Batch 500, Gen Loss: 0.0053, Disc Loss: 0.1416\n",
            "Epoch 1, Batch 501, Gen Loss: 0.0050, Disc Loss: 0.2226\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2, Batch 1, Gen Loss: 0.0058, Disc Loss: 0.0717\n",
            "Epoch 2, Batch 2, Gen Loss: 0.0064, Disc Loss: 0.1378\n",
            "Epoch 2, Batch 3, Gen Loss: 0.0062, Disc Loss: 0.0655\n",
            "Epoch 2, Batch 4, Gen Loss: 0.0048, Disc Loss: 0.1197\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3, Batch 1, Gen Loss: 0.0053, Disc Loss: 0.0712\n",
            "Epoch 3, Batch 2, Gen Loss: 0.0060, Disc Loss: 0.0694\n",
            "Epoch 3, Batch 3, Gen Loss: 0.0058, Disc Loss: 0.0740\n",
            "Epoch 3, Batch 4, Gen Loss: 0.0047, Disc Loss: 0.0988\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4, Batch 1, Gen Loss: 0.0053, Disc Loss: 0.0522\n",
            "Epoch 4, Batch 2, Gen Loss: 0.0060, Disc Loss: 0.0526\n",
            "Epoch 4, Batch 3, Gen Loss: 0.0058, Disc Loss: 0.0639\n",
            "Epoch 4, Batch 4, Gen Loss: 0.0046, Disc Loss: 0.0891\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 5, Batch 1, Gen Loss: 0.0053, Disc Loss: 0.0650\n",
            "Epoch 5, Batch 2, Gen Loss: 0.0060, Disc Loss: 0.0549\n",
            "Epoch 5, Batch 3, Gen Loss: 0.0058, Disc Loss: 0.0604\n",
            "Epoch 5, Batch 4, Gen Loss: 0.0046, Disc Loss: 0.0749\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 6, Batch 1, Gen Loss: 0.0053, Disc Loss: 0.0639\n",
            "Epoch 6, Batch 2, Gen Loss: 0.0059, Disc Loss: 0.0581\n",
            "Epoch 6, Batch 3, Gen Loss: 0.0057, Disc Loss: 0.0611\n",
            "Epoch 6, Batch 4, Gen Loss: 0.0046, Disc Loss: 0.0708\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 7, Batch 1, Gen Loss: 0.0052, Disc Loss: 0.0713\n",
            "Epoch 7, Batch 2, Gen Loss: 0.0059, Disc Loss: 0.0509\n",
            "Epoch 7, Batch 3, Gen Loss: 0.0057, Disc Loss: 0.0569\n",
            "Epoch 7, Batch 4, Gen Loss: 0.0046, Disc Loss: 0.0876\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 8, Batch 1, Gen Loss: 0.0052, Disc Loss: 0.1017\n",
            "Epoch 8, Batch 2, Gen Loss: 0.0059, Disc Loss: 0.0486\n",
            "Epoch 8, Batch 3, Gen Loss: 0.0057, Disc Loss: 0.0633\n",
            "Epoch 8, Batch 4, Gen Loss: 0.0045, Disc Loss: 0.0749\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 9, Batch 1, Gen Loss: 0.0052, Disc Loss: 0.1026\n",
            "Epoch 9, Batch 2, Gen Loss: 0.0059, Disc Loss: 0.0630\n",
            "Epoch 9, Batch 3, Gen Loss: 0.0056, Disc Loss: 0.0960\n",
            "Epoch 9, Batch 4, Gen Loss: 0.0045, Disc Loss: 0.0808\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 10, Batch 1, Gen Loss: 0.0051, Disc Loss: 0.1141\n",
            "Epoch 10, Batch 2, Gen Loss: 0.0058, Disc Loss: 0.0553\n",
            "Epoch 10, Batch 3, Gen Loss: 0.0056, Disc Loss: 0.0921\n",
            "Epoch 10, Batch 4, Gen Loss: 0.0045, Disc Loss: 0.1594\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 11, Batch 1, Gen Loss: 0.0051, Disc Loss: 0.1843\n",
            "Epoch 11, Batch 2, Gen Loss: 0.0058, Disc Loss: 0.0693\n",
            "Epoch 11, Batch 3, Gen Loss: 0.0056, Disc Loss: 0.0882\n",
            "Epoch 11, Batch 4, Gen Loss: 0.0045, Disc Loss: 0.1668\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 12, Batch 1, Gen Loss: 0.0051, Disc Loss: 0.1203\n",
            "Epoch 12, Batch 2, Gen Loss: 0.0058, Disc Loss: 0.2110\n",
            "Epoch 12, Batch 3, Gen Loss: 0.0056, Disc Loss: 0.1474\n",
            "Epoch 12, Batch 4, Gen Loss: 0.0044, Disc Loss: 0.2420\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 13, Batch 1, Gen Loss: 0.0051, Disc Loss: 0.0885\n",
            "Epoch 13, Batch 2, Gen Loss: 0.0058, Disc Loss: 0.2608\n",
            "Epoch 13, Batch 3, Gen Loss: 0.0055, Disc Loss: 0.0669\n",
            "Epoch 13, Batch 4, Gen Loss: 0.0044, Disc Loss: 0.4570\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 14, Batch 1, Gen Loss: 0.0051, Disc Loss: 0.0761\n",
            "Epoch 14, Batch 2, Gen Loss: 0.0057, Disc Loss: 0.3428\n",
            "Epoch 14, Batch 3, Gen Loss: 0.0055, Disc Loss: 0.0455\n",
            "Epoch 14, Batch 4, Gen Loss: 0.0044, Disc Loss: 0.4112\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 15, Batch 1, Gen Loss: 0.0050, Disc Loss: 0.1141\n",
            "Epoch 15, Batch 2, Gen Loss: 0.0057, Disc Loss: 0.4088\n",
            "Epoch 15, Batch 3, Gen Loss: 0.0055, Disc Loss: 0.1456\n",
            "Epoch 15, Batch 4, Gen Loss: 0.0044, Disc Loss: 0.3193\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 16, Batch 1, Gen Loss: 0.0050, Disc Loss: 0.2819\n",
            "Epoch 16, Batch 2, Gen Loss: 0.0057, Disc Loss: 0.2233\n",
            "Epoch 16, Batch 3, Gen Loss: 0.0055, Disc Loss: 0.3358\n",
            "Epoch 16, Batch 4, Gen Loss: 0.0044, Disc Loss: 0.1819\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 17, Batch 1, Gen Loss: 0.0050, Disc Loss: 0.4521\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 18, Batch 1, Gen Loss: 0.0049, Disc Loss: 0.2033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 19, Batch 1, Gen Loss: 0.0048, Disc Loss: 0.1662\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 20, Batch 1, Gen Loss: 0.0048, Disc Loss: 0.0517\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 21, Batch 1, Gen Loss: 0.0047, Disc Loss: 0.0782\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 22, Batch 1, Gen Loss: 0.0047, Disc Loss: 0.0350\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 23, Batch 1, Gen Loss: 0.0047, Disc Loss: 0.0327\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 24, Batch 1, Gen Loss: 0.0047, Disc Loss: 0.0272\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 25, Batch 1, Gen Loss: 0.0047, Disc Loss: 0.0203\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 26, Batch 1, Gen Loss: 0.0047, Disc Loss: 0.0181\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 27, Batch 1, Gen Loss: 0.0047, Disc Loss: 0.0157\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 28, Batch 1, Gen Loss: 0.0046, Disc Loss: 0.0138\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 29, Batch 1, Gen Loss: 0.0046, Disc Loss: 0.0125\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 30, Batch 1, Gen Loss: 0.0046, Disc Loss: 0.0115\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 31, Batch 1, Gen Loss: 0.0046, Disc Loss: 0.0106\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 32, Batch 1, Gen Loss: 0.0046, Disc Loss: 0.0098\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 33, Batch 1, Gen Loss: 0.0046, Disc Loss: 0.0092\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 34, Batch 1, Gen Loss: 0.0046, Disc Loss: 0.0086\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 35, Batch 1, Gen Loss: 0.0046, Disc Loss: 0.0080\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 36, Batch 1, Gen Loss: 0.0046, Disc Loss: 0.0075\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 37, Batch 1, Gen Loss: 0.0045, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 38, Batch 1, Gen Loss: 0.0045, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 39, Batch 1, Gen Loss: 0.0045, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 40, Batch 1, Gen Loss: 0.0045, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 41, Batch 1, Gen Loss: 0.0045, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 42, Batch 1, Gen Loss: 0.0045, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 43, Batch 1, Gen Loss: 0.0045, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 44, Batch 1, Gen Loss: 0.0045, Disc Loss: 0.0048\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 45, Batch 1, Gen Loss: 0.0045, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 46, Batch 1, Gen Loss: 0.0045, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 47, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0042\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 48, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0040\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 49, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 50, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0037\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 51, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 52, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 53, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 54, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 55, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 56, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 57, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 58, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 59, Batch 1, Gen Loss: 0.0044, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 60, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 61, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 62, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 63, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 64, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 65, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 66, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 67, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 68, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 69, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 70, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 71, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 72, Batch 1, Gen Loss: 0.0043, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 73, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 74, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 75, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 76, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 77, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 78, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 79, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 80, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 81, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 82, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 83, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 84, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 85, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 86, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 87, Batch 1, Gen Loss: 0.0042, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 88, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 89, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 90, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 91, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 92, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 93, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 94, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 95, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 96, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 97, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 98, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 99, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 100, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 101, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 102, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 103, Batch 1, Gen Loss: 0.0041, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 104, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 105, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 106, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 107, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 108, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 109, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 110, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 111, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 112, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 113, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 114, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 115, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 116, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 117, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 118, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 119, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 120, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 121, Batch 1, Gen Loss: 0.0040, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 122, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 123, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 124, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 125, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 126, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 127, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 128, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 129, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 130, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 131, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 132, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 133, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 134, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 135, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 136, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 137, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 138, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 139, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 140, Batch 1, Gen Loss: 0.0039, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 141, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 142, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 143, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 144, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 145, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 146, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 147, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0039\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 148, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 149, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 150, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0090\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 151, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0107\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 152, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0121\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 153, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0122\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 154, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0114\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 155, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0095\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 156, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0075\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 157, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 158, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 159, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0050\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 160, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 161, Batch 1, Gen Loss: 0.0038, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 162, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0068\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 163, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0079\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 164, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0087\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 165, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0096\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 166, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0099\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 167, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0099\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 168, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0093\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 169, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0085\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 170, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0072\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 171, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 172, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 173, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 174, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 175, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 176, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 177, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 178, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 179, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 180, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 181, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 182, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 183, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 184, Batch 1, Gen Loss: 0.0037, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 185, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 186, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 187, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 188, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 189, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 190, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 191, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 192, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 193, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 194, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 195, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 196, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 197, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 198, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 199, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0069\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 200, Batch 1, Gen Loss: 0.0036, Disc Loss: 0.0097\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU, Input, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "import cv2\n",
        "\n",
        "# Function to perform deblurring\n",
        "def deblur_image(image, kernel_size=5):\n",
        "    # Create a blurring kernel (e.g., Gaussian)\n",
        "    kernel = np.ones((kernel_size, kernel_size)) / kernel_size**2\n",
        "    deblurred_image = cv2.filter2D(image, -1, kernel)\n",
        "    return deblurred_image\n",
        "\n",
        "# Load the clean MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Select a random image from the dataset\n",
        "index = np.random.randint(0, x_train.shape[0])\n",
        "\n",
        "# Clean image\n",
        "clean_image = x_train[index] / 255.0\n",
        "\n",
        "# Blurred image\n",
        "blurred_image = deblur_image(clean_image)\n",
        "\n",
        "# Define the Deblur GAN, Generator, and Discriminator\n",
        "\n",
        "# Generator model for deblurring\n",
        "def build_deblur_generator(input_shape=(28, 28, 1)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Deblurring layers (replace with your desired architecture)\n",
        "    x = Conv2D(64, (3, 3), activation=\"relu\", padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, (3, 3), activation=\"relu\", padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Upsample with transposed convolutional blocks\n",
        "    x = Conv2DTranspose(64, 4, strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Output convolution\n",
        "    outputs = Conv2D(1, 3, activation='linear', padding='same')(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Create a PatchGAN Discriminator for deblurred images (you can customize this)\n",
        "def build_deblur_discriminator(input_shape=(28, 28, 1)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(64, (4, 4), strides=2, padding='same')(inputs)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(128, (4, 4), strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, (4, 4), strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(1, (4, 4), padding='same')(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=x)\n",
        "\n",
        "# Train the Deblur GAN with early stopping based on generator loss\n",
        "def train_deblur_gan(generator, discriminator, blurred_data, clean_data, batch_size, max_epochs, generator_loss_threshold=0.0050):\n",
        "    # Define loss functions (you may need to adjust these)\n",
        "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "    epoch = 0  # Initialize the epoch counter\n",
        "\n",
        "    while epoch < max_epochs:  # Continue until the maximum number of epochs is reached\n",
        "        for i in range(0, len(blurred_data), batch_size):\n",
        "            batch_blurred = blurred_data[i:i + batch_size]\n",
        "            batch_clean = clean_data[i:i + batch_size]\n",
        "\n",
        "            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "                # Generate deblurred images\n",
        "                generated_images = generator(batch_blurred, training=True)\n",
        "\n",
        "                # Discriminator loss (adversarial)\n",
        "                real_output = discriminator(batch_clean, training=True)\n",
        "                fake_output = discriminator(generated_images, training=True)\n",
        "                disc_loss = loss_fn(real_output, tf.ones_like(real_output)) + loss_fn(fake_output, tf.zeros_like(fake_output))\n",
        "\n",
        "                # Generator loss\n",
        "                gen_loss = loss_fn(batch_clean, generated_images)\n",
        "\n",
        "            gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "            gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "            generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "            discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}, Batch {i//batch_size + 1}, Gen Loss: {gen_loss:.4f}, Disc Loss: {disc_loss:.4f}\")\n",
        "\n",
        "            if gen_loss < generator_loss_threshold:\n",
        "                print(f\"Generator loss threshold ({generator_loss_threshold}) reached. Stopping training.\")\n",
        "                break  # Exit the training loop\n",
        "\n",
        "        epoch += 1  # Move to the next epoch\n",
        "\n",
        "    # Generate and display a noisy image alongside its denoised counterpart\n",
        "    sample_blurred = blurred_data[0:1]\n",
        "    sample_deblurred = generator(sample_blurred, training=False)\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Noisy Image\")\n",
        "    plt.imshow(sample_blurred[0].reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Deblurred Image\")\n",
        "    plt.imshow(sample_deblurred[0].numpy().reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Set hyperparameters\n",
        "batch_size = 32\n",
        "max_epochs_deblur_gan = 200  # Maximum number of epochs\n",
        "generator_loss_threshold = 0.0050  # Generator loss threshold\n",
        "\n",
        "# Prepare data\n",
        "num_samples = x_train.shape[0]\n",
        "blurred_data = np.array([deblur_image(image / 255.0) for image in x_train])\n",
        "blurred_data = np.expand_dims(blurred_data, axis=-1)\n",
        "clean_data = np.expand_dims(x_train / 255.0, axis=-1)\n",
        "\n",
        "# Create and train the Deblur GAN with early stopping\n",
        "deblur_generator = build_deblur_generator()\n",
        "deblur_discriminator = build_deblur_discriminator()\n",
        "\n",
        "# Train the Deblur GAN\n",
        "train_deblur_gan(deblur_generator, deblur_discriminator, blurred_data, clean_data, batch_size, max_epochs_deblur_gan, generator_loss_threshold)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_qHU2IE_Sxi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MO510m573vdg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UgAmdQOV3vgj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "esBBa-2o3vmw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oU2z2G0g3vq_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gmaFSWgP3vvn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NRRvWk3mFqqT",
        "outputId": "5d9dc37e-ee43-4884-e472-6d5942636d58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch 2501, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2502, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2503, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2504, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2505, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2506, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2507, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2508, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2509, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2510, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2511, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2512, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2513, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2514, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2515, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2516, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2517, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2518, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0064\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2519, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0096\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2520, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0124\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2521, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0131\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2522, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0107\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2523, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0057\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2524, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0040\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2525, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2526, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0194\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2527, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0324\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2528, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0497\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2529, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0563\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2530, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0601\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2531, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0499\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2532, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0320\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2533, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0234\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2534, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0182\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2535, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0199\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2536, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0168\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2537, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0144\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2538, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0114\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2539, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0089\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2540, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0074\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2541, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2542, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0058\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2543, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0062\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2544, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0069\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2545, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2546, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0065\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2547, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0058\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2548, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2549, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2550, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2551, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0064\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2552, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0065\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2553, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0067\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2554, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0058\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2555, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0058\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2556, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2557, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2558, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2559, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0093\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2560, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0137\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2561, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0130\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2562, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0082\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2563, Batch 1, Gen Loss: 0.0017, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2564, Batch 1, Gen Loss: 0.0018, Disc Loss: 0.0102\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2565, Batch 1, Gen Loss: 0.0019, Disc Loss: 0.0179\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2566, Batch 1, Gen Loss: 0.0019, Disc Loss: 0.0156\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2567, Batch 1, Gen Loss: 0.0019, Disc Loss: 0.0089\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2568, Batch 1, Gen Loss: 0.0018, Disc Loss: 0.0081\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2569, Batch 1, Gen Loss: 0.0017, Disc Loss: 0.0211\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2570, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0317\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2571, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0336\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2572, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0183\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2573, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0113\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2574, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0231\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2575, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0370\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2576, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0305\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2577, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0143\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2578, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2579, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0091\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2580, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0141\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2581, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0130\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2582, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0094\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2583, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2584, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2585, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2586, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2587, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2588, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2589, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2590, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2591, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2592, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2593, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2594, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2595, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2596, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2597, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2598, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2599, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0077\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2600, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0100\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2601, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0098\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2602, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0087\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2603, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2604, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2605, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2606, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2607, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2608, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0103\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2609, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0143\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2610, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0137\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2611, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0110\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2612, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0082\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2613, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0073\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2614, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0093\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2615, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0098\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2616, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0102\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2617, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0082\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2618, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0064\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2619, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2620, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2621, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0072\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2622, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0094\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2623, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0105\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2624, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0083\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2625, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0047\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2626, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2627, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2628, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0069\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2629, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0072\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2630, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2631, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2632, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0047\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2633, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0089\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2634, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0133\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2635, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0145\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2636, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0104\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2637, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2638, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2639, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0064\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2640, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0082\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2641, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0077\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2642, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0073\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2643, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0101\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2644, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0156\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2645, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0217\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2646, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0252\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2647, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0310\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2648, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0282\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2649, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0257\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2650, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0197\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2651, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0154\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2652, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0117\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2653, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0089\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2654, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2655, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0083\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2656, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0111\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2657, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0168\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2658, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0196\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2659, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0231\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2660, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0221\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2661, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0224\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2662, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0193\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2663, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0192\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2664, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0164\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2665, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0141\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2666, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0109\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2667, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0106\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2668, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0134\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2669, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0213\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2670, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0254\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2671, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0254\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2672, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0162\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2673, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0092\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2674, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0091\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2675, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0123\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2676, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0153\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2677, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0148\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2678, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0124\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2679, Batch 1, Gen Loss: 0.0017, Disc Loss: 0.0109\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2680, Batch 1, Gen Loss: 0.0019, Disc Loss: 0.0116\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2681, Batch 1, Gen Loss: 0.0020, Disc Loss: 0.0141\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2682, Batch 1, Gen Loss: 0.0021, Disc Loss: 0.0179\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2683, Batch 1, Gen Loss: 0.0021, Disc Loss: 0.0214\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2684, Batch 1, Gen Loss: 0.0020, Disc Loss: 0.0233\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2685, Batch 1, Gen Loss: 0.0019, Disc Loss: 0.0211\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2686, Batch 1, Gen Loss: 0.0017, Disc Loss: 0.0230\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2687, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0302\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2688, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0439\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2689, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0432\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2690, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0463\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2691, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0397\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2692, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0293\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2693, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0214\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2694, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0178\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2695, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0289\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2696, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0369\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2697, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0487\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2698, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0404\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2699, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0277\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2700, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0136\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2701, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2702, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0047\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2703, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2704, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2705, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0078\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2706, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0100\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2707, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0093\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2708, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0073\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2709, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2710, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2711, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2712, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2713, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2714, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2715, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2716, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2717, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2718, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2719, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2720, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2721, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2722, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2723, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2724, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2725, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2726, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2727, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2728, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2729, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2730, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2731, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0037\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2732, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2733, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2734, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2735, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0085\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2736, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0109\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2737, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0122\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2738, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0149\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2739, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0162\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2740, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0183\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2741, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0175\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2742, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0175\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2743, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0143\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2744, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0107\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2745, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0081\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2746, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0092\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2747, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0136\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2748, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0207\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2749, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0222\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2750, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0178\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2751, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0096\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2752, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0097\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2753, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0164\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2754, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0226\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2755, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0239\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2756, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0239\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2757, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0171\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2758, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0171\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2759, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0308\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2760, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0553\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2761, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0680\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2762, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0509\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2763, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0218\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2764, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0288\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2765, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0645\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2766, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0906\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2767, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0716\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2768, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0406\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2769, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0410\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2770, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0371\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2771, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0256\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2772, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0117\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2773, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2774, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0058\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2775, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2776, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2777, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2778, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0042\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2779, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0065\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2780, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0083\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2781, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0075\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2782, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0048\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2783, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2784, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2785, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2786, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2787, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2788, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2789, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2790, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0067\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2791, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0050\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2792, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2793, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2794, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0039\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2795, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2796, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2797, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2798, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2799, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2800, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2801, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2802, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0097\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2803, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0128\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2804, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0111\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2805, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2806, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2807, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2808, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0057\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2809, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0065\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2810, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2811, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2812, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2813, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2814, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2815, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2816, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2817, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2818, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2819, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2820, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2821, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2822, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0081\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2823, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0143\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2824, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0170\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2825, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0226\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2826, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0234\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2827, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0235\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2828, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0210\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2829, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0199\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2830, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0184\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2831, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0139\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2832, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0095\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2833, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0057\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2834, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2835, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2836, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2837, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2838, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2839, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2840, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2841, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2842, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2843, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2844, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2845, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0067\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2846, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2847, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2848, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2849, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2850, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2851, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2852, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2853, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2854, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2855, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2856, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2857, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2858, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2859, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2860, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2861, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2862, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2863, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2864, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2865, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2866, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2867, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2868, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0039\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2869, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2870, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2871, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2872, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2873, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2874, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2875, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0050\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2876, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2877, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0100\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2878, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0115\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2879, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0100\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2880, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0064\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2881, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2882, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0081\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2883, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0126\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2884, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0168\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2885, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0167\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2886, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0131\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2887, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0081\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2888, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2889, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2890, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2891, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2892, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2893, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0090\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2894, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0166\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2895, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0239\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2896, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0375\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2897, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0450\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2898, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0585\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2899, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0550\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2900, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0475\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2901, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0334\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2902, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0266\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2903, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0252\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2904, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0240\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2905, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0288\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2906, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0376\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2907, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0379\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2908, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0286\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2909, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0358\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2910, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0596\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2911, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0846\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2912, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0741\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2913, Batch 1, Gen Loss: 0.0017, Disc Loss: 0.0318\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2914, Batch 1, Gen Loss: 0.0020, Disc Loss: 0.0362\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2915, Batch 1, Gen Loss: 0.0022, Disc Loss: 0.0943\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2916, Batch 1, Gen Loss: 0.0023, Disc Loss: 0.1149\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2917, Batch 1, Gen Loss: 0.0024, Disc Loss: 0.0759\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2918, Batch 1, Gen Loss: 0.0023, Disc Loss: 0.0964\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2919, Batch 1, Gen Loss: 0.0022, Disc Loss: 0.1526\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2920, Batch 1, Gen Loss: 0.0019, Disc Loss: 0.1741\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2921, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.1748\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2922, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.1614\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2923, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.1547\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2924, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.1382\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2925, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.1035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2926, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0747\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2927, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0542\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2928, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0684\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2929, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0431\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2930, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0165\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2931, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0075\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2932, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0071\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2933, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0068\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2934, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2935, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2936, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2937, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2938, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0081\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2939, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0108\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2940, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0142\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2941, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0101\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2942, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2943, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2944, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2945, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2946, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2947, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2948, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2949, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2950, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2951, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2952, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2953, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2954, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2955, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2956, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2957, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2958, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2959, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2960, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2961, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2962, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2963, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2964, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2965, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2966, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2967, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2968, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2969, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2970, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2971, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2972, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2973, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2974, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2975, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2976, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2977, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2978, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2979, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2980, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2981, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2982, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2983, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2984, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2985, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2986, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2987, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2988, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2989, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2990, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2991, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2992, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2993, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2994, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2995, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2996, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2997, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2998, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 2999, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3000, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3001, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3002, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3003, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3004, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3005, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3006, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3007, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3008, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3009, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3010, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3011, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3012, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3013, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3014, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3015, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3016, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3017, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3018, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3019, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3020, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3021, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3022, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3023, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3024, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3025, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3026, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3027, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3028, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3029, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3030, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3031, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3032, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3033, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3034, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3035, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3036, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3037, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3038, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3039, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3040, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3041, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3042, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0040\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3043, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3044, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3045, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0042\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3046, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3047, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3048, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3049, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3050, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3051, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3052, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3053, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3054, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3055, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3056, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3057, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3058, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3059, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3060, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3061, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0043\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3062, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0073\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3063, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0088\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3064, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0102\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3065, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0095\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3066, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0087\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3067, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0086\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3068, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0089\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3069, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0107\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3070, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0114\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3071, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0115\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3072, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0096\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3073, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0095\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3074, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0094\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3075, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0088\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3076, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0071\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3077, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3078, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3079, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3080, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0082\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3081, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0100\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3082, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0094\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3083, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3084, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3085, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0057\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3086, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0098\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3087, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0121\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3088, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0128\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3089, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0085\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3090, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3091, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0078\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3092, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0117\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3093, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0140\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3094, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0104\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3095, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0064\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3096, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0078\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3097, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0112\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3098, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0113\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3099, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0057\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3100, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3101, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0101\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3102, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0194\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3103, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0185\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3104, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0103\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3105, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3106, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0067\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3107, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0123\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3108, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0137\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3109, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0124\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3110, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0159\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3111, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0177\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3112, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0167\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3113, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0101\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3114, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0074\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3115, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0131\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3116, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0173\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3117, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0163\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3118, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0095\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3119, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3120, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0162\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3121, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0311\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3122, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0651\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3123, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0833\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3124, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3125, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0835\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3126, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0640\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3127, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0447\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3128, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0338\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3129, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0238\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3130, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0163\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3131, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0153\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3132, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0175\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3133, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0177\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3134, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0146\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3135, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0098\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3136, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0076\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3137, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0090\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3138, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0158\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3139, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0231\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3140, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0297\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3141, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0240\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3142, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0157\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3143, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0082\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3144, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0074\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3145, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0119\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3146, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0143\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3147, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0103\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3148, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3149, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0097\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3150, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0200\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3151, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0253\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3152, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0183\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3153, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0119\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3154, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0192\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3155, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0331\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3156, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0350\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3157, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0249\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3158, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0207\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3159, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0268\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3160, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0399\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3161, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0334\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3162, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0205\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3163, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0159\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3164, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0187\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3165, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0277\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3166, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0276\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3167, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0230\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3168, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0147\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3169, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0092\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3170, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3171, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3172, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3173, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3174, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3175, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3176, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3177, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3178, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3179, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3180, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3181, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3182, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3183, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3184, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3185, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3186, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3187, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3188, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3189, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3190, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3191, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3192, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3193, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3194, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3195, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3196, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3197, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3198, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3199, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3200, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3201, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3202, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3203, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3204, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3205, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3206, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3207, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3208, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3209, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3210, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3211, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3212, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3213, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3214, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3215, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3216, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3217, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3218, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3219, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3220, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3221, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3222, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3223, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3224, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0042\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3225, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0047\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3226, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0048\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3227, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3228, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3229, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3230, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3231, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3232, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3233, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3234, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3235, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3236, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3237, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3238, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3239, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3240, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3241, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3242, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3243, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3244, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3245, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3246, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3247, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3248, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3249, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3250, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3251, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3252, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0068\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3253, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0076\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3254, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0065\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3255, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3256, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3257, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3258, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0111\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3259, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0164\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3260, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0187\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3261, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0159\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3262, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0132\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3263, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0113\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3264, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0146\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3265, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0186\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3266, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0224\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3267, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0215\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3268, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0179\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3269, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0139\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3270, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0115\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3271, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0103\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3272, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0132\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3273, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0197\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3274, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0408\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3275, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0649\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3276, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1134\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3277, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1618\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3278, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.2249\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3279, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1962\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3280, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3281, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0432\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3282, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0356\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3283, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0227\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3284, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0200\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3285, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0255\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3286, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0462\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3287, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0665\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3288, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1071\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3289, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1106\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3290, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3291, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0606\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3292, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0277\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3293, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0109\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3294, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0079\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3295, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0085\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3296, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0102\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3297, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0119\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3298, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0141\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3299, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0151\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3300, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0165\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3301, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0156\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3302, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0129\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3303, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0076\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3304, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3305, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3306, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0040\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3307, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3308, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0075\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3309, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0064\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3310, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3311, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3312, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0057\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3313, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3314, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3315, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3316, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3317, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3318, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3319, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3320, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3321, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0091\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3322, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0136\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3323, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0113\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3324, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0064\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3325, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0102\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3326, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0186\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3327, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0247\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3328, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0215\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3329, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0121\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3330, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3331, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3332, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3333, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3334, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0057\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3335, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0037\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3336, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3337, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3338, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3339, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3340, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3341, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3342, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3343, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3344, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3345, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3346, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3347, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3348, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3349, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3350, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3351, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3352, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3353, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3354, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3355, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3356, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3357, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3358, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3359, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3360, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3361, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3362, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3363, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3364, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3365, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3366, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3367, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3368, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3369, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3370, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0076\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3371, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0068\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3372, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0040\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3373, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3374, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3375, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3376, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0073\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3377, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0067\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3378, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0043\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3379, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3380, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3381, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3382, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0102\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3383, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0104\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3384, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0091\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3385, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3386, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3387, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3388, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3389, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3390, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3391, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3392, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3393, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3394, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3395, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3396, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3397, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3398, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3399, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3400, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3401, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3402, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3403, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3404, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3405, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3406, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3407, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3408, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3409, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3410, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3411, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3412, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3413, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0050\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3414, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0058\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3415, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0050\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3416, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3417, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3418, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3419, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3420, Batch 1, Gen Loss: 0.0017, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3421, Batch 1, Gen Loss: 0.0017, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3422, Batch 1, Gen Loss: 0.0017, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3423, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3424, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0094\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3425, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0161\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3426, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0170\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3427, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0129\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3428, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0129\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3429, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0238\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3430, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0354\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3431, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0378\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3432, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0341\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3433, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0282\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3434, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0360\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3435, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0412\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3436, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0536\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3437, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0550\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3438, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0539\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3439, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0428\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3440, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0298\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3441, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0178\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3442, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0105\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3443, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0098\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3444, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0105\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3445, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0097\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3446, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3447, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3448, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3449, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0077\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3450, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0126\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3451, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0138\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3452, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0125\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3453, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0076\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3454, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3455, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3456, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3457, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0098\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3458, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0124\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3459, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0111\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3460, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0067\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3461, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0040\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3462, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3463, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0087\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3464, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0097\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3465, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0069\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3466, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3467, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0089\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3468, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0173\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3469, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0271\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3470, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0249\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3471, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0168\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3472, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0089\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3473, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0079\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3474, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0145\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3475, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0175\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3476, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0144\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3477, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0100\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3478, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0143\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3479, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0336\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3480, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0569\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3481, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0812\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3482, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0726\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3483, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0446\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3484, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0206\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3485, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0117\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3486, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0164\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3487, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0209\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3488, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0230\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3489, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0207\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3490, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0174\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3491, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0165\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3492, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0185\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3493, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0288\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3494, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0364\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3495, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0415\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3496, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0295\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3497, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0181\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3498, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0105\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3499, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0069\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3500, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0064\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3501, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0068\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3502, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0062\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3503, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3504, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3505, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0067\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3506, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0078\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3507, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3508, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3509, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3510, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3511, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3512, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3513, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0047\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3514, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3515, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3516, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3517, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0037\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3518, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3519, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3520, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3521, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3522, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3523, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3524, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3525, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3526, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3527, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3528, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3529, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3530, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3531, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3532, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0067\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3533, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0078\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3534, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0076\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3535, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0082\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3536, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0090\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3537, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0125\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3538, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0185\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3539, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0245\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3540, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0248\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3541, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0181\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3542, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0121\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3543, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0145\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3544, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0214\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3545, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0297\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3546, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0266\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3547, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0217\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3548, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0152\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3549, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0133\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3550, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0116\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3551, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0141\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3552, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0157\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3553, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0233\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3554, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0317\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3555, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0535\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3556, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0780\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3557, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.1258\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3558, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.1577\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3559, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1723\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3560, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1102\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3561, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0717\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3562, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0525\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3563, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0533\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3564, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0435\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3565, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0368\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3566, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0236\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3567, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0132\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3568, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3569, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3570, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3571, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3572, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3573, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3574, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3575, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3576, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3577, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3578, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3579, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3580, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3581, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3582, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3583, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3584, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0043\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3585, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3586, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3587, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3588, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3589, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3590, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0069\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3591, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0068\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3592, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0062\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3593, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0048\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3594, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0043\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3595, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3596, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0048\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3597, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3598, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3599, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0058\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3600, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0057\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3601, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3602, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3603, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0074\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3604, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0109\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3605, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0110\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3606, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0098\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3607, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0071\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3608, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3609, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3610, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3611, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3612, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3613, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3614, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3615, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3616, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3617, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3618, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3619, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3620, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3621, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0080\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3622, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0085\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3623, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3624, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0037\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3625, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3626, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0085\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3627, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0103\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3628, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0082\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3629, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0091\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3630, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0170\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3631, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0239\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3632, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0225\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3633, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0202\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3634, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0287\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3635, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0476\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3636, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0534\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3637, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0344\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3638, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0160\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3639, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0152\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3640, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0263\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3641, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0275\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3642, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0195\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3643, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0095\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3644, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3645, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3646, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0050\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3647, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3648, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3649, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3650, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3651, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0073\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3652, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0101\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3653, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0091\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3654, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0068\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3655, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3656, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3657, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3658, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3659, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3660, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3661, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3662, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3663, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3664, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3665, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3666, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3667, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3668, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3669, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3670, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3671, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3672, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3673, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3674, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3675, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3676, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3677, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3678, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3679, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3680, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3681, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3682, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3683, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3684, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3685, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3686, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3687, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3688, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3689, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3690, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3691, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3692, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3693, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3694, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3695, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3696, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3697, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3698, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3699, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3700, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3701, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3702, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3703, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3704, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3705, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3706, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3707, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3708, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3709, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0077\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3710, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0089\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3711, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0092\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3712, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0074\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3713, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3714, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3715, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0050\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3716, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3717, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0080\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3718, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0084\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3719, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0105\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3720, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0171\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3721, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0409\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3722, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0622\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3723, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0922\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3724, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0943\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3725, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0836\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3726, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0366\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3727, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0110\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3728, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0183\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3729, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0198\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3730, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0125\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3731, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0081\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3732, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0105\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3733, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0139\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3734, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0144\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3735, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0105\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3736, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3737, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3738, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0077\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3739, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0078\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3740, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3741, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0068\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3742, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0104\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3743, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0114\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3744, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0089\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3745, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0100\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3746, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0176\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3747, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0211\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3748, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0170\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3749, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0128\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3750, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0138\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3751, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0171\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3752, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0145\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3753, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0114\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3754, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0133\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3755, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0139\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3756, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0154\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3757, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0114\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3758, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0075\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3759, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3760, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0071\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3761, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0146\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3762, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0219\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3763, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0376\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3764, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0431\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3765, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0483\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3766, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0406\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3767, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0316\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3768, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0183\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3769, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0115\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3770, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0074\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3771, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0071\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3772, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0068\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3773, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0074\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3774, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3775, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3776, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3777, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0058\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3778, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3779, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3780, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0039\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3781, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3782, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3783, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3784, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3785, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3786, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3787, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3788, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0040\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3789, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3790, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3791, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3792, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3793, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3794, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3795, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3796, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3797, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3798, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3799, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3800, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3801, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0040\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3802, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3803, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3804, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3805, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0068\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3806, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0071\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3807, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0075\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3808, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0071\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3809, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3810, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3811, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3812, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0094\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3813, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0166\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3814, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0203\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3815, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0208\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3816, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0140\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3817, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0075\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3818, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3819, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0077\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3820, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0118\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3821, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0156\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3822, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0160\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3823, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0128\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3824, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0093\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3825, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0097\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3826, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0124\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3827, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0181\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3828, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0179\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3829, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0150\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3830, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0099\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3831, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0065\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3832, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3833, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3834, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3835, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3836, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3837, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3838, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3839, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3840, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3841, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3842, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3843, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3844, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3845, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3846, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3847, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3848, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3849, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3850, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3851, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3852, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3853, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3854, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0112\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3855, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0153\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3856, Batch 1, Gen Loss: 0.0018, Disc Loss: 0.0131\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3857, Batch 1, Gen Loss: 0.0020, Disc Loss: 0.0077\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3858, Batch 1, Gen Loss: 0.0023, Disc Loss: 0.0078\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3859, Batch 1, Gen Loss: 0.0024, Disc Loss: 0.0180\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3860, Batch 1, Gen Loss: 0.0025, Disc Loss: 0.0276\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3861, Batch 1, Gen Loss: 0.0024, Disc Loss: 0.0271\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3862, Batch 1, Gen Loss: 0.0022, Disc Loss: 0.0333\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3863, Batch 1, Gen Loss: 0.0019, Disc Loss: 0.0444\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3864, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0557\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3865, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0694\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3866, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0932\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3867, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.1074\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3868, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.1198\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3869, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.1136\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3870, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0832\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3871, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0636\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3872, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0642\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3873, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0802\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3874, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0639\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3875, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0363\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3876, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0217\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3877, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0211\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3878, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0291\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3879, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0346\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3880, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0381\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3881, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0281\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3882, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0114\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3883, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0114\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3884, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0200\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3885, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0348\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3886, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0388\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3887, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0331\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3888, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0169\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3889, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3890, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0039\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3891, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3892, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0069\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3893, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3894, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0042\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3895, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3896, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3897, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3898, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0037\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3899, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3900, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3901, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3902, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3903, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3904, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3905, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3906, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3907, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3908, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3909, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3910, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3911, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3912, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3913, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3914, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3915, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3916, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3917, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3918, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3919, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3920, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3921, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3922, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3923, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3924, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3925, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3926, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3927, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3928, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3929, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0001\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3930, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0001\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3931, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0001\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3932, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0001\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3933, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0001\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3934, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0001\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3935, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0001\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3936, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0001\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3937, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3938, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3939, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3940, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0001\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3941, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0001\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3942, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0001\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3943, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0001\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3944, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3945, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3946, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3947, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3948, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3949, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3950, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3951, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3952, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3953, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3954, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3955, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3956, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3957, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3958, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3959, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3960, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3961, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0002\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3962, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3963, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3964, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3965, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3966, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3967, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3968, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3969, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3970, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3971, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3972, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3973, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3974, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3975, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3976, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3977, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3978, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3979, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3980, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3981, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3982, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3983, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3984, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3985, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3986, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3987, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3988, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3989, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3990, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3991, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3992, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3993, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3994, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3995, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3996, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3997, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3998, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 3999, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4000, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4001, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4002, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4003, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4004, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4005, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4006, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4007, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4008, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4009, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4010, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4011, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4012, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4013, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4014, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4015, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4016, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4017, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4018, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4019, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4020, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4021, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4022, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4023, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4024, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4025, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0037\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4026, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0047\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4027, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4028, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0040\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4029, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4030, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4031, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4032, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4033, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0100\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4034, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0116\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4035, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0116\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4036, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0106\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4037, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0111\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4038, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0153\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4039, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0220\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4040, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0324\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4041, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0409\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4042, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0442\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4043, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0506\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4044, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0634\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4045, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.1380\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4046, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.2392\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4047, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.3934\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4048, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.3669\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4049, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.1789\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4050, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.1188\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4051, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.1085\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4052, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1391\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4053, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1564\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4054, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1928\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4055, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.1277\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4056, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0588\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4057, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0381\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4058, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0393\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4059, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0342\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4060, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0188\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4061, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4062, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0090\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4063, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0139\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4064, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0231\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4065, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0212\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4066, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0194\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4067, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0113\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4068, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0086\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4069, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4070, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4071, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4072, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4073, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0048\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4074, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4075, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4076, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4077, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0057\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4078, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4079, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4080, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4081, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4082, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4083, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4084, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4085, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4086, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4087, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4088, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4089, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4090, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4091, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4092, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4093, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4094, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4095, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4096, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4097, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4098, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4099, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4100, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4101, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4102, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4103, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4104, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4105, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4106, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4107, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4108, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4109, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4110, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4111, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0058\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4112, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4113, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4114, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4115, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4116, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4117, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4118, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4119, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4120, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4121, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4122, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4123, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0039\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4124, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4125, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4126, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4127, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4128, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4129, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0073\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4130, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0096\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4131, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0081\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4132, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4133, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4134, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4135, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4136, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4137, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4138, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4139, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4140, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4141, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4142, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0050\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4143, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4144, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4145, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0040\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4146, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4147, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4148, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4149, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4150, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4151, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4152, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4153, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4154, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4155, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4156, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4157, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4158, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4159, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4160, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4161, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4162, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4163, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4164, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4165, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0003\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4166, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4167, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4168, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4169, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4170, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4171, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4172, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4173, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4174, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4175, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0004\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4176, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4177, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4178, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4179, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4180, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4181, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4182, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4183, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4184, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4185, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4186, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4187, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4188, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4189, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4190, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4191, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4192, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4193, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0037\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4194, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0050\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4195, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0048\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4196, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4197, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4198, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4199, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4200, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0048\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4201, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4202, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4203, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4204, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0072\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4205, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0076\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4206, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0084\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4207, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0083\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4208, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0102\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4209, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0119\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4210, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0124\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4211, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0085\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4212, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4213, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0117\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4214, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0160\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4215, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0159\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4216, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0110\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4217, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4218, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4219, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4220, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0091\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4221, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0123\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4222, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0175\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4223, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0176\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4224, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0170\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4225, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0122\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4226, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0093\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4227, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4228, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0047\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4229, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4230, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4231, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0068\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4232, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0088\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4233, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0108\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4234, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0135\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4235, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0168\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4236, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0186\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4237, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0205\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4238, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0196\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4239, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0162\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4240, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0120\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4241, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0076\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4242, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0064\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4243, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0081\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4244, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0152\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4245, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0208\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4246, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0321\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4247, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0342\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4248, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0298\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4249, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0185\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4250, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0126\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4251, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0149\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4252, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0178\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4253, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0215\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4254, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0210\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4255, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0189\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4256, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0147\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4257, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0117\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4258, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0095\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4259, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0073\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4260, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0067\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4261, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0062\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4262, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4263, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4264, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0050\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4265, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0043\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4266, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4267, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4268, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4269, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4270, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4271, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4272, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4273, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4274, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4275, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4276, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4277, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4278, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4279, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4280, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4281, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4282, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4283, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4284, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4285, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4286, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4287, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4288, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4289, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4290, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4291, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4292, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4293, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4294, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4295, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4296, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4297, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0037\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4298, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4299, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4300, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0079\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4301, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0119\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4302, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0099\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4303, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4304, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4305, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0088\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4306, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0132\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4307, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0125\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4308, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0092\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4309, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0108\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4310, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0182\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4311, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0235\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4312, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0229\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4313, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0178\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4314, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0146\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4315, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0153\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4316, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0207\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4317, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0270\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4318, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0309\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4319, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0268\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4320, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0256\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4321, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0280\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4322, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0311\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4323, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0283\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4324, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0222\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4325, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0212\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4326, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0225\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4327, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0193\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4328, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0168\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4329, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0128\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4330, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0141\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4331, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0114\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4332, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0096\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4333, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4334, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0042\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4335, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4336, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4337, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4338, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4339, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4340, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4341, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0082\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4342, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0125\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4343, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0138\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4344, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0153\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4345, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0119\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4346, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0095\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4347, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4348, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4349, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4350, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4351, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4352, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0050\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4353, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0054\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4354, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4355, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4356, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0073\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4357, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0073\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4358, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0093\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4359, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0113\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4360, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0153\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4361, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0190\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4362, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0262\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4363, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0338\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4364, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0461\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4365, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0615\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4366, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0998\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4367, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.1443\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4368, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.2084\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4369, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.1939\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4370, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1215\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4371, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0699\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4372, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0531\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4373, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0377\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4374, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0246\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4375, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0142\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4376, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0078\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4377, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0186\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4378, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0366\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4379, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0431\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4380, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0209\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4381, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0185\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4382, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0643\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4383, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.1025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4384, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0895\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4385, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0376\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4386, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0321\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4387, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.1080\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4388, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.1281\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4389, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.1084\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4390, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0561\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4391, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0304\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4392, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0281\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4393, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0266\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4394, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0191\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4395, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0099\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4396, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4397, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0131\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4398, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0202\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4399, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0270\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4400, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0222\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4401, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0135\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4402, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4403, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4404, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4405, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4406, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4407, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4408, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4409, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4410, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4411, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4412, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4413, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4414, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4415, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4416, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4417, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4418, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4419, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4420, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4421, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4422, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4423, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4424, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4425, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4426, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4427, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4428, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4429, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4430, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4431, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4432, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4433, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4434, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4435, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4436, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4437, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4438, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4439, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4440, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4441, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4442, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4443, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4444, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4445, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4446, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4447, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4448, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4449, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4450, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4451, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4452, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4453, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4454, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4455, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4456, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4457, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4458, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0037\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4459, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0043\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4460, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0042\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4461, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0039\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4462, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4463, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4464, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4465, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4466, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4467, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4468, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4469, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4470, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4471, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4472, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4473, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4474, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4475, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4476, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4477, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4478, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4479, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4480, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4481, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4482, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4483, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4484, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4485, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4486, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4487, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4488, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4489, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4490, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4491, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4492, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4493, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4494, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4495, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4496, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4497, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4498, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4499, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4500, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4501, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4502, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4503, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4504, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4505, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4506, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4507, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4508, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4509, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4510, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4511, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4512, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4513, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4514, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4515, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4516, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4517, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4518, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4519, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4520, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4521, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4522, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4523, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4524, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4525, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4526, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4527, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4528, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4529, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4530, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4531, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4532, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4533, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0071\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4534, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4535, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4536, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4537, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4538, Batch 1, Gen Loss: 0.0018, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4539, Batch 1, Gen Loss: 0.0019, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4540, Batch 1, Gen Loss: 0.0020, Disc Loss: 0.0057\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4541, Batch 1, Gen Loss: 0.0019, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4542, Batch 1, Gen Loss: 0.0018, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4543, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0097\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4544, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0145\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4545, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0137\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4546, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0103\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4547, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0088\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4548, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0122\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4549, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0155\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4550, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0182\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4551, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0169\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4552, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0139\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4553, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0099\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4554, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0067\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4555, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4556, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4557, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0037\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4558, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4559, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4560, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4561, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4562, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4563, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4564, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0042\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4565, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4566, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4567, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0047\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4568, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4569, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4570, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4571, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4572, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4573, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4574, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4575, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4576, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4577, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0050\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4578, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4579, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4580, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4581, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4582, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4583, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0078\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4584, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4585, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4586, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0039\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4587, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0115\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4588, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0147\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4589, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0107\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4590, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0045\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4591, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4592, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0139\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4593, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0237\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4594, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0165\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4595, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0064\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4596, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0109\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4597, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0281\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4598, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0497\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4599, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0553\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4600, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0407\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4601, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0246\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4602, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0304\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4603, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0694\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4604, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4605, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1351\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4606, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1516\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4607, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1402\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4608, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.1129\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4609, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0816\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4610, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0473\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4611, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0239\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4612, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0271\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4613, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0292\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4614, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0237\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4615, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0150\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4616, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0097\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4617, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0125\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4618, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0155\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4619, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0217\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4620, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0205\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4621, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0187\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4622, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0137\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4623, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0105\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4624, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0065\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4625, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4626, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4627, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4628, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4629, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4630, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4631, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4632, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4633, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4634, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4635, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4636, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4637, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4638, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4639, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4640, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4641, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4642, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4643, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4644, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4645, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4646, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4647, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4648, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4649, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4650, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4651, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4652, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4653, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4654, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4655, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4656, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4657, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4658, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4659, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4660, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4661, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4662, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4663, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4664, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4665, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4666, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4667, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4668, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4669, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0047\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4670, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4671, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0042\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4672, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4673, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0016\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4674, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4675, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4676, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4677, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4678, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4679, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4680, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4681, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4682, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4683, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0019\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4684, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4685, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4686, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4687, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4688, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4689, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4690, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4691, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4692, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4693, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4694, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4695, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4696, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4697, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0047\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4698, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4699, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4700, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4701, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0072\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4702, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0085\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4703, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0069\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4704, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4705, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0039\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4706, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4707, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4708, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0042\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4709, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4710, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4711, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0072\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4712, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0098\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4713, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0114\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4714, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0161\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4715, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0189\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4716, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0211\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4717, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0185\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4718, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0140\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4719, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0099\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4720, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0096\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4721, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0107\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4722, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0122\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4723, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0112\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4724, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0118\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4725, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0155\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4726, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0268\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4727, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0374\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4728, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0477\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4729, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0491\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4730, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0484\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4731, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0355\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4732, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0302\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4733, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0276\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4734, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0319\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4735, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0296\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4736, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0274\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4737, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0236\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4738, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0207\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4739, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0149\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4740, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0089\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4741, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0065\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4742, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4743, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0069\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4744, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4745, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0062\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4746, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0048\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4747, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4748, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4749, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4750, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4751, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4752, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4753, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4754, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4755, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4756, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4757, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4758, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4759, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4760, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0017\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4761, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4762, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0087\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4763, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0114\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4764, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0088\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4765, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0042\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4766, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0072\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4767, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0196\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4768, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0296\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4769, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0240\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4770, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0109\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4771, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0040\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4772, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0094\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4773, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0165\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4774, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0165\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4775, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0101\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4776, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4777, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4778, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0065\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4779, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0066\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4780, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4781, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4782, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4783, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0044\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4784, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0091\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4785, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0117\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4786, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0144\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4787, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0125\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4788, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0093\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4789, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4790, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4791, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4792, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4793, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0022\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4794, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4795, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4796, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0030\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4797, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4798, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0023\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4799, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4800, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4801, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4802, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4803, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4804, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4805, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4806, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4807, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4808, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4809, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4810, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4811, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4812, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4813, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4814, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4815, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4816, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0006\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4817, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0008\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4818, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0009\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4819, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4820, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0005\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4821, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0007\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4822, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0011\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4823, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0015\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4824, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4825, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0010\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4826, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0012\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4827, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4828, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4829, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4830, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0014\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4831, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4832, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0027\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4833, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0039\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4834, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4835, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0018\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4836, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0026\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4837, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0053\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4838, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0073\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4839, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0058\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4840, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0028\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4841, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4842, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0037\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4843, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4844, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4845, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0038\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4846, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4847, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0040\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4848, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4849, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4850, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0059\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4851, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0052\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4852, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4853, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4854, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0025\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4855, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0021\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4856, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4857, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0031\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4858, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0039\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4859, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0041\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4860, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0035\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4861, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4862, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0033\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4863, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0034\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4864, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0036\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4865, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0046\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4866, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0063\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4867, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0078\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4868, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0070\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4869, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0056\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4870, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0058\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4871, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0080\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4872, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0120\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4873, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0166\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4874, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0191\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4875, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0173\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4876, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0119\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4877, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0071\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4878, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0055\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4879, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0086\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4880, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0122\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4881, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0147\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4882, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0141\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4883, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0116\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4884, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0090\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4885, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0071\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4886, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0061\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4887, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4888, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0039\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4889, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4890, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0020\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4891, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0029\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4892, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4893, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0112\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4894, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0176\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4895, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0272\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4896, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0325\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4897, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0376\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4898, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0356\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4899, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0292\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4900, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0241\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4901, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0226\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4902, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0225\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4903, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0218\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4904, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0291\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4905, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0315\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4906, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0270\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4907, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0184\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4908, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0137\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4909, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0168\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4910, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0219\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4911, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0282\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4912, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0297\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4913, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0288\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4914, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0221\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4915, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0138\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4916, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0105\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4917, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0133\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4918, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0235\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4919, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0254\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4920, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0202\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4921, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0116\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4922, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0085\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4923, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0153\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4924, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0220\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4925, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0235\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4926, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0186\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4927, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0123\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4928, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0072\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4929, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0064\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4930, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0123\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4931, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0181\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4932, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0231\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4933, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0176\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4934, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0109\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4935, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0165\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4936, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0262\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4937, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0335\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4938, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0291\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4939, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0251\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4940, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0204\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4941, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0166\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4942, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0193\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4943, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0294\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4944, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0417\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4945, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0427\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4946, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0314\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4947, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0147\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4948, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0060\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4949, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0092\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4950, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0136\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4951, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0139\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4952, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0076\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4953, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0051\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4954, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0151\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4955, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0341\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4956, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0511\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4957, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0521\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4958, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0530\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4959, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0487\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4960, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0389\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4961, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0256\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4962, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0198\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4963, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0199\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4964, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0201\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4965, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0181\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4966, Batch 1, Gen Loss: 0.0007, Disc Loss: 0.0203\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4967, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0205\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4968, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0148\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4969, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.0067\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4970, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0069\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4971, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.0101\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4972, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0110\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4973, Batch 1, Gen Loss: 0.0011, Disc Loss: 0.0160\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4974, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.0315\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4975, Batch 1, Gen Loss: 0.0013, Disc Loss: 0.0462\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4976, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.0460\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4977, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.0332\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4978, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0450\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4979, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0703\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4980, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0574\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4981, Batch 1, Gen Loss: 0.0016, Disc Loss: 0.0585\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4982, Batch 1, Gen Loss: 0.0015, Disc Loss: 0.1558\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4983, Batch 1, Gen Loss: 0.0014, Disc Loss: 0.2013\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4984, Batch 1, Gen Loss: 0.0012, Disc Loss: 0.1327\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4985, Batch 1, Gen Loss: 0.0010, Disc Loss: 0.0911\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4986, Batch 1, Gen Loss: 0.0009, Disc Loss: 0.1284\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4987, Batch 1, Gen Loss: 0.0008, Disc Loss: 0.1447\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4988, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0877\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4989, Batch 1, Gen Loss: 0.0006, Disc Loss: 0.0464\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4990, Batch 1, Gen Loss: 0.0005, Disc Loss: 0.0405\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4991, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0262\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4992, Batch 1, Gen Loss: 0.0004, Disc Loss: 0.0167\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4993, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0098\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4994, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0103\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4995, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0081\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4996, Batch 1, Gen Loss: 0.0003, Disc Loss: 0.0073\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4997, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0058\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4998, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0049\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 4999, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0032\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n",
            "Epoch 5000, Batch 1, Gen Loss: 0.0002, Disc Loss: 0.0024\n",
            "Generator loss threshold (0.005) reached. Stopping training.\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, LeakyReLU, Input, Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "import cv2\n",
        "\n",
        "# Function to perform Gaussian blurring\n",
        "def gaussian_blur(image, sigma=1):\n",
        "    return cv2.GaussianBlur(image, (0, 0), sigma)\n",
        "\n",
        "# Load the clean MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Select a random image from the dataset\n",
        "index = np.random.randint(0, x_train.shape[0])\n",
        "\n",
        "# Clean image\n",
        "clean_image = x_train[index] / 255.0\n",
        "\n",
        "# Blurred image with Gaussian blur\n",
        "blurred_image = gaussian_blur(clean_image)\n",
        "\n",
        "# Define the Deblur GAN, Generator, and Discriminator\n",
        "\n",
        "# Generator model for deblurring\n",
        "def build_deblur_generator(input_shape=(28, 28, 1)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Deblurring layers (replace with your desired architecture)\n",
        "    x = Conv2D(64, (3, 3), activation=\"relu\", padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Conv2D(64, (3, 3), activation=\"relu\", padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "\n",
        "    # Upsample with transposed convolutional blocks\n",
        "    x = Conv2DTranspose(64, 4, strides=1, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    # Output convolution\n",
        "    outputs = Conv2D(1, 3, activation='linear', padding='same')(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Create a PatchGAN Discriminator for deblurred images (you can customize this)\n",
        "def build_deblur_discriminator(input_shape=(28, 28, 1)):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    x = Conv2D(64, (4, 4), strides=2, padding='same')(inputs)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(128, (4, 4), strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(256, (4, 4), strides=2, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = LeakyReLU(alpha=0.2)(x)\n",
        "\n",
        "    x = Conv2D(1, (4, 4), padding='same')(x)\n",
        "\n",
        "    return Model(inputs=inputs, outputs=x)\n",
        "\n",
        "# Train the Deblur GAN with early stopping based on generator loss\n",
        "def train_deblur_gan(generator, discriminator, blurred_data, clean_data, batch_size, max_epochs, generator_loss_threshold=0.0050):\n",
        "    # Define loss functions (you may need to adjust these)\n",
        "    loss_fn = tf.keras.losses.MeanSquaredError()\n",
        "\n",
        "    generator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "    discriminator_optimizer = tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\n",
        "    epoch = 0  # Initialize the epoch counter\n",
        "\n",
        "    while epoch < max_epochs:  # Continue until the maximum number of epochs is reached\n",
        "        for i in range(0, len(blurred_data), batch_size):\n",
        "            batch_blurred = blurred_data[i:i + batch_size]\n",
        "            batch_clean = clean_data[i:i + batch_size]\n",
        "\n",
        "            with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "                # Generate deblurred images\n",
        "                generated_images = generator(batch_blurred, training=True)\n",
        "\n",
        "                # Discriminator loss (adversarial)\n",
        "                real_output = discriminator(batch_clean, training=True)\n",
        "                fake_output = discriminator(generated_images, training=True)\n",
        "                disc_loss = loss_fn(real_output, tf.ones_like(real_output)) + loss_fn(fake_output, tf.zeros_like(fake_output))\n",
        "\n",
        "                # Generator loss\n",
        "                gen_loss = loss_fn(batch_clean, generated_images)\n",
        "\n",
        "            gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "            gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "            generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "            discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "            print(f\"Epoch {epoch + 1}, Batch {i//batch_size + 1}, Gen Loss: {gen_loss:.4f}, Disc Loss: {disc_loss:.4f}\")\n",
        "\n",
        "            if gen_loss < generator_loss_threshold:\n",
        "                print(f\"Generator loss threshold ({generator_loss_threshold}) reached. Stopping training.\")\n",
        "                break  # Exit the training loop\n",
        "\n",
        "        epoch += 1  # Move to the next epoch\n",
        "\n",
        "    # Generate and display a noisy image alongside its denoised counterpart\n",
        "    sample_blurred = blurred_data[0:1]\n",
        "    sample_deblurred = generator(sample_blurred, training=False)\n",
        "\n",
        "    plt.figure(figsize=(8, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.title(\"Noisy Image\")\n",
        "    plt.imshow(sample_blurred[0].reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.title(\"Deblurred Image\")\n",
        "    plt.imshow(sample_deblurred[0].numpy().reshape(28, 28), cmap='gray')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Set hyperparameters\n",
        "batch_size = 32\n",
        "max_epochs_deblur_gan = 5000  # Maximum number of epochs\n",
        "generator_loss_threshold = 0.0050  # Generator loss threshold\n",
        "\n",
        "# Prepare data\n",
        "num_samples = x_train.shape[0]\n",
        "blurred_data = np.array([gaussian_blur(image / 255.0) for image in x_train])\n",
        "blurred_data = np.expand_dims(blurred_data, axis=-1)\n",
        "clean_data = np.expand_dims(x_train / 255.0, axis=-1)\n",
        "\n",
        "# Create and train the Deblur GAN with early stopping\n",
        "deblur_generator = build_deblur_generator()\n",
        "deblur_discriminator = build_deblur_discriminator()\n",
        "\n",
        "# Train the Deblur GAN\n",
        "train_deblur_gan(deblur_generator, deblur_discriminator, blurred_data, clean_data, batch_size, max_epochs_deblur_gan, generator_loss_threshold)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I86w83CWccLj",
        "outputId": "709c29d1-da5c-4e17-961d-e9201ffcbf99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-addons\n",
            "  Downloading tensorflow_addons-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (611 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m611.8/611.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow-addons) (24.0)\n",
            "Collecting typeguard<3.0.0,>=2.7 (from tensorflow-addons)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: typeguard, tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.23.0 typeguard-2.13.3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "PkLDlbvNYPNm",
        "outputId": "05994176-dfe8-4ab0-8350-a5a948cd17d8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "OpenCV(4.8.0) /io/opencv/modules/imgproc/src/smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'GaussianBlur'\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7d3f8f83c293>\u001b[0m in \u001b[0;36m<cell line: 34>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-7d3f8f83c293>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Apply blur to the original image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mblurred_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Apply deblurring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.8.0) /io/opencv/modules/imgproc/src/smooth.dispatch.cpp:617: error: (-215:Assertion failed) !_src.empty() in function 'GaussianBlur'\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from skimage.metrics import peak_signal_noise_ratio, structural_similarity\n",
        "\n",
        "def main():\n",
        "    # Load the original image\n",
        "    original_image = cv2.imread('original_image.jpg')\n",
        "\n",
        "    # Apply blur to the original image\n",
        "    blurred_image = cv2.GaussianBlur(original_image, (5, 5), 0)\n",
        "\n",
        "    # Apply deblurring\n",
        "    deblurred_photo = sample_deblurred[0].numpy().reshape(28, 28)\n",
        "\n",
        "    # Print the original, blurred, and deblurred images\n",
        "    cv2.imshow('Original Image', original_image)\n",
        "    cv2.imshow('Blurred Image', blurred_image)\n",
        "    cv2.imshow('Deblurred Image', deblurred_image)\n",
        "    cv2.waitKey(0)\n",
        "    cv2.destroyAllWindows()\n",
        "\n",
        "    # Calculate PSNR and SSIM\n",
        "    psnr_blurred = peak_signal_noise_ratio(original_image, blurred_image)\n",
        "    ssim_blurred = structural_similarity(original_image, blurred_image, multichannel=True)\n",
        "    psnr_deblurred = peak_signal_noise_ratio(original_image, deblurred_image)\n",
        "    ssim_deblurred = structural_similarity(original_image, deblurred_image, multichannel=True)\n",
        "\n",
        "    # Print PSNR and SSIM values\n",
        "    print(\"PSNR (Original vs. Blurred):\", psnr_blurred)\n",
        "    print(\"SSIM (Original vs. Blurred):\", ssim_blurred)\n",
        "    print(\"PSNR (Original vs. Deblurred):\", psnr_deblurred)\n",
        "    print(\"SSIM (Original vs. Deblurred):\", ssim_deblurred)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JK0xyvmncQOc",
        "outputId": "30192d39-d6d5-41e6-cc28-a19f9149c76a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.11.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (2023.9.26)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (1.4.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image) (23.2)\n"
          ]
        }
      ],
      "source": [
        "pip install scikit-image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "id": "TJdNmkEjd15x",
        "outputId": "27cce0eb-a19f-44a2-813d-f032cbcdfc77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original vs Blurred PSNR: 18.63\n",
            "Original vs Blurred SSIM: 0.8760\n",
            "Original vs Deblurred PSNR: 30.83\n",
            "Original vs Deblurred SSIM: 0.9888\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-21-1901c6e985f5>:6: UserWarning: Inputs have mismatched dtype.  Setting data_range based on image_true.\n",
            "  psnr_value = psnr(original, distorted)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7YAAAE7CAYAAADpSx23AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA4IUlEQVR4nO3deXQUZbrH8afTnT0kITv7LhDIKISrIggJyDAqCoygoCAgyOIAckUZYUQcmQOo4wwCguACCOiMKCpeREXZXcYNxAuCwAQUhiUbAbJ3d90/POlLCFhPSIfwwvdzjudI5Zen3qqueruernS3w7IsSwAAAAAAMFRATQ8AAAAAAICqoLEFAAAAABiNxhYAAAAAYDQaWwAAAACA0WhsAQAAAABGo7EFAAAAABiNxhYAAAAAYDQaWwAAAACA0WhsAQAAAABGo7E1yBNPPCEOh+OCfnfJkiXicDjkwIED/h3UGQ4cOCAOh0OWLFlSbesAcGVzOBzyxBNP1PQw1IYOHSqNGzeu6WEAuAKUXet9/fXXttm0tDRJS0ur/kH5ycW4joX5aGwvgp07d8qgQYOkXr16EhwcLHXr1pV77rlHdu7cWdNDqxEbN24Uh8Mhb775Zk0PBUANK7tYOfO/hIQESU9Pl7Vr19b08C6atLQ0adu2bU0PA0A1O3vOCwkJkbp160rPnj1lzpw5curUqZoeotHKbgJlZWXV9FBQA2hsq9mqVaukffv28sknn8iwYcNk/vz5Mnz4cNmwYYO0b99e3n77bXWtxx57TAoLCy9oHIMHD5bCwkJp1KjRBf0+AFSnJ598UpYtWyavvvqqTJo0STIzM+WWW26R//mf/6npoQGA35XNeQsWLJBx48aJiMiECRMkJSVFduzYUcOjA8zkqukBXM72798vgwcPlqZNm8rmzZslPj7e97MHH3xQbrzxRhk8eLDs2LFDmjZtet46+fn5Eh4eLi6XS1yuC3vInE6nOJ3OC/pdAKhuN998s3To0MH37+HDh0tiYqK8/vrr0qtXr2pZp9frlZKSEgkJCanws7J5FwCqw9lz3uTJk2X9+vXSq1cvuf322+WHH36Q0NDQGhxh5RQUFEhYWFiF5W63W7xerwQFBdXAqHCl4Y5tNXrmmWekoKBAFi1aVK6pFRGJi4uThQsXSn5+vjz99NO+5WV/QrFr1y65++67pXbt2tK5c+dyPztTYWGhjB8/XuLi4qRWrVpy++23y+HDhyu8D+1c701o3Lix9OrVS7Zu3SrXXnuthISESNOmTeXVV18tt46cnBx5+OGHJSUlRSIiIiQyMlJuvvlm+e677/y0p/5/23788UcZNGiQREVFSXx8vEydOlUsy5Kff/5ZevfuLZGRkZKUlCTPPvtsud8vKSmRxx9/XFJTUyUqKkrCw8PlxhtvlA0bNlRYV3Z2tgwePFgiIyMlOjpahgwZIt9999053x+8e/du6devn8TExEhISIh06NBBVq9e7bftBnBu0dHREhoaavti3vnew3qu+dLhcMjYsWNlxYoV0qZNGwkODpYPPvjANz9u2rRJHnjgAUlISJD69ev7fm/t2rVy4403Snh4uNSqVUtuvfXWc76V5J133pG2bdtKSEiItG3btlJ/kXMuZeNduXKlJCcnS2hoqHTs2FG+//57ERFZuHChNG/eXEJCQiQtLa3Ce8+2bNki/fv3l4YNG0pwcLA0aNBA/vu///ucf/lTto4zx36ufev1emX27NnSpk0bCQkJkcTERBk1apTk5uZWaVsBiHTr1k2mTp0qBw8elOXLl5f7WWWuRwoKCmTUqFESGxsrkZGRcu+999qeo+d7D2vZ28c2btzoW1b21olvvvlGunTpImFhYTJlyhTfZ6389a9/ldmzZ0uzZs0kODhYdu3aValt2Llzp3Tr1k1CQ0Olfv368pe//EW8Xq9iD55b2Xh37NghXbt2lbCwMGnevLnvLXGbNm2S6667TkJDQ6Vly5by8ccfl/v9gwcPygMPPCAtW7aU0NBQiY2Nlf79+5/z/b5l6zhz7IsXLz7nvtU+t0CPO7bV6L333pPGjRvLjTfeeM6fd+nSRRo3bixr1qyp8LP+/ftLixYtZMaMGWJZ1nnXMXToUHnjjTdk8ODBcv3118umTZvk1ltvVY9x37590q9fPxk+fLgMGTJEXnnlFRk6dKikpqZKmzZtRETk3//+t7zzzjvSv39/adKkiRw7dkwWLlwoXbt2lV27dkndunXV67Nz1113SevWrWXWrFmyZs0a+ctf/iIxMTGycOFC6datmzz11FOyYsUKefjhh+W//uu/pEuXLiIicvLkSXnppZdk4MCBcv/998upU6fk5Zdflp49e8qXX34p11xzjYj8clF22223yZdffiljxoyRVq1aybvvvitDhgypMJadO3dKp06dpF69evLoo49KeHi4vPHGG9KnTx956623pG/fvn7bbuBKl5eXJ1lZWWJZlhw/flzmzp0rp0+flkGDBvl1PevXr5c33nhDxo4dK3FxcdK4cWPZvn27iIg88MADEh8fL48//rjk5+eLiMiyZctkyJAh0rNnT3nqqaekoKBAFixYIJ07d5Zt27b5Gr+PPvpI7rjjDklOTpaZM2dKdna2DBs2rFyDfCG2bNkiq1evlj/84Q8iIjJz5kzp1auXTJo0SebPny8PPPCA5ObmytNPPy333XefrF+/3ve7K1eulIKCAhkzZozExsbKl19+KXPnzpVDhw7JypUrfbk1a9bIXXfdJSkpKTJz5kzJzc2V4cOHS7169SqMZ9SoUbJkyRIZNmyYjB8/XjIyMmTevHmybds2+fTTTyUwMLBK2wtc6QYPHixTpkyRjz76SO6//34Rqfz1yNixYyU6OlqeeOIJ2bNnjyxYsEAOHjzoa1L9ITs7W26++WYZMGCADBo0SBITE30/W7x4sRQVFcnIkSMlODhYYmJi1Ntw9OhRSU9PF7fb7cstWrSoynevc3NzpVevXjJgwADp37+/LFiwQAYMGCArVqyQCRMmyOjRo+Xuu++WZ555Rvr16yc///yz1KpVS0REvvrqK/nss89kwIABUr9+fTlw4IAsWLBA0tLSZNeuXb471YcPH5b09HRxOBwyefJkCQ8Pl5deekmCg4MrjEf73IJKslAtTpw4YYmI1bt371/N3X777ZaIWCdPnrQsy7KmTZtmiYg1cODACtmyn5X55ptvLBGxJkyYUC43dOhQS0SsadOm+ZYtXrzYEhErIyPDt6xRo0aWiFibN2/2LTt+/LgVHBxsTZw40besqKjI8ng85daRkZFhBQcHW08++WS5ZSJiLV68+Fe3ecOGDZaIWCtXrqywbSNHjvQtc7vdVv369S2Hw2HNmjXLtzw3N9cKDQ21hgwZUi5bXFxcbj25ublWYmKidd999/mWvfXWW5aIWLNnz/Yt83g8Vrdu3SqMvXv37lZKSopVVFTkW+b1eq0bbrjBatGixa9uIwCdsrnp7P+Cg4OtJUuWVMifPbcNGTLEatSoUYXc2fNl2e8GBARYO3fuPOcYOnfubLndbt/yU6dOWdHR0db9999fLn/06FErKiqq3PJrrrnGqlOnjnXixAnfso8++sgSkXOO72xdu3a12rRpU2G8wcHB5ebthQsXWiJiJSUl+Z43LMuyJk+eXGGOLygoqLCemTNnWg6Hwzp48KBvWUpKilW/fn3r1KlTvmUbN26sMPYtW7ZYImKtWLGiXM0PPvjgnMsBVFQ233z11VfnzURFRVnt2rXz/Vt7PVJWOzU11SopKfEtf/rppy0Rsd59913fsq5du1pdu3at8LtnziGW9f/XbBs2bCj3uyJivfDCC+WyZdeBkZGR1vHjx8v9TLsNEyZMsETE+te//uVbdvz4cSsqKuqc4ztb2dyfmZlZYbyvvfaab9nu3bt9zwlffPGFb/mHH35Y4XrwXHPp559/bomI9eqrr/qWjRs3znI4HNa2bdt8y7Kzs62YmJhyY6/Mcwsqhz9FriZln2pX9mrP+ZT9/OTJk+WWjx492nYdH3zwgYj8cpfhTGUfQqCRnJxc7o5yfHy8tGzZUv7973/7lgUHB0tAwC+HisfjkezsbImIiJCWLVvKt99+q16XxogRI3z/73Q6pUOHDmJZlgwfPty3PDo6usIYnU6n7/0bXq9XcnJyxO12S4cOHcqN8YMPPpDAwEDfq6AiIgEBAb67IWVycnJk/fr1cuedd8qpU6ckKytLsrKyJDs7W3r27Cl79+6Vw4cP+3XbgSvZ888/L+vWrZN169bJ8uXLJT09XUaMGCGrVq3y63q6du0qycnJ5/zZ/fffX+6zCNatWycnTpyQgQMH+uaArKwscTqdct111/ne6nDkyBHZvn27DBkyRKKiony/36NHj/OuS6t79+7lXrm/7rrrRETkjjvuKPf8Urb8zHnxzDsc+fn5kpWVJTfccINYliXbtm0TEZH//Oc/8v3338u9994rERERvnzXrl0lJSWl3FhWrlwpUVFR0qNHj3L7IzU1VSIiIs751g8AlRcREeG7jryQ65GRI0eW++uJMWPGiMvlkvfff99vYwwODpZhw4ad82d33HFHubfgVWYb3n//fbn++uvl2muv9f1+fHy83HPPPVUab0REhAwYMMD375YtW0p0dLS0bt3aN3+K2M+lpaWlkp2dLc2bN5fo6OgK15gdO3b0/ZWgiEhMTEyFsWufW1B5/ClyNSm74LD72PbzNcBNmjSxXcfBgwclICCgQrZ58+bqcTZs2LDCstq1a5d7L4bX65XnnntO5s+fLxkZGeLxeHw/i42NVa/rQsYTFRUlISEhEhcXV2F5dnZ2uWVLly6VZ599Vnbv3i2lpaW+5Wfun4MHD0qdOnUqfMDB2fts3759YlmWTJ06VaZOnXrOsR4/fvycf6oHoPKuvfbach+kMnDgQGnXrp2MHTtWevXq5bcPHvm1ufXsn+3du1dEfnnf27lERkaKyC/ziohIixYtKmSq+gLgueZEEZEGDRqcc/mZc/dPP/0kjz/+uKxevbrC++vy8vLKjf1czxvNmzcvN/a9e/dKXl6eJCQknHOsx48fV20TgF93+vRp33l2IdcjZ89FERERUqdOHb9+B2y9evXOOy+fPZdWZhsOHjxYrtEs07JlyyqNt379+hX+DDsqKko1lxYWFsrMmTNl8eLFcvjw4XJvESybS0V+mU87duxYYd1nz6/a5xZUHo1tNYmKipI6derYfmT7jh07pF69ehUO4ov1SXjn+6TkM0/aGTNmyNSpU+W+++6T6dOnS0xMjAQEBMiECROq9GZ+7Xg0Y1y+fLkMHTpU+vTpI4888ogkJCSI0+mUmTNnyv79+ys9jrLtevjhh6Vnz57nzFTmBQQAlRMQECDp6eny3HPPyd69e33v+T/b+d4vduYLcGf6tbn17J+VzQPLli2TpKSkCvkL/ZT6yjjf/Gc3L3o8HunRo4fk5OTIH//4R2nVqpWEh4fL4cOHZejQoRc0d3u9XklISJAVK1ac8+dnf0gigMo7dOiQ5OXl+a4xLtb1yMWYS2vymupC51KRX/4ScvHixTJhwgTp2LGjREVFicPhkAEDBlzwXCpSs88tlyv2XDXq1auXvPjii7J161bfJxufacuWLXLgwAEZNWrUBdVv1KiReL1eycjIKPfq3L59+y54zOfy5ptvSnp6urz88svllp84caLCndSa8uabb0rTpk1l1apV5SbnadOmlcs1atRINmzYUOFj6c/eZ2VfvxQYGCg33XRTNY4cwPm43W4R+eXuxfnUrl1bTpw4UWF52Z3IqmjWrJmIiCQkJPzqPFD2/eBlr8Kfac+ePVUex4X4/vvv5ccff5SlS5fKvffe61u+bt26crmysZ/reePsZc2aNZOPP/5YOnXqZNTXkAAmWbZsmYiIrwG8kOuRvXv3Snp6uu/fp0+fliNHjsgtt9xy3t+pXbu2iEiF+dQfc2lltqFRo0aX1Fwq8ss15pAhQ8p9I0dRUVGFfdWoUSP1XCpi/9yCyuM9ttXokUcekdDQUBk1alSFP5vNycmR0aNHS1hYmDzyyCMXVL9s0ps/f3655XPnzr2wAZ+H0+ms8MnMK1euvKTeY1r2ituZ4/zXv/4ln3/+eblcz549pbS0VF588UXfMq/XK88//3y5XEJCgqSlpcnChQvlyJEjFdaXmZnpz+EDOEtpaal89NFHEhQUJK1btz5vrlmzZpKXl1fur2OOHDlS5a/aEfllvoiMjJQZM2aUe3tDmbJ5oE6dOnLNNdfI0qVLy/1Z2rp163xfc3GxnWtOtCxLnnvuuXK5unXrStu2beXVV18t9wLCpk2bfF8rVObOO+8Uj8cj06dPr7A+t9t9zhcYAOitX79epk+fLk2aNPG9L/NCrkcWLVpUbs5asGCBuN1uufnmm8+77rJma/Pmzb5lHo9HFi1adMHbU6Yy23DLLbfIF198IV9++WW5n5/vL0UuhnNdB8+dO7fC3eyePXvK559/7vukfZFfrvfPHrv2uQWVxx3batSiRQtZunSp3HPPPZKSkiLDhw+XJk2ayIEDB+Tll1+WrKwsef31132TSWWlpqbKHXfcIbNnz5bs7Gzf1/38+OOPInL+PyuprF69esmTTz4pw4YNkxtuuEG+//57WbFihe8VuEtBr169ZNWqVdK3b1+59dZbJSMjQ1544QVJTk4ud7HWp08fufbaa2XixImyb98+adWqlaxevVpycnJEpPw+e/7556Vz586SkpIi999/vzRt2lSOHTsmn3/+uRw6dMiv3+MLXOnWrl0ru3fvFpFf3mv12muvyd69e+XRRx/91fcbDRgwQP74xz9K3759Zfz48b6vTLjqqquq/OF2kZGRsmDBAhk8eLC0b99eBgwYIPHx8fLTTz/JmjVrpFOnTjJv3jwR+eVreG699Vbp3Lmz3HfffZKTkyNz586VNm3a/Ood5+rSqlUradasmTz88MNy+PBhiYyMlLfeeuuc32U5Y8YM6d27t3Tq1EmGDRsmubm5Mm/ePGnbtm25sXft2lVGjRolM2fOlO3bt8tvf/tbCQwMlL1798rKlSvlueeek379+l3MzQSMVTbnud1uOXbsmKxfv17WrVsnjRo1ktWrV0tISIgvW9nrkZKSEunevbvceeedsmfPHpk/f7507txZbr/99vOOp02bNnL99dfL5MmTJScnR2JiYuQf//iH7y9nqkq7DZMmTZJly5bJ7373O3nwwQd9X/fTqFEj27f3VZdevXrJsmXLJCoqSpKTk+Xzzz+Xjz/+uMLnzEyaNEmWL18uPXr0kHHjxvm+7qdhw4aSk5Pju8aszHMLKofGtpr1799fWrVqJTNnzvQ1s7GxsZKeni5TpkyRtm3bVqn+q6++KklJSfL666/L22+/LTfddJP885//lJYtW5abFKtiypQpkp+fL6+99pr885//lPbt28uaNWvk0Ucf9Ut9fxg6dKgcPXpUFi5cKB9++KEkJyfL8uXLZeXKleW+VNzpdMqaNWvkwQcflKVLl0pAQID07dtXpk2bJp06dSq3z5KTk+Xrr7+WP//5z7JkyRLJzs6WhIQEadeunTz++OM1sJXA5evMcyokJERatWolCxYssH2rRmxsrLz99tvy0EMPyaRJk6RJkyYyc+ZM2bt3r18+tf3uu++WunXryqxZs+SZZ56R4uJiqVevntx4443lPhH0d7/7naxcuVIee+wxmTx5sjRr1kwWL14s7777brk56GIJDAyU9957T8aPHy8zZ86UkJAQ6du3r4wdO1auvvrqctnbbrtNXn/9dXniiSfk0UcflRYtWsiSJUtk6dKlsnPnznLZF154QVJTU2XhwoUyZcoUcblc0rhxYxk0aJB06tTpYm4iYLSyOS8oKEhiYmIkJSVFZs+eLcOGDavwgaKVvR6ZN2+erFixQh5//HEpLS2VgQMHypw5c2xveKxYsUJGjRols2bNkujoaBk+fLikp6dLjx49qry92m2oU6eObNiwQcaNGyezZs2S2NhYGT16tNStW7fcN2RcTM8995w4nU5ZsWKFFBUVSadOneTjjz+u8H7hBg0ayIYNG2T8+PEyY8YMiY+Plz/84Q8SHh4u48ePL3eNqX1uQeU4rLPvrcN427dvl3bt2sny5cur/PHoV4p33nlH+vbtK1u3buXiDABE5JprrpH4+PgK78sFAOhNmDBBFi5cKKdPnz7vh1XBP3iPreEKCwsrLJs9e7YEBARIly5damBEl76z95nH45G5c+dKZGSktG/fvoZGBQA1o7S0tMKfG27cuFG+++47SUtLq5lBAYCBzr7GzM7OlmXLlknnzp1pai8C/hTZcE8//bR88803kp6eLi6XS9auXStr166VkSNHVvhuLvxi3LhxUlhYKB07dpTi4mJZtWqVfPbZZzJjxgw+6RPAFefw4cNy0003yaBBg6Ru3bqye/dueeGFFyQpKUlGjx5d08MDAGN07NhR0tLSpHXr1nLs2DF5+eWX5eTJk+f9/l74F3+KbLh169bJn//8Z9m1a5ecPn1aGjZsKIMHD5Y//elPfA/Webz22mvy7LPPyr59+6SoqEiaN28uY8aMkbFjx9b00ADgosvLy5ORI0fKp59+KpmZmRIeHi7du3eXWbNmXfCHGwLAlWjKlCny5ptvyqFDh8ThcEj79u1l2rRpfK3PRUJjCwAAAAAwGu+xBQAAAAAYjcYWAAAAAGA09Zsw7b77CgDsXK7vfGB+BFBVl+v8GBcXd9HXqZ2TL9d9XhWafef1ei/6Ov1N+9j7+5OM/b3vrhRZWVmqHHdsAQAAAABGo7EFAAAAABiNxhYAAAAAYDQaWwAAAACA0WhsAQAAAABGo7EFAAAAABiNxhYAAAAAYDQaWwAAAACA0WhsAQAAAABGc9X0AAAAAAB/sSyrRtbrcDhsM9qxaWpVpp425/V6bTMBAbr7YtptcLvdqpx2GzTjCwoKUtXy99gCAwP9tk5UxB1bAAAAAIDRaGwBAAAAAEajsQUAAAAAGI3GFgAAAABgNBpbAAAAAIDRaGwBAAAAAEajsQUAAAAAGI3GFgAAAABgNBpbAAAAAIDRXDU9AAAATBUQoHt92OXSPd1qc5Zl2WbcbreqljanWSdwNu1x43A4qnkk1c+f54i2lr/3r9PptM1o5wxNLRGRwMBAVU67rUFBQbaZ4uJiVS3tfvN4PH7Lafeb9nHQboM2VxPHuRZ3bAEAAAAARqOxBQAAAAAYjcYWAAAAAGA0GlsAAAAAgNFobAEAAAAARqOxBQAAAAAYjcYWAAAAAGA0GlsAAAAAgNF03wQPAMAVxOl0qnLh4eGqXEJCgioXGxurynk8HttMVlaWqlZOTo4qV1hYqMq53W7bjGVZqlown8Ph8Gs9fx472rFp1+nvba2JdZaWlvptnV6vV5UrLi5W5bTrPXnypG0mMDBQVUubCwjQ3SvU7F8t7f4ICgpS5TRzd2XWWxO4YwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMJqrpgeAy8ddd92lyj322GOqXHh4uG3mt7/9rarWvn37VDkAlz+n02mb0cw/IiJNmjRR5a677jpVrnXr1qqcx+OxzezZs0dV64cfflDlDh06pMrl5OTYZgoLC1W13G63KmdZlioH8zkcjitinVo1cexr1+n1elW5Hj16qHITJ05U5TTzxrhx41S1MjIyVLnQ0FBVTrPvSktLVbWCgoJUOe3joKXZBu054+9zizu2AAAAAACj0dgCAAAAAIxGYwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMBqNLQAAAADAaDS2AAAAAACjOSzLslRBh6O6x4JLVEJCgip35MgRVU55yKlkZGSocp999pkq9/TTT6tyO3fuVOVQnj8f+0sJ8+OlweVyqXK1atWyzTRq1EhVq2PHjqpcz549Vbk2bdqocppzSTs/7tq1S5X73//9X1Vu9+7dthnt2HJyclS54uJiVe5SnoMu5bFVRVxcXE0PwUj+Ph48Ho8qFxBgf8/L7XararVo0UKVe+2111S56OhoVS4zM9MvGRGRL774QpV74403VLmff/7ZNuP1elW1SktLVbmgoCBVTvscqhmf9vjV5rKzs1U57tgCAAAAAIxGYwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIzmsCzLUgUdjuoeCy6yESNGqHITJ05U5a666ipVTnnI1YjS0lJV7s0337TNTJgwQVUrOztblbscXMqPfVUwP1avwMBAVS4qKkqV08xVHTt2VNXq2rWrKpeamqrKJSUlqXKaY+7UqVOqWsePH1flMjIyVLlt27bZZrZu3aqqtX37dlXu2LFjqlxJSYkqVxMu1/kxLi6upodwSdE+zjV1PLjdbttM3759VbXuueceVa5x48aqXGhoqCqnuZYLCwtT1QoKClLlcnJyVLn33nvPNrNo0SJVLe3crT2W/Hkto62lHZv2Wpk7tgAAAAAAo9HYAgAAAACMRmMLAAAAADAajS0AAAAAwGg0tgAAAAAAo9HYAgAAAACMRmMLAAAAADAajS0AAAAAwGiumh4AqseIESNsM3//+99VtbRfiH050H4R98CBA20zderUUdXq37+/Kpebm6vKAaYIDAxU5WJiYlS5Vq1aqXJdunSxzXTt2lVVKzk5WZXTboP2S+01uYiICFUt7eMQHR2tymm21el0qmrl5eWpcidPnlTlSktLVTnLslQ5oLK8Xq8qpz0GtbmAAN29rDvuuMM289hjj6lqabdVe52pndM010vaOSMqKkqV086jmmu+tm3bqmqNHDlSldPOo1qaY0l7XGqf87S4YwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMJqrpgeAX4SHh6tyU6dOVeXGjx9vmwkKClLVwoVJS0tT5erVq6fK5ebmVmE0wMXjcumeWqKjo1W55ORkVa5bt26qXNeuXW0zLVu2VNUKDAxU5Y4eParKFRYWqnJOp9M2Y1mWqlZJSYkqp32eSkxMtM1o9692fty7d68qd/r0aVXO4/Gocrg0ORwOVU57jmj587jRji0kJESVGzVqlCo3aNAg24x2ztDMBSIiBQUFqpz2OkizT5o0aaKqpZ1bIiIiVLmAAPt7ivHx8apaCQkJqlxRUZEqp33+0Rzn2usAf+OOLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMBqNLQAAAADAaK6aHgB+ceedd6pyjzzySDWP5MKNHTtWlTtw4IAqd/PNN9tmkpOTVbV69+6tymn379SpU1U5jYiICL/VAqqby2X/tBEdHa2q1bJlS1WuS5cuqlxaWpoq16pVK9uMw+FQ1dq3b58qt337dlXu6NGjqpzmcbAsS1XL7Xarck2bNlXlrrnmGtuM9hhJSkpS5cLDw1U5p9Opynk8HlUOF5/2uNbQnufa40FTz+v1+nWdt912myo3fPhwv61Xe92Sm5urys2bN0+VO3z4sCrXqVMn20xmZqaq1ocffqjKaa8zH3roIdvM8ePHVbUaNmyoyu3evVuV0zyvaGmP84AA/95j5Y4tAAAAAMBoNLYAAAAAAKPR2AIAAAAAjEZjCwAAAAAwGo0tAAAAAMBoNLYAAAAAAKPR2AIAAAAAjEZjCwAAAAAwGo0tAAAAAMBoDsuyLFXQ4ajusVyWhgwZosq98sorqpzy4VLJzc1V5VatWqXKjRo1qirDuSQkJSWpcocOHfLbOpcvX67KDR061G/rrCn+PH4vJZfD/OhyuVS5qKgo20yrVq1UtdLS0lS5Hj16qHLJycmqnObx2rt3r6rW5s2bVbmtW7eqcv6cW7SCgoJUudTUVFWuT58+tpmYmBhVrfXr16tyK1euVOV27typyhUWFqpy/nS5zo9xcXGqnHb7/Tnfejwev66ztLTUNhMQoLunpDmPRESmTZumymnP86KiIttMYGCgqtayZctUuYULF6pyXq9XlQsLC1PlNLKyslS5iIgIVe6zzz6zzURGRqpqzZ07V5WbM2eOKqe9DtAc59rHSnve5+TkqHLcsQUAAAAAGI3GFgAAAABgNBpbAAAAAIDRaGwBAAAAAEajsQUAAAAAGI3GFgAAAABgNBpbAAAAAIDRaGwBAAAAAEajsQUAAAAAGM1V0wMw1YgRI1S5OXPmVPNILtzzzz+vyj3xxBPVO5BLSG5uriq3fv1620y3bt1UterUqaPKBQcHq3LFxcWqHK4MTqdTlYuMjFTlWrZsaZvp0qWLqlb37t1VudatW6tyDodDldu9e7dtZuPGjapamzZtUuV27dqlyp04cUKV83q9thnt/oiIiFDl4uPjVbmsrCzbTGJiol/XGRUVpcoFBgaqckVFRbYZy7JUta502v2knas8Ho9fMiIiAQG6+ztut1uVc7nsL6v79OmjqjVt2jS/rVNEN2do682bN09V6/3331fltPOe9jpIU0+7PzRzgYhIdHS0KvfJJ5/YZjp16qSqpc1pr/e114+ac1r7/ONv3LEFAAAAABiNxhYAAAAAYDQaWwAAAACA0WhsAQAAAABGo7EFAAAAABiNxhYAAAAAYDQaWwAAAACA0WhsAQAAAABG032r8xVmxIgRtpm///3vqlpBQUFVHc4FGTNmjG1m+fLlF2EkZtF+OfWRI0f8ts7u3burclFRUarc8ePHqzIcGEL75eehoaGqXOPGjVW5zp0722ZuuukmVa02bdqoci6X7qlq7969qtzGjRttM+vXr1fV+uGHH1S5nJwcVa60tFSVsyzLNhMQoHvtOjg4WJVzu92qnNfr9ds6o6OjVbmIiAhVTnssac4vzWMA/X7y5/50Op2qnOZYFdEfN/369bPNPProo6pa2rFp5wztPvnb3/5mm3nvvfdUtfLz81U57WOv3Sea87ekpERVq379+qpcXl6eKqfpC7THW8OGDVU57fVjVlaWKqehvUbx9zzKHVsAAAAAgNFobAEAAAAARqOxBQAAAAAYjcYWAAAAAGA0GlsAAAAAgNFobAEAAAAARqOxBQAAAAAYjcYWAAAAAGA0GlsAAAAAgNFcNT2Ai6lNmzaq3Jw5c2wzQUFBVR3OBVm6dKnfciUlJVUdzmUnISFBlfv9739fzSMBfl1gYKAqFxcXp8pdffXVqlznzp1tM61bt1bVcjqdqlxGRoYqt2XLFlVu06ZNtpldu3apauXk5KhypaWlqpw/ORwOVS44OFiVq127tioXHR1tmwkJCVHVCgjQvf6u3VZcfNrHxp/Ha0FBgaqWdg5q2LChKjd58mS/rdPtdqtysbGxqtyiRYtUuffee882c/z4cVUt7XmuzWmPEZfLvr3Rzme5ubmqXJ06dVS53/zmN7YZy7JUtTRzrYj+mNPOt16v1y8ZEf/P3dyxBQAAAAAYjcYWAAAAAGA0GlsAAAAAgNFobAEAAAAARqOxBQAAAAAYjcYWAAAAAGA0GlsAAAAAgNFobAEAAAAARqOxBQAAAAAYzVXTA/AHp9Opyk2bNk2VCw4OrspwyikoKFDlVq5cqcoNHz68KsOBjfT0dFUuLCzMb+v89ttvVbn8/Hy/rROXtoAA+9ccIyIiVLWaNWumynXo0EGVa9WqlW3G5dI9tezfv1+V27x5syr3ySefqHI7d+60zeTm5qpqud1uVa4maI4jEZFatWqpcklJSapcbGysbUa737Kzs1W5vLw8VU67XsuyVDn4j9frVeWKi4ttM9rrwsDAQFVu0qRJqlxhYaFtRnv9oJ1HX3rpJVVu4cKFqtyJEydsM9r9pn0cSkpKVDnt9bnm+TEnJ0dVS3O8iYjceOONqlxiYqJtRjuf7dixQ5XTbmtRUZEqpzk2tXOow+FQ5bS4YwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMJqrpgfgD/fee68q9/vf/16VsyyrKsMp58knn1TlnnnmGb+tExcuNTVVlfPnMfLXv/5VlcvPz/fbOnFpczqdtpno6GhVrauuukqVS05OVuWioqJsM0ePHlXV2rp1qyr38ccfq3I7duxQ5bKzs20zpaWlqlr+nAv8zeXSPcVHRESocrGxsapcWFiYbebkyZOqWj/99JMql5mZqcqVlJSocpfy42oah8OhymkfG81xrV1nz549Vbmrr75alYuMjLTNaI+t+fPnq3IvvfSSKqfdv5p9FxCguy/m9XpVOS3tvFxcXGyb0T4OCQkJqlxcXJwq5/F4bDPa43fZsmWqXFFRkSqnXa8mp33stceSFndsAQAAAABGo7EFAAAAABiNxhYAAAAAYDQaWwAAAACA0WhsAQAAAABGo7EFAAAAABiNxhYAAAAAYDQaWwAAAACA0WhsAQAAAABGc9X0APyhdevWF32dR44cUeVefPHFah4JTLdz586aHgIuMU6n0zYTFhamqpWYmKjKxcTEqHLFxcW2mT179qhqffnll6rcrl27VLns7GxVrrS01DZjWZaqVk3RHCOhoaGqWnFxcaqc9lgKCQmxzRw/flxVS5s7deqUKud2u1U5+E9AgO4eSnBwsCrncDhsM16vV1Wrbdu2qpx2bJpjf/fu3apaq1evVuW021qrVi1VLj8/3zYTGBioqqUdm8fjUeVcLl3boqmnneO1c0udOnVUuby8PNtMVFSUqtaOHTtUOe1+086PmnNQ8xwloj9GtLhjCwAAAAAwGo0tAAAAAMBoNLYAAAAAAKPR2AIAAAAAjEZjCwAAAAAwGo0tAAAAAMBoNLYAAAAAAKPR2AIAAAAAjKb7xl5UcO+996pyJ06cqN6BQKVNmzaq3JAhQ6p5JIB/aL9wPTg4WJULCNC9zqn5svqff/5ZVevw4cOq3OnTp1U5f3/Ruz9pvtBeRP+4hoeH22YaNmyoqtW2bVtVrlmzZqpcaGiobSY/P19V6+TJk6pccXGxKmdZlioH//F4PKqcdg7SzGl5eXmqWgUFBaqc9rzUzI9/+9vfVLWOHj2qyjmdTlVOOwdpHgfNOS4ikpWVpcpFRESocto5XrOtbrdbVSslJUWV6969uyqn2QbtPKXdb9pzMDAw0G/1tOezv5+3uWMLAAAAADAajS0AAAAAwGg0tgAAAAAAo9HYAgAAAACMRmMLAAAAADAajS0AAAAAwGg0tgAAAAAAo9HYAgAAAACMRmMLAAAAADCaq6YHYKrGjRvX9BAgIm3atFHl1q1bp8rFxcWpcpZl2WYOHjyoqpWdna3KAWfSHIMiIm63W5Xzer2qXGBgoG0mOjpaVat+/fqq3IkTJ1S5Y8eOqXKFhYW2Ge3+0HK5dE+3kZGRqpzmOahDhw6qWmlpaapckyZNVDnN/v3pp59UtbSPaVFRkSqnPW/gP9pzyel0qnL5+fm2Ge3jXKtWLVVOW8/j8dhmEhMTVbW0c8HJkydVOe08qtkGzWMgIhIcHKzK5eXlqXLa5xbNHNSpUydVrenTp6tytWvXVuU0c9X+/ftVtTIzM1U5f18vaJ/PagJ3bAEAAAAARqOxBQAAAAAYjcYWAAAAAGA0GlsAAAAAgNFobAEAAAAARqOxBQAAAAAYjcYWAAAAAGA0GlsAAAAAgNFobAEAAAAARnPV9AD8oaCgQJVzOBx+W+dLL72kyo0ePVqVmz59uir3ySefqHKFhYWqXE2IiopS5f70pz/ZZiZOnFjV4ZQTEKB7refQoUO2me7du6tqHTlyRJXDlcPr9dpm8vPzVbUyMzNVuZycHFWuWbNmtpl27dqpagUGBqpyDRo0UOX27dunymm2tbi4WFVLO2cEBwercvXr11flUlJSbDOpqamqWk2bNlXlLMtS5Xbv3m2b+eqrr1S1Dhw4oMppn/M05xb8S3uOuN1uVU7zGIaGhqpqaefHkJAQVa6kpMQ2M3XqVFWtbt26qXILFixQ5bZt26bKaeZl7f7QzqPax157nj/22GO2mT59+qhqJSUlqXJFRUWqXGlpqW1mzJgxqlra60d/Hr8iunNQ+3zhz95MhDu2AAAAAADD0dgCAAAAAIxGYwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMBqNLQAAAADAaDS2AAAAAACjuWp6AP7w1FNPqXIpKSmqXO/evasynHJSU1NVuXfffVeV+/TTT1W5jIwMVc6fHA6HKtexY0dVrkmTJrYZy7JUtbQOHTqkys2ZM8c2c+DAgSqOBlcqj8djmzlx4oSq1g8//KDKac43EZHIyEjbTJ06dVS1ateurcq1aNFCldOevzk5ObaZ4uJiVa2AAN3rw6GhoapcYmKiKtewYUPbTGxsrKpWQUGBKrdz505VbtOmTbaZr7/+WlXr2LFjqlxpaakqh4tPe45on8/dbrdtRnv+/uMf/1DlmjVrpsqlp6fbZgIDA1W1OnXqpMq1a9dOldPOj7t27bLNaB4DEf22BgUFqXLa6/ikpCTbjMula4G0c5DW3LlzbTOZmZmqWtpt0M6P2nNQe07XhEt3ZAAAAAAAKNDYAgAAAACMRmMLAAAAADAajS0AAAAAwGg0tgAAAAAAo9HYAgAAAACMRmMLAAAAADAajS0AAAAAwGgOS/ltvA6Ho7rHUu1q1aqlyr3yyiu2mb59+1Z1OOVo96/2y5NrwqW8DQcPHlTlunfvrsodOHCgCqO5cl3Kx29V1MT8qP1C+8TERFWuXbt2qlxaWpptpkOHDqpaDRo0UOXCwsJUOY/Ho8ppvqxeW0t7TDudTlUuMDBQlfN6vbaZnJwcVa0dO3aoclu2bFHlvv76a9tMRkaGqtbJkydVOe3jdSm7XOfHuLg4VU57jmjOX+2ccerUKVUuKSlJlXvkkUdsM7169VLV0h77ERERqlxJSYkqpxEeHq7KFRcXq3Ka+UxEpKCgQJXTPCdHRUWpammv9yZOnKjK7d+/3zbjdrtVtbT7zd/PUwEB9vdFtWPTysrKUuW4YwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMBqNLQAAAADAaDS2AAAAAACj0dgCAAAAAIxGYwsAAAAAMJrDsixLFXQ4qnssl4xatWrZZm699VZVrYceekiVS01NVeWUD1eN0B4j2m04cuSIbeaTTz5R1Zo+fboqt3//flUOF+ZSPn6roibmR+06g4KCVLn4+HhVrmXLlraZ3/zmN6paKSkpqlzjxo1VucTERFVOM8drFRcXq3JFRUWqXEFBgSr3n//8xzazZ88eVa1vv/1WlduxY4cqd/jwYduMdjs9Ho8qdzm4XOdH7dyifaxdLpdtRnu+RUdHq3KZmZmqXN26dW0zvXv3VtXq2bOnKtekSRNVTnt8hYWF+a1WSUmJKhcXF6fKaedbzeO1efNmVa3Fixercvv27VPlAgLs7ylq96/2+b20tFSV04xNRDc+7TZor2WysrJUOe7YAgAAAACMRmMLAAAAADAajS0AAAAAwGg0tgAAAAAAo9HYAgAAAACMRmMLAAAAADAajS0AAAAAwGg0tgAAAAAAo9HYAgAAAACM5rAsy1IFHY7qHstlKTw8XJWLj49X5caMGaPK9evXzzaTn5+vqrV27VpVTisrK0uVe/HFF20zJ06cqOJocDEppxvjXMrzo3ZsgYGBqlytWrVsM9r5rEGDBqpco0aN/JpLSkqyzQQE6F73PX36tF9zOTk5qtzPP/9smzl48KCq1uHDh1U57diKiopsM16vV1XrSnK5zo8JCQmqnHauKi0t9Vstp9OpyrndblVOM29o55bg4GBVrmHDhqpcnz59VLlrr71WldPYtm2bKnfy5ElVLjMzU5XbvHmzbeann35S1QoLC1PliouLVTmXy2Wb8Xg8qlo1pSbmKm3vwB1bAAAAAIDRaGwBAAAAAEajsQUAAAAAGI3GFgAAAABgNBpbAAAAAIDRaGwBAAAAAEajsQUAAAAAGI3GFgAAAABgNBpbAAAAAIDRHJZlWaqgw1HdYwFwmVNON8a5kuZHp9NpmwkMDFTVCgkJUeUiIyNVuZiYGFUuIiLCNhMQoHvdt7i42K+5goICVS4vL882c/r0aVUt7dg8Ho8qd7me59Xtct1v8fHxqpx2+71er22mpuZkzTminVv8nSsqKlLlNPOttpbb7VblwsPDVTntXKXZJ9paLpdLldPSPIdq95umVmVozi2Rmjm/srKyVDnu2AIAAAAAjEZjCwAAAAAwGo0tAAAAAMBoNLYAAAAAAKPR2AIAAAAAjEZjCwAAAAAwGo0tAAAAAMBoNLYAAAAAAKPR2AIAAAAAjOawLMtSBR2O6h4LgMuccroxDvPjhQkI0L22qs25XC5Vzul0qnIa2mPa6/X6NefxePxW63I9L01zuT4OcXFxF32d2mNfO3drc5q5xe12q2ppj4fS0lJVLiQkRJUrLCy0zQQFBalqafebdo7XPq6ax0G7Ts1cW5mcZp9ox+bvOUP7eGnWqx2bdp1ZWVmqHHdsAQAAAABGo7EFAAAAABiNxhYAAAAAYDQaWwAAAACA0WhsAQAAAABGo7EFAAAAABiNxhYAAAAAYDQaWwAAAACA0XTfZg8AgJ95vV6/5txud1WGA6AaWJalyjkcDr/VczqdqlraucXj8ahyLpf9ZbV2OzW1KpPTrrdWrVq2Ge3+8Pf+1SouLrbNaI8Rf+c0x6/2nPG3mlivv9fJHVsAAAAAgNFobAEAAAAARqOxBQAAAAAYjcYWAAAAAGA0GlsAAAAAgNFobAEAAAAARqOxBQAAAAAYjcYWAAAAAGA0GlsAAAAAgNFcNT0AAAAAXJ4cDocqZ1mW3+p5vV6/1RIRCQjQ3QcqLS21zTidTr/VEhHxeDyqnHYbXC771kC737S09fz9eGloj0t/Hr/aWpcDfx9L3LEFAAAAABiNxhYAAAAAYDQaWwAAAACA0WhsAQAAAABGo7EFAAAAABiNxhYAAAAAYDQaWwAAAACA0WhsAQAAAABGo7EFAAAAABjNYVmWVdODAAAAAADgQnHHFgAAAABgNBpbAAAAAIDRaGwBAAAAAEajsQUAAAAAGI3GFgAAAABgNBpbAAAAAIDRaGwBAAAAAEajsQUAAAAAGI3GFgAAAABgtP8DwOv6G3wjy5QAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1200x400 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from skimage.metrics import peak_signal_noise_ratio as psnr\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "\n",
        "# Function to calculate PSNR and SSIM\n",
        "def calculate_metrics(original, distorted, title):\n",
        "    psnr_value = psnr(original, distorted)\n",
        "    ssim_value = ssim(original, distorted, data_range=original.max() - original.min())\n",
        "\n",
        "    print(f\"{title} PSNR: {psnr_value:.2f}\")\n",
        "    print(f\"{title} SSIM: {ssim_value:.4f}\")\n",
        "\n",
        "# Original image\n",
        "original_image = x_train[index] / 255.0\n",
        "\n",
        "# Calculate PSNR and SSIM between original and blurred image\n",
        "calculate_metrics(original_image, blurred_image, \"Original vs Blurred\")\n",
        "\n",
        "# Generate and display a deblurred image\n",
        "sample_deblurred = deblur_generator(np.expand_dims(blurred_image, axis=0), training=False).numpy().reshape(28, 28)\n",
        "\n",
        "# Calculate PSNR and SSIM between original and deblurred image\n",
        "calculate_metrics(original_image, sample_deblurred, \"Original vs Deblurred\")\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "# Original image\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(original_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "# Blurred image\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.title(\"Blurred Image\")\n",
        "plt.imshow(blurred_image, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "# Deblurred image\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.title(\"Deblurred Image\")\n",
        "plt.imshow(sample_deblurred, cmap='gray')\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "id": "E1lM4WC61OBH",
        "outputId": "1ad78fb4-1706-4dcb-b3e0-c0b5c7129b1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter expected grade for MAE: B\n",
            "Enter expected grade for CN: B+\n",
            "Enter expected grade for DEPARTMENT ELECTIVE WITH LAB: B\n",
            "Enter expected grade for DEPARTMENT ELECTIVE WITHOUT LAB: B\n",
            "Enter expected grade for OPEN ELECTIVE 1: B\n",
            "Enter expected grade for OPEN ELECTIVE 2: B\n",
            "Enter expected grade for SUMMER INTERNSHIP: A\n",
            "Enter expected grade for MINOR PROJECT: A\n",
            "Your CGPA is: 7.39\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "s16C7obP2OJU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}